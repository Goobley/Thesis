\chapter{Time-Dependent Radiative Transfer}\label{Chap:TimeDepRt}
%TC:group pycode 0 0
\setpythontexautoprint{false}
\begin{pycode}[TimeDepRT]
name = 'TimeDepRT'
chRT = texfigure.Manager(
    pytex,
    './02TimeDepRT',
    number=2,
    python_dir='./02TimeDepRT/python',
    fig_dir=   './02TimeDepRT/Figs',
    data_dir=  './Data/02TimeDepRT'
)
\end{pycode}

% \begin{pycode}[TimeDepRT]
% from lightweaver.fal import Falc82
% from lightweaver.rh_atoms import H_6_atom, C_atom, O_atom, Si_atom, Al_atom, CaII_atom, Fe_atom, He_atom, MgII_atom, N_atom, Na_atom, S_atom
% import lightweaver as lw
% import matplotlib.pyplot as plt
% import numpy as np

% def iterate_ctx(ctx, Nscatter=3, NmaxIter=500):
%     for i in range(NmaxIter):
%         dJ = ctx.formal_sol_gamma_matrices()
%         # NOTE(cmo): Do some initial iterations without touching the
%         # populations to lambda iterate the background scattering terms
%         if i < Nscatter:
%             continue
%         delta = ctx.stat_equil()

%         # NOTE(cmo): Check convergence
%         if dJ < 3e-3 and delta < 1e-3:
%             print('Iterations taken: %d' % (i+1))
%             print('-'*60)
%             return

% wave = np.linspace(853.9444, 854.9444, 1001)
% def synth_8542(atmos, conserve, useNe):
%     # NOTE(cmo): Configure the Gauss-Legendre angular quadrature for 5 rays
%     atmos.quadrature(5)

%     # NOTE(cmo): Construct the RadiativeSet with the following atomic models
%     aSet = lw.RadiativeSet([H_6_atom(), C_atom(), O_atom(), Si_atom(), Al_atom(), CaII_atom(),
%                             Fe_atom(), He_atom(), MgII_atom(), N_atom(), Na_atom(), S_atom()])
%     # NOTE(cmo): Set Hydrogen and Calcium to active
%     aSet.set_active('H', 'Ca')
%     # NOTE(cmo): Compute the SpectrumConfiguration for this RadiativeSet
%     spect = aSet.compute_wavelength_grid()

%     # NOTE(cmo): If we're using the electron density provided with FAL C, then
%     # compute the associated LTE populations, otherwise find a solution for
%     # self consistent LTE populations and electron density.
%     if useNe:
%         eqPops = aSet.compute_eq_pops(atmos)
%     else:
%         eqPops = aSet.iterate_lte_ne_eq_pops(atmos)

%     # NOTE(cmo): Construct the Context, optionally setting chargeConservation and the number of threads to use.
%     ctx = lw.Context(atmos, spect, eqPops, conserveCharge=conserve, Nthreads=8)

%     # NOTE(cmo): Iterate the NLTE problem to convergence
%     iterate_ctx(ctx)
%     # NOTE(cmo): Compute a detailed solution to Ca II 8542 on the 1 nm wavelength grid above
%     Iwave = ctx.compute_rays(wave, [1.0], stokes=False)
%     return Iwave

% # NOTE(cmo): Load an atmosphere. In this case we include a copy of FAL C, but
% # Lightweaver also supports loading atmospheres in the MULTI format, and it is
% # also simple to do so from the raw data components
% atmosRef = Falc82()
% # NOTE(cmo): Ca II 8542 with the reference electron density in the FAL C atmosphere
% IwaveRef = synth_8542(atmosRef, conserve=False, useNe=True)

% atmosCons = Falc82()
% # NOTE(cmo): Ca II 8542 with the electron density obtained from charge conservation
% IwaveCons = synth_8542(atmosCons, conserve=True, useNe=False)

% atmosLte = Falc82()
% # NOTE(cmo): Ca II 8542 with LTE electron density
% IwaveLte = synth_8542(atmosLte, conserve=False, useNe=False)

% fig = plt.figure()
% plt.plot(wave, IwaveRef, label='Reference')
% plt.plot(wave, IwaveCons, '--', label='Conserved')
% plt.plot(wave, IwaveLte, '--', label='LTE')
% plt.title(r'Comparison of Ca\,\textsc{ii} 854.2\,nm with different electron densities', y=1.04)
% plt.ylabel(r'Intensity [SI]')
% plt.xlabel(r'$\lambda$ [nm]')
% plt.legend()
% lFig = chRT.save_figure('EleDensComparison', fig, fext='.pgf')
% lFig.caption = r'Comparison of Ca\,\textsc{ii} 854.2\,nm with different electron densities'
% \end{pycode}
% \setpythontexautoprint{false}

% \py[TimeDepRT]|chRT.get_figure('EleDensComparison')|

% \begin{itemize}
%     \item Current problems not solved by RADYN and MS\_RADYN.
%     \item \Lw{}
%     \item \MsLw{}
%     \item Reprocessing RADYN simulations
%     \item Effect of the Lyman lines on \CaLine{} in RHD simulations
%     \item Diagnostic potential of response functions
%     \item Another item - PRD is hard?
% \end{itemize}

Modern Radiation Hydrodynamic (RHD) codes are highly complex, and contain many specialised features as discussed in the previous chapter.
In the following discussion we will focus primarily on \Radyn{}, the most widely used code of its ilk, and how using additional tools can facilitate new avenues of investigation.

\section{Introduction to Hydrodynamics and Conservation Laws}
\emph{The majority of the basic theory in this section follows the two texts by Leveque \NeedRef{}}

In the previous chapter we have explained the basis of the radiative transfer methods used throughout this work.
The difficulty in radiative transfer primarily lies in the nuance of the various integration terms.
To provide a clear understanding of RHD we also need a numerical description of hydrodynamics, and an explanation of solving the coupled systems of partial differential equations (PDE) that represent the other major facet of RHD.

The scalar radiative transfer equation, solved via the formal solver (presented in the previous chapter) is a good example of an ordinary differential equation.
It is relatively easy to solve via a variety of methods, typically striving for a balance of speed, reliability, and accuracy.
In general, PDEs are difficult to solve numerically in a general way.

A generic second-order PDE of a quantity $q$ depending on two independent variables $x$ and $y$ can be written as
\begin{equation}
    aq_{xx} + bq_{xy} + cq_{yy} + dq_x + eq_y + fq = g,
\end{equation}
wherein the subscripts represent partial derivatives with respect to these variables.
The sign of the discriminant ($\Delta = b^2-4ac$) of this equation determines the class of the problem:
\begin{itemize}
    \item $\Delta < 0$: Elliptic problem (e.g. Poisson equation).
    \item $\Delta = 0$: Parabolic problem (e.g. Heat equation).
    \item $\Delta > 0$: Hyperbolic problem (e.g. Advection equation).
\end{itemize}
Here, we will focus primarily on hyperbolic problems, with a brief discussion of parabolic terms.
Hyperbolic problems take the form
\begin{equation}\label{Eq:ConsLaw}
    q_t + f(q)_x = 0,
\end{equation}
where $f$ is a function describing the the flux of $q$ at each location in the domain, $t$ indicates a temporal coordinate, and $x$ a spatial coordinate.
There is an inherent assumption that the flux function is local, and acts only on the local state variables $q$.

Equations of the form \eqref{Eq:ConsLaw} are known as conservation laws, and the quantities $q$ are often termed ``conserved quantities'', implying that $\int_{-\infty}^{\infty} q\, dx$ is constant in time.
This does not preclude the addition of sources and sinks of this quantity, but simply requires that the total of a conserved quantity not change \emph{without} being acted on in such a way.
The simplest equation of this form is advection, which simply arises from conservation of mass in a moving fluid and is written for mass density $\rho$ and velocity $u$ as
\begin{equation}\label{Eq:Advection}
    \rho_t + (\rho u)_x = 0.
\end{equation}

The advection equation can be augmented with two further equations to form the Euler equation set.
These three equations are the conservation of mass, momentum, and energy.
Together they describe the evolution of ideal fluids.
The complete set is written
\begin{equation}\label{Eq:EulerEqns}
\begin{split}
    \rho_t + (\rho u)_x &= 0,\\
    (\rho u)_t + (\rho u^2 + p)_x &= 0,\\
    E_t + (u(E + p))_x &= 0,
\end{split}
\end{equation}
where $E$ is the total energy and $p$ is the gas pressure.
As our three conserved quantities are the mass density, momentum density, and energy, the pressure must be expressed as a combination of these so as to be able to write this system in the form of \eqref{Eq:ConsLaw}.
The simplest way to achieve this is to use the equation of state for an ideal gas
\begin{equation}
    E = \frac{p}{\gamma-1} + \frac{1}{2}\rho u^2.
\end{equation}
Here $\gamma$ is the ratio of gas' specific heat at constant pressure and constant volume, which is 5/3 for monatomic gasses, as considered in the case of solar plasma.

The Euler equations \eqref{Eq:EulerEqns} describe the evolution of an ideal fluid without any energy losses.
In practice we often need to model some loss terms.
Ignoring radiative effects for now, the most important of these is heat conduction\footnote{In the plasmas considered here there is additional nuance to heat conduction, which we will return to in Sec.~\ref{Sec:NumericalConduction}.}, which is typically described by parabolic equations.
This adds a second spatial derivative term to the right-hand side of the energy conservation equation.
It is also common to need source and sink terms when modelling real world problems, these can account for fluids entering and leaving a volume, the non-local emission and absorption of energy, or simply the effects of gravity.
These terms are also added to the right-hand side of the equations of \eqref{Eq:EulerEqns}, and together with the effects of viscosity, these describe the Navier-Stokes equations.

\subsection{Numerical Approaches}

The typical first choice for numerically solving differential equations is to apply a finite difference method.
In this class of method, the problem is discretised, similarly to the approach taken in radiative transfer, and the values associated with each grid point represent the local pointwise value.
The local gradient of the conserved quantities can then be estimated from pointwise difference between in the quantity between adjacent cells.
This method can be applied to discrete problems in both space and time.
Applying a basic one-sided method to the advection equation \eqref{Eq:Advection} gives
\begin{equation}\label{Eq:FdmAdvection}
    \frac{q^{t+1}_i - q^t_i}{\Delta t} + u\left( \frac{q^t_{i+1} - q^t_i}{\Delta x} \right),
\end{equation}
where the subscript refers to the location of the conserved quantity, the superscript the discrete timestep, with $\Delta x$ and $\Delta t$ being the local grid spacing and timestep duration respectively.

It is clear that without loss of generality we could have also chosen to spatially difference our problem in the other direction (i.e. $q^t_i - q^t_{i-1}$).
From the infinitesimal definition of the derivative, these two formulations are equivalent.
This is not the case in discretised problems.
It is better to locally use the formulation such that information from points ``upwind'' in terms of the fluid velocity are used to update the points downwind of themselves.
In this sense the information used to update points is following the fluid flow.
Equation \eqref{Eq:FdmAdvection} can be rewritten to explicitly determine the approximate value of the quantity at the next timestep,
\begin{equation}
    q^{t+1}_i = q^t_i - \frac{u \Delta t}{\Delta x}\left( q^t_{i+1} - q^t_i \right).
\end{equation}

This simple first order accurate approach can be applied to any conservation law, and higher-order accurate methods can be derived from using finite difference methods over larger stencils, or deriving similar approaches from combinations of the local finite difference approximations using Taylor series.

Many other spatial and temporal discretisations can be devised for conservation laws, and it is important to choose a discretisation that introduces minimal error.
In general, we term discretisations where $q^{t+1}$ depends only on $q^{t}$ as \emph{explicit}, and those also depending on $q^{t+1}$ as \emph{implicit}, necessitating the solution of a system of typically non-linear equations.

Whilst the finite difference method provides an intuitive formulation for discretising these equations, it is difficult to ensure conservation of the quantities that we desire be conserved with only pointwise values and no formal description of the variation between these points.
Instead the finite volume description is often preferable and consists of treating $q_i^t$ as the average value over a grid cell.
Conservation can then be ensured by evolving this value based on the fluxes in and out of the cell.
This implies
\begin{equation}
    q_i^t \approx \frac{1}{\Delta x}\int_{x_i}^{x_{i+1}} q^t(x)\, dx.
\end{equation}
Rewriting the conservation law \eqref{Eq:ConsLaw} in an integral form then gives
\begin{equation}
    \int_{x_i}^{x_{i+1}} q^{t+1}(x)\, dx = \int_{x_i}^{x_{i+1}} q^{t}(x)\, dx
                                         + \int_{t_t}^{t_{t+1}} q_i(t)\, dt
                                         - \int_{t_t}^{t_{t+1}} q_{i+1}(t)\, dt,
\end{equation}
which can then be written as the flux-differencing form
\begin{equation}\label{Eq:FiniteVolumeMethod}
    q_i^{t+1} = q_i^t - \frac{\Delta t}{\Delta x}\left( F^t_{i+1} - F^t_{i} \right),
\end{equation}
where $F_i$ represents the flux due between cells $i$ and $i-1$, and $F_{i+1}$ the flux between cells $i$ and $i+1$.
In the case of an explicit method with a correctly chosen timestep for the grid, where information cannot move further than one cell in a timestep, each of these flux functions depends only on cell $i$ and one of its neighbours.
An important strength of this method for solving conservation law problems is that if $F_i$ and $F_{i+1}$ are respectively the left and right edge fluxes for cell $i$, then $F_{i+1}$ will be the left edge flux for cell $i+1$, and $F_{i}$ will be the right edge flux for cell $i-1$.
Thus the numerical integration of $q^{t+1}$ is conserved with respect to $q^t$ as all numerical fluxes, other than the left- and right-most, will cancel due to the formulation of \eqref{Eq:FiniteVolumeMethod}.
These left- and right-most fluxes will need to consider the boundary conditions of the finite simulation volume to ensure the correctness of the conservation law.


\subsection{Riemann Problems}

% spell-checker: disable
\begin{pycode}[TimeDepRT]
from shocktubecalc import sod
from matplotlib.ticker import MaxNLocator

gamma = 1.4
positions, regions, values = sod.solve(left_state=(1.0, 1.0, 0.0), right_state=(0.1, 0.125, 0.0),
                                       geometry=(0.0, 1.0, 0.5), t=0.2, gamma=gamma, npts=500)
fig, ax = plt.subplots(2, 2, figsize=texfigure.figsize(pytex, scale=1, height_ratio=0.6),
                       constrained_layout=True)
ax = ax.ravel()
grid = values['x']
pressure = values['p']
density = values['rho']
velocity = values['u']
totE = pressure / (gamma - 1.0) + 0.5 * density * velocity**2

ax[0].plot(grid, density)
ax[0].set_xticklabels([])
ax[1].plot(grid, velocity)
ax[1].set_xticklabels([])
ax[2].plot(grid, pressure)
ax[3].plot(grid, totE)

ax[0].set_ylabel(r'$\rho$')
ax[1].set_ylabel(r'$u$')
ax[2].set_ylabel(r'$p$')
ax[3].set_ylabel(r'$E$')

ax[2].set_xlabel(r'$x$')
ax[3].set_xlabel(r'$x$')

lFig = chRT.save_figure('SodTubeAnalytic', fig, fext='.pgf')
lFig.caption = r'Solution to the classic Sod shock tube problem at $t=\SI{0.2}{\second}$.'

fig = plt.figure(figsize=texfigure.figsize(pytex, scale=1, height_ratio=0.55))
ax = plt.gca()
ax.plot(grid, density)
ax.set_ylabel(r'$\rho$', c='C0')
ax.set_xlabel(r'$x$')

ax2 = ax.twinx()
# ax2.plot([0.5, 0.7], [0, 0.2], c='#222222')
for i, p in enumerate(positions.values()):
    ax2.axvline(p, c='k')
    if i != 1:
        ax2.plot([0.5, p], [0, 0.2], c='#555555')
regionLims = np.array([0, *positions.values(), 1])
regionCentres = 0.5 * (regionLims[1:] + regionLims[:-1])
labels = [r'$\alpha$', r'$\beta$', r'$\gamma$', r'$\delta$', r'$\epsilon$']
for i, c in enumerate(regionCentres):
    ax2.text(c, 0.02, labels[i])

ax2.set_ylabel(r'$t$')
ax2.yaxis.set_major_locator(MaxNLocator(5))
lFig = chRT.save_figure('RiemannFan', fig, fext='.pgf')
lFig.caption = r'Riemann fan of different wave speeds and associated regions for the Sod shock tube problem.'
\end{pycode}

\py[TimeDepRT]|chRT.get_figure('SodTubeAnalytic')|
\py[TimeDepRT]|chRT.get_figure('RiemannFan')|
% spell-checker: enable

The finite volume method we have described therefore depends on finding expressions for the numerical flux between two adjacent cells.
This is often framed as a Riemann problem at the cell interface.
A Riemann problem consists of solving a conservation law with an initial parameter distribution consisting of two constant states meeting at a discontinuity.
Without loss of generality this discontinuity can be placed at $x=0$, and the value of $q$ for $x<0$ is termed $q_l$ and $q_r$ for $x>0$.

A very well studied Riemann problem, that is often used as a test case for numerical hydrodynamics, is that of the Sod shock tube \citep{Sod1978}.
The problem is a single Riemann problem, with gas at a different pressure and density on each side of a membrane.
At $t=0$ the membrane is removed, and multiple waves with different velocities are launched in both directions.
A solution to the classic Sod shock tube with states $q_l = \{\rho=1, p=1, u=0\}, q_r = \{\rho=0.125, p=0.1, u=0\}$ at $t=\SI{0.2}{\second}$ is shown in Fig.~\ref{Fig:SodTubeAnalytic}.
At this time, a complex pressure and density structure has formed in the shock tube.
The Riemann problem is often considered in terms of the propagating waves.
In Fig.~\ref{Fig:RiemannFan} we show the same density profile, but divided into regions by black lines, with grey lines showing a time-distance plot of the different waves in the system.
This plot, and manner of considering the waves in the system is known as a Riemann fan.

The left- and right-most regions of density ($\alpha$ and $\epsilon$) shown in Fig.~\ref{Fig:RiemannFan}, are simply the initial left and right states of the fluid, as these are currently unperturbed by the waves propagating from the initial discontinuity.
Starting from the initial discontinuity, a rarefaction wave (reduction in density) moves into the high density region (to the left), and a shock wave propagates into the low density region (to the right).
The rarefaction wave is present in region $\beta$, with the shock front being the boundary between $\delta$ and $\epsilon$.
There is an additional front between regions $\beta$ and $\gamma$, which we note is not visible on either the velocity or pressure panels of Fig.~\ref{Fig:SodTubeAnalytic}.
This is a contact discontinuity and represents the boundary between two regions of different entropy.
This is the original interface between the two gases at $t=0$, and it is advected along with the flow at the velocity $u$, so there is no mixing between the two sides of this contact discontinuity (in the case of an ideal gas).

From analysis of the Jacobian of the flux function of the Euler equations, the structure of this solution can be revealed.
There are three waves, associated with the eigenvalues of this Jacobian.
The contact discontinuity propagates at the fluid velocity $u$ (as the fluid expands into the low density region), the other two eigenvalues are $u\pm c_s$, where $c_s$ is the sound speed of the fluid.
Unfortunately these waves are non-linear and do not necessarily propagate at the characteristic velocity given by their associated eigenvalue.
Instead it is necessary to apply the Rankine-Hugoniot jump conditions, at both the shock front and the contact discontinuity (given that the pressure and velocity do not vary across the latter), and solve the resultant transcendental equation to determine the parameters of regions $\gamma$ and $\delta$.
These problems can be solved using iterative methods and knowledge of the expected wave form of the solution.

As the complexity of the system and the equation of state increases, it becomes harder (or impossible) to compute this solution in an efficient manner.
Fortunately, it is rarely necessary to compute the exact solution to the Riemann problem, but it is important to understand the the structure originating from this simple case to interpret and validate the numerical methods described later.

% N.B. The characteristic of a system like this is a line for which the the solution q is constant. i.e. for advection this is x(t) = x0 + ut
% For linear systems we can transform to characteristic variables, for which the coefficient matrix is diagonal and we have a system of independent scalar advection equations.
% The velocity is time/space varying along the rarefaction wave.
% The characteristic field of an equation is an eigenvector, if this is linearly
% degenerate then we can only have contact discontinuities.
% Integral curves are curves which connect two points by an integral of one of the eigenvectors of the system.
% A function of q that is invariant along any integral curve is called a Riemann invariant, these are used for solving problems related to rarefaction waves.
% These Riemann invariants are conserved along the characteristic. For the u eigenvector, we have u and p as invariant, hence only the pressure can change => contact discontinuity.
% Characteristics on each side of shock linked by Hugoniot locus

\subsection{Godunov's Method and Higher Order Reconstructions}

Godunov's method \citep{Godunov1959} consists of assuming that the data $q$ is piecewise constant in each cell of our simulation domain.
At this point the values on the left- and right-hand side of each interface are known and the flux through this interface can be determined by solving a Riemann problem.
The Riemann problem at each interface can be treated independently under the assumption that the fastest wave from one interface not carry information to the next.
This is a fundamental requirement of stability and will be discussed in more detail in Sec.~\ref{Sec:HydroStability}.

This method provides a basic framework for solving conservation laws.
It is limited by the assumption that the data is piecewise constant, but nevertheless paved the way for some of the most accurate numerical methods for conservation laws.
\citet{VanLeer1979} provided one of the first higher order extension to Godunov's method.
It is tempting to attempt to estimate the value of $q$ at cell interfaces with higher accuracy by using some form of reconstruction (a method closely related to interpolation), but care must be taken with this approach.
The MUSCL method of \citet{VanLeer1979} uses a piecewise linear approach to reconstruction in each grid cell, but limits the gradient of the reconstruction to prevent the addition of under- or over-shoots to the data.
This is achieved through use of a slope-limiter such that a monotonic series of cell averages be preserved by ensuring that the reconstructed slope not take values beyond the average of the adjacent cells.
If the current cell is an extremum then the slope is set to 0.
Different slope-limiters have been designed and present different trade-offs in terms of accuracy in smooth regions against the risk of introducing spurious oscillations in the solution, these are discussed at length in introductory texts, such as Leveque \NeedRef{}.
This method tracks the data to second-order in regions of smooth variation, but degenerates to the first-order Godunov method at discontinuities.

There are further high-order extensions to the concept of reconstruction including the parabolic method of \citet{Colella1984} providing third-order accuracy in smooth regions, and the general weighted essentially non-oscillatory (WENO) methods.
WENO methods are a cornerstone of reconstruction\footnote{The properties that make WENO methods a good choice for reconstruction also render them applicable to interpolation. Throughout \Lw{} and the other numerical tools presented in this thesis we make use of a fourth-order WENO interpolation method described by \citet{Janett2019} for its accuracy in smoothly varying regions and reliable behaviour around sharp variations.} in modern finite volume codes, and as such we will describe them briefly here.

WENO methods were first proposed by \citet{Liu1994}, and formalised for arbitrary order by \citet{Jiang1996}.
These methods form a convex combination of polynomials over overlapping regions.
For example, in the case of the commonly used fifth-order WENO method of \citet{Jiang1996}, three parabolae are constructed over five adjacent points, i.e. the first uses the stencil $\{x_1, x_2, x_3\}$ the second $\{x_2, x_3, x_4\}$, and the third $\{x_3, x_4, x_5\}$.
We can equivalently define a fifth-order polynomial over the stencil $\{x_1, \ldots, x_5\}$, which can also be written as a linear combination of our interpolating parabolae at each point in this region.
These linear weights can be further weighted by a term known as the \emph{smoothness indicator}, which estimates the local smoothness, such that the weight of each term is equal to its expected linear weight in smooth regions, and heavily biased towards a parabola in a smooth region if other regions present discontinuities or similar effects.

The process of computing these initial interpolating functions is somewhat complex due to the finite volume framework often applied in hydrodynamics.
These should be computed such that the integral over the interpolating polynomial in each cell is close to the average value, rather than simply taking it as a pointwise value.
For a fixed uniform grid, the integration weights for each interface can be computed analytically, and the lack of conditional branches in the calculation of the final weighted value renders the method highly performant.
For non-uniform grids, the weights can be precalculated if the grid remains fixed, or computed on the fly if necessary.
There are also a number of approximate methods for handling non-uniform grids at low computational cost such as WENO-NM \citep{Huang2018}.
The WENO method has been extended many times to provide increased accuracy or meet certain requirements; its strong reconstructive ability and reliable behaviour around shocks makes it a workhorse of modern hydrodynamics and enables simpler flux functions to be reliably used, as will be discussed in the next section.


\subsection{Numerical Fluxes}

Whilst there are many approximate Riemann solvers that can accurately and efficiently solve the Riemann problems arising from the Euler equations including the addition of source terms, it does not appear feasible to express the evolution of the RHD system in this way.
Instead, in explicit methods we use numerical approximations to the flux based on the reconstructed values at the interfaces is used.
For implicit methods we can instead use a Newton iterative scheme to minimise the residual of the discretised conservation law across the cell interfaces with the fluxes typically computed from the upwind value of the reconstructed parameter.

With high-order reconstructions, simple expressions for the fluxes can be used and give accurate results.
An obvious first choice would be the average flux from the reconstructed states left and right of the interface.
Unfortunately, this leads to numerical instabilities, and some artificial damping (numerical viscosity) is needed.
This leads to a flux known as the Local Lax-Friedrichs, or Rusanov Flux \citep{Rusanov1962}
\begin{equation}
    F_{\mathrm{LLF}} = \frac{1}{2}(f(q_{i+1}^L) + f(q_i^R)) - \frac{1}{2}\alpha(q_i^R - q_{i+1}^L).
\end{equation}
Here $q_i^L$ and $q_i^R$ represent the left and right hand reconstructed states of the $i$-th Riemann problem, $f$ represents the flux function of the conservation law, and $\alpha$ is the local maximum wave propagation speed for this system.
Whilst $\alpha$ can often be formally derived from the Jacobian of $f$, it can often be replaced with either the maximum absolute value of the sum of the sound speed on each side of the interface and the local fluid velocity, or the average of these on both sides of the interface.
General symmetric fluxes like this are simple and efficient, but tend to be diffusive, smearing features across many grid cells, especially if the first-order Godunov or van Leer-style reconstruction methods are used.
This can be effectively combatted by the use of high-order reconstruction schemes and adaptive mesh refinement techniques, although when available, a specialised Riemann solver for the current problem is likely a better choice.

\subsection{Time Integration and Stability}\label{Sec:HydroStability}

Explicit schemes are only stable (i.e. do not diverge or introduce spurious oscillations) if the Courant-Friedrichs-Lewy (CFL) condition is met.
The CFL condition states that the numerical domain of dependence of the the equation (i.e. the terms used in the computation of a value in the next timestep) must encompass the analytic domain of dependence to ensure that all necessary information is taken into account.
This is a necessary, but not sufficient condition, and the exact requirements of each scheme can often be derived analytically, although it is common to apply an additional safety margin to the maximum permitted value of the CFL condition.

For explicit methods the CFL condition sets the maximum timestep that can be used based on the current simulation conditions.
In a hyperbolic system the CFL condition takes the form
\begin{equation}
    C = \frac{u\Delta t}{\Delta x},
\end{equation}
and will be constrained to a maximum value ($\leq 1$) for stability of an explicit method.
Most implicit methods do not place an upper limit on the CFL condition for stability (as all points are coupled), but typically need to remain $\sim 1$ to avoid losing fine detail in the solution.
This is discussed \citet{Viallet2011}, who comment that CFL $\sim 1$ serves as an accuracy criterion and typically represents the optimum accuracy/computational cost ratio despite the method being nominally stable for large CFL values.

It is difficult to achieve better than second order accuracy due to the temporal discretisations discussed so far, but by viewing $F_i^t$ as the flux at time $t$, we can achieve higher order accuracy by applying a multi-step method to more accurately integrate these fluxes (and any associated source terms) over time.
A good choice for this is a method in the family of total-variation diminishing Runge-Kutta methods \citep[e.g.][]{Shu1988}.
These multi-step time integration methods can be combined with fractional step methods that allow us to perform \emph{operator splitting}.
That is, splitting an equation into two subproblems that can solved independently.
An example of this would be the radioactive decay of an isotope transported by advection.
Splitting this into an advection and a reaction problem allows for standard methods to be used in both of these problems, but clearly their results need to be coupled to each other.
A naive first approach is to solve one of the subproblems over the timestep, and then solve the other, but this method cannot be better than first order accurate in time for coupled subproblems.
A commonly used approach that is second order is known at Strang splitting \citep{Strang1968}, which consists of time-advancing the first subproblem by half the timestep, then the second by the whole timestep, before once again advancing the first subproblem by a timestep.
This method can provide second-order accuracy.
Many more advanced splitting procedures have been developed, but Strang splitting remains widely used due to its ease of implementation.

LeVeque \NeedRef{} comments that in many situations the first-order splitting described above performs better than would be commonly expected from its formal first-order accuracy.
This is because the errors introduced are equivalent to solving the problem at a slightly different time, differing by up to a single timestep.
Whilst this renders the method first-order accurate, the quality of the solution is still primarily controlled by the quality of the methods used to solve the subproblems, and this exceedingly simple splitting scheme can often be applied with no problems.

There are many nuances to each of the techniques needed to accurately and robustly solve conservation laws numerically, and no single \emph{correct} method to use.
The above is intended to serve as an introduction to the complexities of these methods, but by no means present a conclusion on how conservation laws should be solved.
It is hoped that this introduction will improve general understanding of this aspect of RHD codes.

\section{Conduction}\label{Sec:NumericalConduction}

When expressed in terms of energy the heat equation in a plasma along a magnetic field line is given by
\begin{equation}
    \frac{\partial E}{\partial t} = \frac{\partial}{\partial z}\left( \kappa_0 T^{5/2} \frac{\partial T}{\partial z} \right),
\end{equation}
with spatial coordinate $z$, and coefficient $\kappa_0$ varying, but typically taken to be approximately \SI{1e-6}{\erg\per\centi\metre\per\second\per\kelvin\tothe{7/2}} \citep{Spitzer1953,Braginskii1965} based on deviations from a fully ionised hydrogen plasma.
The form of this equation poses several problems, the most significant being that in regions of sufficiently steep temperature gradients, the conductive flux approaches infinity.
Clearly this is not physical and there is a maximum limit, known as the free-streaming limit, at which all electrons in the plasma are flowing at their thermal speed with this heat gradient, representing a finite limit on this term.
As this free-streaming limit is approached the heat flux becomes non-local and depends on the global temperature and density structure in the loop \citep{Battaglia2009}.
\citet{Campbell1984} provides an expression for the transport coefficients used to determine the conductive flux through an ionised plasma and smoothly handles both the Spitzer-H\"{a}rm, locally limited, and non-locally limited regimes.
This approach can be applied in numerical simulations but more frequently (such as in RADYN) the method of \citet{FISHER1985} is applied which smoothly limits the local flux to remain less than the local free-streaming limit, helping to stabilise this equation.

Due to its parabolic nature, an explicit solution of the heat equation can be extremely costly; stability requirements provide a timestep requirement scaling with the inverse square of the grid spacing, rather than linearly as in the case of most hyperbolic equations.
Any attempt to explicitly integrate the heat equation on a timestep limit set by the hydrodynamic equations will likely be met with rapid divergence of any small perturbation in the data.
This renders the conduction term stiff compared to the hydrodynamical terms and it may therefore be advantageous to use an implicit method  to guarantee stability.
Several alternative methods have been developed, such as expressing the parabolic equation as a hyperbolic wave equation \citep{Rempel2016}, implicit-explicit methods (which may also be used for integrating stiff source terms such as the atomic level population transition rates) \citep[e.g.][]{Ascher1995}, or accepting the cost of an explicit discretisation in exchange for simplicity and accuracy \citep{Bradshaw2003, Bradshaw2013}.

Recently, discussion has emerged around the concept of turbulence suppressed conduction \citep{Bian2016}, where turbulence restricts the motion of electrons along the loop, and it has been suggested that the standard assumption of collisionally-dominated conduction may be a significant overestimation of true conduction rates.
Simulations using the zero-dimensional enthalpy based EBTEL code \NeedRef{} currently suggest that this turbulent suppression alone is insufficient to maintain the high coronal temperatures and slow cooling times seen in observations, but likely represents an important component of this effect \citep{Bian2018}.
As part of further investigation, work is currently under way to integrate these effects in the \Radyn{} and HYDRAD codes.

\section{A Brief Dissection of \Radyn{} and a Possible Future of RHD Modelling}\label{Sec:RadynDissection}

\emph{This section is informed by my discussions with Mats Carlsson, experiences using \Radyn{}, and in-depth analysis of its source code. It represents my own conclusions from the synthesis of these.}

\Radyn{}'s design closely follows its radiative transfer lineage. Its direct predecessor is the MULTI radiative transfer code \citep{Carlsson1992}\NeedRef{} and many commonalities remain.
NLTE radiative transfer is solved on a per transition basis using an ALI method and linearisation of the resultant level population balance equations.
This method is designed to solve the problem of non-overlapping lines but including an underlying background continuum.
This linearisation approach was proven by \citet{SocasNavarro1997} to be effectively equivalent to that of preconditioning for non-overlapping transitions \citep{Rybicki1991} for pure radiative transfer problems in the statistical equilibrium case.
This approach also assumed the use of a local diagonal $\Lambda^*$ operator, as discussed in the previous chapter.
\Radyn{}, however, chooses to employ a pentadiagonal $\Lambda^*$ operator to make optimal use of matrix bandwidth necessary elsewhere in the program and obtain improved convergence as a result.
It is unlikely that this change in operator significantly affects the conclusions of \citet{SocasNavarro1997}, but the two methods will no longer arrive at exactly equivalent numerical formulations.
\Radyn{} also uses an efficient Feautrier formalism for its formal solver, which solves for both the up- and down-going rays simultaneously but cannot handle both overlapping lines and Doppler shifts.
There are no lines with significant overlap considered in the standard model atoms used in \Radyn{}, and continuum emissivities and opacities rarely change sufficiently over the wavelength range of a line to need to be considered in a wavelength varying sense.
This is likely fair trade-off for \Radyn{} given the computational benefits it can bring.

The advantage of the linearisation approach in \Radyn{} is the ability to directly couple other equations to the RTE and implicitly solve all of these simultaneously and self-consistently.
Taking for example the kinetic equilibrium equation \eqref{Eq:KinEq}, \Radyn{}'s method formulates this expression such that the corrections from both the advection and population transition terms are considered simultaneously.
This is achieved through the use of a Newton-Raphson method, where the Jacobian is computed based on an analytic derivation, including the aforementioned linearisation of the kinetic equilibrium equations.
This same process simultaneously solves for the population updates, heat conduction, hydrodynamics of the system, and the new locations of the dynamic grid of \citet{Dorfi1987}.

A significant benefit of this implicit approach is a relaxation of the timestep constraints present in explicit approaches.
This is particularly important when considering the very fine grid spacing often required by the dynamic grid, which, combined with the large bulk velocities occurring in flares can lead to extremely oppressive timestep constraints.

Despite its elegance, there are several major downsides to this implicit approach.
Foremost of these is the complexity engendered by the coupled design of the system, and the need to ensure that all necessary derivatives are analytically derived and correctly computed.
This presents a very large barrier to entry for future developments on the platform, and this is likely part of the reason why both Fokker-Planck modules integrated in \Radyn{} have operated externally to this core coupled system.
Additionally, implicit codes, whilst having less severe timestep constraints, are typically much more costly per timestep than explicit codes.
This is somewhat offset by the majority of the cost of each step residing within the formal solver, which remains similar in both cases.
The dynamic grid can also become problematic due its lack of interpretability, and propensity to drop to spacings finer than the local cyclotron radius in more energetic simulations.
On these scales the assumptions that allow us to treat the plasma as an ideal fluid begin to break down.

\Radyn{} is a fantastic tool that has enabled insight into many different flare associated phenomena, and through these comments we do not intend to discredit its use, but instead highlight avenues for future development within the field of RHD.
As the different uses of \Radyn{} continue to evolve in complexity, with projects such as multi-strand arcade and minority species modelling \NeedRef{}, the code at the core of \Radyn{} will need to be modified by different researchers, and work facilitating this and highlighting additional factors to be considered in RHD modelling is core to the future development of this field.

As discussed previously in respect to \Lw{} and radiative transfer, the flexibility of a framework designed for solving a class of problem can yield significant advances in productivity.
The task of designing, constructing, and testing a framework for a problem as complex as the complete quasi-one-dimensional RHD simulation of flares is too significant to be undertaken here.
Nevertheless, it may prove a powerful future development once the necessary specifications are defined.
In the following we focus on reprocessing aspects of the radiative transfer of previously computed \Radyn{} simulations and investigating important directions for future developments in RHD modelling of flares.

\section{Minority Species}

For flares, \Radyn{}'s primary focus is on the major spectral lines and continua of hydrogen, helium, and calcium.
These typically represent the bulk of the radiative energy lost in the chromosphere.
Singly ionised magnesium has also been shown to be an important contributor to these energy losses, however the h and k lines require a treatment including PRD to avoid significantly overestimating their losses.
The \Caii{} H and K lines are also somewhat affected by PRD, in addition to the hydrogen Lyman lines.
For the Lyman lines we will discuss several strategies for approximating this treatment, and for \Caii{} H and K, it has been suggested that considering these in CRD approximately accounts for the lack of Mg\,\textsc{ii} h and k if all of these transitions were treated with PRD \citep{Kerr2019a}.

Whilst the lines of these four species are some of the strongest in solar spectrum, and their continua mediate much of the energy leaving the chromosphere, there are other chromospheric transitions that can also be used to diagnose the atmosphere.
For example, Si\,\textsc{iv} optical thickness has been investigated in a minority species context by \citet{Kerr2019c}.
An element treated as a ``minority species'' is assumed to not interact significantly with the energy balance of the simulation (i.e. the thermodynamic response of the model does not change significantly if this species is subject to a complete radiative treatment).
This should be true for most species with trace populations.
The radiative transfer calculations associated with this species can then be performed in a ``second-pass'' over a previously computed \Radyn{} simulation.
The MS\_RADYN code was designed for this task; it takes the thermodynamic parameters from every timestep of a \Radyn{} simulation, along with the non-equilibrium hydrogen populations, and solves the kinetic equilibrium equation at each timestep for a minority species.
Due to the lack of atmospheric thermodynamic response to changes in the radiative output of this species, far more complex atomic models can be used, such as the 30 level model silicon atom used by \citet{Kerr2019c}.

An approach similar to that of minority species modelling can be applied to testing the methods used in \Radyn{} and the importance of certain omissions.
Due to the reduced complexity of solving the kinetic equilibrium equations rather than the entire RHD system, these calculations typically run significantly faster than the original simulation.
In the following we will discuss the creation of a minority species tool for reprocessing \Radyn{} simulations, built on the \Lw{} framework, as well as its application to investigating the importance of overlapping transitions and discussing the difficulties of including PRD in these simulations.
From the previous discussion, building such a tool on the \Lw{} framework should provide researchers with a modern, simpler codebase that is easier to conceptualise and modify, allowing for investigation of effects to be included in \Radyn{} or future RHD codes.
Excluding the model atom definitions, the source code of the simulations presented in this chapter totals $\sim$1000 lines of Python, mostly following modern best practices.

This approach could also be applied to a simple investigation of the effects of a magnetic field on the outgoing radiation by imposing an \emph{ad hoc} magnetic field (constant or varying) on the model atmosphere and computing the emergent line profiles, in a much simpler way than a modifying \Radyn{} for this task.

\section{Reprocessing \Radyn{} Simulations with the \Lw{} Framework}

To perform a minority species simulation, a particular file from the original simulation, \texttt{atmost.dat}, must be provided.
From investigating the contents of this file we can determine the exact configuration of \Lw{} and the equations to be solved.
This file is written to for every internal timestep of the \Radyn{} simulation, and represents a limited subset of the less frequently written ``complete'' output (typically stored every \SI{0.1}{\second}).
It contains some metadata describing the size of the simulation, then for each internal timestep, the current timestep, the elapsed time at each timestep, the current locations of the dynamic grid, the mass density profile, the electron density profile, the temperature structure, the vertical velocity, and the current hydrogen level populations.

\TODO{Double check AR rates}
For the validation of \Lw{} and this style of simulation, we also wished to compute and compare the hydrogen populations to those computed in \Radyn{}.
Several difficulties arose due to the non-thermal collisional rates used in the kinetic equilibrium calculation for hydrogen and helium.
The non-thermal collisional rates of \citet{1993Fang} are used to determine hydrogen ionisation, and require the beam energy deposition throughout the atmosphere at each timestep.
For helium, if the Fokker-Planck electron beam description is used, then the rates of \citet{Arnaud1985} are used, but these require integration over the electron energy distribution.
Whilst it is possible to add both of these to the \texttt{atmost.dat} file, the complete electron distribution information is very large, and we instead elect to use ``Emslie'' beam electron formalism \citep{Emslie1978}, for which the energy deposition profile throughout the atmosphere is sufficient to describe the non-thermal rates.
We therefore chose to slightly modify \Radyn{} and add the beam deposition profile to the \texttt{atmost.dat} file.
Our function for reading these files can handle both files with and without this modification.
In the event that this beam heating information is not saved, an approximation of it can be reconstructed via interpolation from the information in \Radyn{}'s complete save file.
Our testing of this show that the approximation is relatively good, but short term, or particularly narrow heating features may be lost.
For this reason, all simulations presented here use the version with this data.

With the above data we have sufficient information to construct the \Radyn{} thermodynamic atmosphere at any of its internal timesteps.
\Lw{} does not make use of the mass density directly, but instead maps it to hydrogen density.
For this we use of the default abundances in \Lw{}, based on \citet{Asplund2009}.
These differ to those used in \Radyn{}, but not significantly for any of the species discussed here.

Ignoring the advection term it is then simple to produce a minority species tool using this approach.
In many situations, the advection term has a small effect, and can safely be ignored \NeedRef{} \TODO{Old Flarix paper}.
The method for advancing the atomic populations in time employed in \Radyn{} is formulated on the dynamic grid, and this is not the case in \Lw{}, which assumes that the grid is static (although this limitation can be worked around).
We can simply use a fixed denser spatial sampling of the atmosphere to account for the motion of features such as the transition region over the course of the simulation.
This model then interpolates the thermodynamic properties and NLTE hydrogen populations for the starting atmosphere onto our stratification and computes the statistical equilibrium solution for the minority species in question.
For each subsequent timestep these properties are interpolated from the new \Radyn{} grid to the static grid, and the minority species populations can be advanced in time using the process described in Sec.~\NeedRef{}.

To reduce the number of grid points needed for a static stratification one could instead use a fixed column mass stratification.
The transition region moves very little in terms of column mass during the simulation, however it then becomes necessary to interpolate the populations from one column mass stratification to the next; a process which can introduce significant error if not undertaken with care.
This error can be reduced by renormalising each specie's total number density throughout the atmosphere from the mass density and abundances, and this helps to avoid errors growing around regions of high gradient, such as the transition region.

To solve the minority species problem properly in a manner compatible with \Radyn{} it is necessary to include the advection terms.
In the following we will describe several different approaches to handling these advection terms, drawing on our previous discussions of hydrodynamics, and thus solving the complete kinetic equilibrium equations.

\subsection{Advection}

In Sec.~\ref{Sec:RadynDissection} we discussed the coupled nature in which \Radyn{} solves the RHD equations.
For flexibility we wish to decouple the advection terms from the radiative effects.
Our initial approach was to use an explicit method on the dense, fixed grid discussed above.
This method is available in the \texttt{Advection} branch of the associated repository \NeedRef{}.
It draws from the simple explicit finite-volume approaches discussed earlier in this chapter, and thus uses a fifth-order WENO-NM scheme for reconstruction and the simple local Lax-Friedrichs flux for estimating the flow of the atomic populations through the simulation.
This numerical scheme performs extremely well in textbook advection and hydrodynamic tests, however it was found to be ill-suited to the long internal timesteps that \Radyn{}'s implicit method chooses.
These timesteps are longer than those permitted by the CFL condition, requiring the explicit method to perform multiple substeps for each of \Radyn{}'s timestep.
This alone can introduce cumulative error, which is further compounded by the use of the dense static grid.
As this grid needs to conform to the requirements of the simulation over its entire evolution, rather than just its instantaneous requirements (as is the case for \Radyn{}'s grid) there are often dense clusters of points in regions where they are not required to resolve the atmospheric structure.
These regions may have high plasma flow velocities, further increasing the timestep restrictions on the explicit method.
In some cases several thousand applications of the explicit scheme were required to match one of \Radyn{}'s internal timesteps.
With such different timestep restrictions imposed on the two components of this simulation, it is difficult to correctly treat both processes in a coupled fashion.

Using this explicit approach for advection, a fair agreement with \Radyn{} was found, but this worsened and a greater proportion of runtime had to be spent on the advection terms, as the energy deposition in simulations increased, and in turn increased the flow speeds and moved the transition region further from its starting altitude.
Due to \Radyn{}'s longer timesteps, during more explosive evaporative phases, the advection scheme was occasionally able to carry chromospheric material through the majority of the transition region.
Whilst the populations quickly evolved in their new environment this process is sufficiently slow to introduce unexpected variability in the line profiles.
A higher order splitting scheme may have helped to mitigate this but would add more computational cost to an already expensive process (due to the shear number of advection steps needed).
This effect can also be mitigated by limiting the maximum timestep that can be taken by \Radyn{} during the creation of the baseline simulation.
However, limiting \Radyn{}'s performance is a poor solution to this problem; the explicit advection method described here could serve well at the core of a code designed around it, in the way that FLARIX and HYDRAD both use similar explicit advection schemes, but many difficulties are created by the difference in ideologies between this and \Radyn{}'s implicit dynamic grid scheme.

To improve the agreement with \Radyn{}, reduce the number of interpolations, and leverage rather than fight its adaptive grid we instead decided to apply its technique for advection, but keep it separate from the radiative transfer.
Thus, at the start of each timestep we advect the populations from the previous grid to the new grid locations, and then advance the populations in time based on the NLTE rates.
This method employs a variant of the second order spatially accurate method of \citet{VanLeer1979} to reconstruct the values on either side of the interface, of which the upwind value is chosen.
This is set within a time-centering scheme similar to that described in Dorfi \NeedRef{}.
Under this scheme the advection stencil depends on the values of five cells, two on either side of the current one.
Thus the Jacobian matrix for this equation is pentadiagonal (and block pentadiagonal for the system of ODEs).
For simplicity and ease of implementation we chose to not directly code the expressions for these derivatives that occur in the Jacobian matrix, but instead compute them by finite differences.
There is an elegant technique that can be used to optimise this process when an equation's region of dependence is known.
This approach is known as Coloured Finite Difference \citep{Curtis1974}; so long as only one point in the domain affecting each output point is perturbed the gradient can be trivially attributed to the correct point.
In essence, we need only perform five additional evaluations of the advection residual, perturbing one point in every five to fill the Jacobian, rather than the traditional approach where each point would be perturbed in turn.
The solution to this system is then computed by a Newton-Raphson iteration with Armijo line search \NeedRef{} to accelerate convergence.
This technique has proven far more suited for reprocessing these simulations than the previous explicit scheme.
Only one application of the method (typically requiring at most five Newton-Raphson iterations) is needed for each timestep and the computational cost is $<0.1\,\%$ of the total CPU time.
This approach remains harder to debug and modify due to its implicit nature, although this is simplified thanks to the finite difference method for computing the Jacobian which does not need to be adjusted if the equations are modified so long as the stencil remains the same.

\section{On the Importance of \Caii{} Photoionisation by the Hydrogen Lyman Lines in Flare Models}

\emph{The content of this section is based on the work presented in \Caii{} paper \NeedRef{}.}

The methods discussed above can be used to reprocess the radiative transfer aspects of \Radyn{} simulations and thus investigate the effects of the Lyman lines on \Caii{} photoionisation in these models.
In \Radyn{} the photoionisation of \Caii{} by the hydrogen Lyman continuum is considered, but the effects of the Lyman lines are not.
The hydrogen Lyman lines are strongly enhanced in flares, and a two dex enhancement relative to quiet sun intensity was found by \citet{RubioDaCosta2009} using observations from the Transition Region and Coronal Explorer (TRACE).
RHD modelling using \Radyn{} has also suggested that enhancements at least this large are to be expected in this line \citep{Brown2018, Hong2019}.
Fig.~\ref{Fig:CaIIOverlaps} shows the the overlap between the hydrogen Lyman transitions and the \Caii{} continua present in our model.
Radiation from Ly$\alpha$ photoionises \Caii{} from all levels other than the ground state.
All of the other Lyman transitions present can photoionise \Caii{} to \Caiii{} from all levels present in this model.
Additionally, in flaring conditions, the higher lines of the Lyman sequence are significantly Stark broadened and create a quasi-continuum between Ly$\delta$ and the Lyman continuum \citep{DeFeiter1975}, which will further enhance the photoionisation of \Caii{} from what is considered in our model.
These highly enhanced transitions therefore provide an important mechanism for the photoionisation of \Caii{} to \Caiii{} and in the following we will investigate the effect this has on both the emergent line profiles and the radiative losses of several RHD models.
These effects have long been considered in prominence modelling, starting with the work of \citet{Ishizawa1971}, however we are not aware of any previous detailed investigation of these effects in RHD modelling of flares, where the Lyman transitions become so significantly enhanced.

%spell-checker: disable
\begin{pycode}[TimeDepRT]
from MsLightweaverAtoms import H_6, CaII
from matplotlib.patches import Rectangle
from weno4 import weno4

# plt.ion()
H = H_6()
Ca = CaII()
fig = plt.figure(figsize=texfigure.figsize(pytex, scale=1, height_ratio=0.55))
ax = plt.gca()

# C1 = '#EECC66'
# C2 = '#6699CC'
C1 = 'C1'
C2 = 'C0'

lineLabels = [r'Ly$\alpha$', r'Ly$\beta$', r'Ly$\gamma$', r'Ly$\delta$']
lineIdx = 0
for l in H.lines:
    if l.i != 0:
        continue
    plt.axvline(l.lambda0, c=C1)
    ha = 'center' if lineIdx != 2 else 'left'
    ax.annotate(lineLabels[lineIdx], xy=(l.lambda0, 1), xytext=(-1, 6),
                xycoords=ax.get_xaxis_transform(), textcoords='offset points', ha=ha, fontsize='small')
    lineIdx += 1

caLabels = [
    r'Ca\textsc{ii} 3p$^6$ 4s – Ca\textsc{iii}',
    r'Ca\textsc{ii} 3p$^6$ 4p – Ca\textsc{iii}',
    r'Ca\textsc{ii} 3p$^6$ 3d – Ca\textsc{iii}']
labelIdx = 0
for i, c in enumerate(Ca.continua[::2]):
    patch = Rectangle((c.minLambda, i-0.25), c.lambdaEdge - c.minLambda, 0.5, fc=C2, alpha=0.7)
    ax.add_patch(patch)
    ax.annotate(caLabels[labelIdx], xy=(c.lambdaEdge + 1, i), va='center', fontsize='small')
    labelIdx += 1
plt.ylim(-0.25, len(Ca.continua[::2])-0.75)
plt.xlim(80, 160)

c = H.continua[0]
patch = Rectangle((c.minLambda, -0.25), c.lambdaEdge - c.minLambda, 5, fc=C1,
                  alpha=0.5, hatch='/', ec=C1, lw=0.0)
ax.add_patch(patch)
plt.axvline(c.lambdaEdge, c=C1, ls='--', alpha=0.8)
ax.annotate('← LyC', xy=(c.lambdaEdge, 1), xytext=(-5, 6),
            xycoords=ax.get_xaxis_transform(), textcoords='offset points', ha='center', fontsize='small')

# yticks = np.arange(5)
# plt.yticks(yticks, ['A', 'B', 'C', 'D', 'E'])
plt.yticks([],[])

plt.xlabel(r"$\lambda$ [nm]")
plt.tight_layout()
lFig = chRT.save_figure('CaIIOverlaps', fig, fext='.pgf')
lFig.caption = r'The overlap betwen the hydrogen Lyman lines and continuum with the Ca\,\textsc{ii} continua present in the model atom used here. Both the Ca\,\textsc{ii} 3p$^6$ 4p and 3p$^6$ 3d levels contain two sub-levels with indistinguishably different continuum edges.'
lFig.placement = 'hbtp'
\end{pycode}

\py[TimeDepRT]|chRT.get_figure('CaIIOverlaps')|
%spell-checker: enable

The hydrogen (five bound levels with H\,\textsc{ii} continuum and ten lines), helium, and calcium (five bound \Caii{} levels with \Caiii{} continuum and five lines) model atoms used in the simulations presented here are the same as those used in \Radyn{}.
All other model atoms used in the LTE background opacities are taken from the \Lw{} standard library (and have in turn been converted from  RH distribution \citep{Uitenbroek2001}).
Currently only the hydrogen and calcium populations are considered in the NLTE treatment.

To determine the importance of the photoionisation by the Lyman lines, each \Radyn{} simulation is reprocessed twice, once including the effects of the Lyman lines on \Caii{} (henceforth Lyman inclusive (LI)), and once without these effects (Lyman exclusive (LE)).
This is achieved through the use of two different hydrogen model atoms.
In both cases the effects of the Lyman continuum are included, as this is commonly considered in RHD codes, and allows for direct comparison of the LE simulation against \Radyn{}.
The simulations are performed using the CRD formalism for consistency with \Radyn{}, although the models used for the Lyman lines contain an approximation to PRD by removing radiative broadening and reducing van der Waals broadening.
This makes line profile closer to a Doppler profile, by reducing the importance of the Lorentzian wings.
This is one of the two more common approaches to approximating PRD effects in these transitions, the other being to truncate the line quadrature around ten Doppler widths from the line core.
Both of these are empirical but we favour the former in flare simulations as the narrow grid used in the latter can easily ``lose'' opacity in the moderate to high Doppler shifts that occur in flare models (Carlsson 2021, \emph{private communication}).
PRD effects are also present in the \Caii{} lines (primarily the resonance lines, although cross-redistribution effects also affect the infra-red triplet).
The effects on these are typically less significant than those on the hydrogen Lyman lines, especially due to the high chromospheric densities that occur during flares.
We therefore do not add any approximate PRD treatments to the \Caii{} lines.
These model atoms are therefore identical between \Radyn{} and \Lw{}, and the two models differ only in their description of LTE background opacities, which in the case of the \Lw{} simulations includes helium.
Comparison of these simulations should therefore enable the study of these photoionisation effects.

Our \Lw{}-based tool uses the first-order splitting technique discussed in Sec.~\ref{Sec:HydroStability}.
The complete kinetic equilibrium equations are split into radiative and advective operators that are applied sequentially.
A Strang-splitting approach was trialled but provided no noticeable difference in the solution over this first-order technique and whilst being more computationally costly than the simpler approach.
After solving the statistical equilibrium problem to determine an initial solution for the atomic populations in the given starting atomsphere, the populations are then advected, and the thermodynamic atmospheric parameters are updated using the \Radyn{} data from the next timestep.
This update process includes the calculation of the LTE populations of all species considered and computing the resultant background opacities.
The atomic level populations are then advanced in time using the approach described in \NeedRef{}.

\subsection{The \Radyn{} simulations}

For this investigation two \Radyn{} simulations were used.
Their parameters were chosen to serve as typical simulations, and were based on those used by \citet{Kerr2019, Kerr2019a}.
The same starting atmosphere derived from VAL3C \citep{Vernazza1981} as used in the F-CHROMA grid of simulations was used.
As previously discussed, the ``Emslie'' beam formalism was chosen over the Fokker-Planck for ease of reconstructing any non-thermal rates that might be needed.
The spectral index used for the power-law distribution of electron energies was $\delta=5$, with a low-energy cut-off of \SI{20}{\kilo\electronvolt}.
The two simulations differed only in energy deposition, which was a constant flux for \SI{10}{\second} of $1\times 10^{6}$ or \SI{1e7}{\joule\per\square\metre\per\second} \footnote{In the cgs units that are commonly adopted for \Radyn{} simulations these represent $1\times 10^9$ and \SI{1e10}{\erg\per\square\centi\metre\per\second}}.
These simulations will be referred to as F9 and F10 respectively.

All of these parameters fall within the range of those used in the F-CHROMA grid, other than the beam energy flux which is lower than the peak fluxes used in the grid.
This is primarily due to the triangular \SI{20}{\second} duration heating profile used which is less demanding on the simulation than the constant deposition used in our simulations.
Our choice of parameters are also supported by observational data.
The low-energy cut-off is in accord with the findings of \citet{Sui2007} whose analysis of 33 early impulsive flares using the Ramaty High Energy Solar Spectroscopy Imager (RHESSI) found a range of 10-\SI{50}{\kilo\electronvolt} whilst accounting for X-ray albedo and under the assumption of a cold collisional thick target model.
Another study of 53 flares using RHESSI by \citet{Saint-Hilaire2008} found that the photon spectral index $\gamma$ was distributed between 2 and 5, peaking between 3 and 3.5.
Given this, our choice of spectral index is reasonable and lies well inside this distribution as the spectral index of the electron beam is related to the photon spectral index by $\delta = \gamma + 1$.

For both of these simulations \Radyn{}'s coronal irradiation terms were disabled due to discrepancies that were found between the implementation of these in \Radyn{} and \Lw{}.
Additionally, the maximum timestep allowed in \Radyn{} was limited to \SI{0.01}{\second}.
This was primarily due to experiments with the explicit advection scheme, but likely also improved the accuracy of the operator splitting used in our final reprocessed simulations.

\subsection{Line Profiles}\label{Sec:TimeDep8542Profiles}

%spell-checker: disable
\begin{pycode}[TimeDepRT]
import zarr
from matplotlib.ticker import MultipleLocator, AutoMinorLocator
from MsLightweaverAtoms import CaII
import astropy.units as u
import lightweaver as lw
from radynpy.cdf import LazyRadynData

# Get the RADYN intensity for a line down a particular direction; in SI
def line_intensity_with_cont(data, kr, muIdx):
    if not not data.cont[kr]:
        print('line_intensity cannot compute bf intensity')
        return

    wl = data.alamb[kr] / (data.q[0:data.nq[kr], kr] *  data.qnorm * 1e5 / data.cc + 1)
    intens = (data.outint[:, 1:data.nq[kr]+1, muIdx, kr] + data.outint[:, 0, muIdx, kr][:, np.newaxis]) *  data.cc * 1e8 / (wl**2)[np.newaxis, :]
    print(intens.shape)
    # wl is retruned in angstrom, intens in erg/cm^2/sr/A/s
    wl = wl[::-1] << u.Angstrom
    intens = lw.utils.convert_specific_intensity(wl, intens[:, ::-1] << u.erg / u.cm**2 / u.sr / u.Angstrom / u.s, 'J/m2/sr/Hz/s')

    return wl << u.nm, intens

def plot_8542_profiles(liData, leData, radyn):
    plotTimes = [5, 11, 20, 40]
    fig, ax = plt.subplots(1, 4, figsize=texfigure.figsize(pytex, scale=1, height_ratio=0.40),
                           sharex=True, sharey=True,
                           gridspec_kw={'wspace': 0.1, 'width_ratios':[1,1,1,1]})
    fig.subplots_adjust(left=0.12, right=0.99)
    ax = ax.ravel()

    lineData = line_intensity_with_cont(radyn, 20, -1)
    waveRange = (854.3444, 854.5444)
    ca = CaII()
    wavelength = liData['wavelength'][...]
    wavelengthLE = leData['wavelength'][...]
    for i, time in enumerate(plotTimes):
        lwIdx = np.searchsorted(liData['time'], time)
        radynIdx = np.searchsorted(radyn.time, time)
        lambda0 = ca.lines[-1].lambda0

        if i == 0:
            ax[i].plot(lineData[0].value - lambda0, lineData[1][radynIdx], label='RADYN')
            ax[i].plot(wavelength - lambda0, liData['Iwave'][lwIdx, :, -1], '--', label='Lightweaver LI')
            ax[i].plot(wavelengthLE - lambda0, leData['Iwave'][lwIdx, :, -1], '--', label='Lightweaver LE')
        else:
            ax[i].plot(lineData[0].value - lambda0, lineData[1][radynIdx])
            ax[i].plot(wavelength - lambda0, liData['Iwave'][lwIdx, :, -1], '--')
            ax[i].plot(wavelengthLE - lambda0, leData['Iwave'][lwIdx, :, -1], '--')

        ax[i].set_title('{:.2f} s'.format(time))
        ax[i].xaxis.set_minor_locator(AutoMinorLocator())

    ax[0].set_yscale('log')
    ax[0].set_ylim(1e-8, 1.3e-7)
    ax[0].set_xlim(-0.08, 0.08)

    ax[0].yaxis.offsetText.set_visible(False)
    ax[0].set_ylabel('Specific Intensity [SI]')
    for a in ax:
        a.set_xlabel('$\Delta\lambda$ [nm]')
    fig.subplots_adjust(bottom=0.15)
    fig.legend(*ax[0].get_legend_handles_labels(), loc=(0.80,0.66), frameon=False,
               handletextpad=0.5, handlelength=1.5, fontsize=9)#, bbox_to_anchor=(0.5,0.53))
#     fig.savefig('LineProfiles1e10_8542.png', dpi=300)
    return fig

from radynpy.cdf import LazyRadynData
radyn = LazyRadynData(chRT.data_file('Flat1e9NoIncRad/radyn_out.cdf'))
liData = zarr.convenience.open(chRT.data_file('Flat1e9NoIncRad/Flat1e9NoIncRadLIThesis.zip'), 'r')
leData = zarr.convenience.open(chRT.data_file('Flat1e9NoIncRad/Flat1e9NoIncRadLEThesis.zip'), 'r')
fig = plot_8542_profiles(liData, leData, radyn)
lFig = chRT.save_figure('F9Profiles', fig, fext='.pgf')
lFig.caption = r'Comparison of the LI, LE, and RADYN Ca\,\textsc{ii} \SI{854.2}{\nano\metre} line profiles during the F9 simulation.'

radynF10 = LazyRadynData(chRT.data_file('Flat1e10NoIncRad/radyn_out.cdf'))
liDataF10 = zarr.convenience.open(chRT.data_file('Flat1e10NoIncRad/Flat1e10NoIncRadLIThesis.zip'), 'r')
leDataF10 = zarr.convenience.open(chRT.data_file('Flat1e10NoIncRad/Flat1e10NoIncRadLEThesis.zip'), 'r')
fig = plot_8542_profiles(liDataF10, leDataF10, radynF10)
lFig = chRT.save_figure('F10Profiles', fig, fext='.pgf')
lFig.caption = r'Comparison of the LI, LE, and RADYN Ca\,\textsc{ii} \SI{854.2}{\nano\metre} line profiles during the F10 simulation.'
\end{pycode}
\py[TimeDepRT]|chRT.get_figure('F9Profiles')|
\py[TimeDepRT]|chRT.get_figure('F10Profiles')|
%spell-checker: enable

The \CaLine{} line profile from 5, 11, 20, and \SI{40}{\second} after the onset of heating in the F9 and F10 simulations is shown in Figs.~\ref{Fig:F9Profiles} and \ref{Fig:F10Profiles} respectively.
These figures show the comparison of the LI and LE treatments, as well as the reference line profiles computed by \Radyn{}.
Despite the different formal solvers and numerical techniques, the agreement between the \Radyn{} and LE profiles is extremely good, differing by a few percent at most.
There are substantial differences between the LI and LE models; in the F9 simulation the LI line profile is narrower, consistently double-peaked, and less intense than the LE profile, which is much more variable, including becoming singly-peaked after the heating ends ($t=11$ and \SI{20}{\second}), before returning to a double-peaked shape at later times in the simulation.

The differences in the outgoing radiation in the F10 case are still significant, but perhaps a little less dramatic than the F9 case.
The LI peak intensity is significantly reduced relative to the LE line profile in the $t=\SI{5}{\second}$ plot, and post-heating ($t=\SI{11}{\second}$) the asymmetry of the double-peaked profiles is reversed between the LI and LE treatments.
At $t=\SI{20}{\second}$ the situation is similar to the F9 simulation; the LE treatment produces a singly-peaked line profile, whilst the LI treatment produces an asymmetric double-peaked profile (due to the appearance of a secondary peak on the violet wing).
At later times there is a significant dip in the far violet wing for the LE treatment that is not present in the LI treatment.
This dip varies slowly in position and depth over the evolution of the cooling phase.

We can investigate the formation of these line profiles by looking at the contribution functions, and the atomic level populations associated with these spectral lines.
From Figs.~\ref{Fig:F9Profiles} and \ref{Fig:F10Profiles}, we consider that the difference between the two treatments is most significant at $t=11$ and \SI{20}{\second}.
The contribution functions and associated atomic level populations for these two times in both of the simulations are plotted in Figs.~\ref{Fig:F9ContFn11s}-\ref{Fig:F10ContFn20s}.



%spell-checker: disable
\begin{pycode}[TimeDepRT]
from ReadAtmost import read_atmost
from lightweaver.rh_atoms import H_6_atom, C_atom, O_atom, OI_ord_atom, Si_atom, Al_atom, Fe_atom, FeI_atom, MgII_atom, N_atom, Na_atom, S_atom, CaII_atom, He_9_atom
from MsLightweaverAtoms import H_6, CaII, H_6_nasa, CaII_nasa, H_6_nobb
from lightweaver.LwCompiled import FastBackground
from weno4 import weno4
from matplotlib.colors import LogNorm, SymLogNorm
from contextlib import redirect_stdout
import os

atmost = read_atmost(chRT.data_file('Flat1e9NoIncRad/atmost.dat'))
atmost.to_SI()
atmostF10 = read_atmost(chRT.data_file('Flat1e10NoIncRad/atmost.dat'))
atmostF10.to_SI()

# Set up atmosphere with data from initial timestep
nHTot = atmost.d1 / (lw.DefaultAtomicAbundance.massPerH * lw.Amu)
atmos = lw.Atmosphere.make_1d(scale=lw.ScaleType.Geometric, depthScale=np.copy(atmost.z1[0]),
                              temperature=np.copy(atmost.tg1[0]), vlos=np.copy(atmost.vz1[0]),
                              vturb=np.copy(atmost.vturb), ne=np.copy(atmost.ne1[0]), nHTot=np.copy(nHTot[0]))
atmos.quadrature(5)
FchromaAtoms = [H_6(), CaII(), He_9_atom(), C_atom(), O_atom(), Si_atom(), Fe_atom(),
                MgII_atom(), N_atom(), Na_atom(), S_atom()]

# Set up our atoms and Lightweaver context
aSet = lw.RadiativeSet(FchromaAtoms)
aSet.set_active('H', 'Ca')
spect = aSet.compute_wavelength_grid()
eqPops = aSet.compute_eq_pops(atmos)
def fast_background(*args, Nthreads=12):
    return FastBackground(*args, Nthreads=Nthreads)
ctx = lw.Context(atmos, spect, eqPops, initSol=lw.InitialSolution.Lte, conserveCharge=False, Nthreads=12, backgroundProvider=fast_background)
ctx.depthData.fill = True

# Add the extra information expected by our Atoms with Fang non-thermal beam collisional rates
atmos.bHeat = np.ones_like(atmost.bheat1[0]) * 1e-20
atmos.hPops = eqPops['H']

# An omission from Lightweaver (will be added in a later version), computes tau from the complete chi array
def compute_tau(ctx, mu):
    upDown = 1
    tau = np.zeros_like(ctx.depthData.chi[:, mu, upDown, :])
    chi = ctx.depthData.chi
    atmos = ctx.kwargs['atmos']

    # NOTE(cmo): Compute tau for all wavelengths
    tau[:, 0] = 1e-20
    for k in range(1, tau.shape[1]):
        tau[:, k] = tau[:, k-1] + 0.5 * (chi[:, mu, upDown, k] + chi[:, mu, upDown, k-1]) \
                                      * (atmos.height[k-1] - atmos.height[k]) / atmos.muz[mu]
    return tau

# Load the data from a particular timestep into the Lightweaver context
def load_timestep(atmost, file, idx):
    nHTot = atmost.d1 / (lw.DefaultAtomicAbundance.massPerH * lw.Amu)
    internalIdx = np.searchsorted(atmost.time, file['time'][idx])
    atmos.temperature[:] = atmost.tg1[internalIdx]
    atmos.vlos[:] = atmost.vz1[internalIdx]
    atmos.ne[:] = atmost.ne1[internalIdx]
    atmos.nHTot[:] = nHTot[internalIdx]
    atmos.bHeat[:] = atmost.bheat1[internalIdx]

    atmos.height[:] = atmost.z1[internalIdx]

    for name, pops in file['eqPops'].items():
        if 'n' in pops.keys():
            eqPops.atomicPops[name].pops[:] = pops['n'][idx]
        eqPops.atomicPops[name].nStar[:] = pops['nStar'][idx]
    atmos.ne[:] = file['ne'][idx]
    ctx.update_deps()

# Support functions for plotting the contribution function
def scale_cfn(cfn, scaleLimits=None):
    cfnLog = cfn
    if scaleLimits is None:
        minVal = np.min(cfnLog[np.isfinite(cfnLog)])
        maxVal = np.max(cfnLog[np.isfinite(cfnLog)])
    else:
        minVal = scaleLimits[0]
        maxVal = scaleLimits[1]
    cfnLog = np.clip(cfnLog, minVal, maxVal)
    return cfnLog

# Scale a line profile to overlie the contfn
def scale_profile(wavelengthGrid, profile, wavelengthRange, scaleRange):
    minIdx = np.searchsorted(wavelengthGrid, wavelengthRange[0])
    maxIdx = np.searchsorted(wavelengthGrid, wavelengthRange[1]) + 1

    profile = np.copy(profile)
    profile -= profile[minIdx:maxIdx].min()
    profile /= profile[minIdx:maxIdx].max()
    profile *= (scaleRange[1] - scaleRange[0])
    profile += scaleRange[0]
    return profile

# Compute the tau=1 line via interpolation
def tau1_line(tau, z):
    tau1 = np.zeros(tau.shape[0])

    for la in range(tau.shape[0]):
        tau1[la] = weno4(1.0, tau[la], z)

    return tau1

def quiet_pls(fn, *args, **kwargs):
    with open(os.devnull, 'w') as devnull:
        with redirect_stdout(devnull):
            return fn(*args, **kwargs)

def plot_cfn(timeToPlot, liData, leData, atmost):
    lwIdx = np.searchsorted(liData['time'], timeToPlot)
    internalIdx = np.searchsorted(atmost.time, liData['time'][lwIdx])

    wavelength = liData['wavelength'][...]
    wavelengthLE = leData['wavelength'][...]
    # Use ctx for LI case
#     load_timestep('TimestepsAdvNrLosses/', lwIdx)
    def load_iter_ctx(data, idx):
        load_timestep(atmost, data, idx)
        for i in range(10):
            dJ = ctx.formal_sol_gamma_matrices()
            if dJ < 1e-3:
                break
    quiet_pls(load_iter_ctx, liData, lwIdx)

    fullNe = np.copy(ctx.kwargs['atmos'].ne)
    fullTau = compute_tau(ctx, mu=-1)
    fullCfn = lw.compute_contribution_fn(ctx, mu=-1)
    caPopsFull = np.copy(ctx.eqPops['Ca'])

    # LE case
    quiet_pls(load_iter_ctx, leData, lwIdx)

    noLybbNe = np.copy(ctx.kwargs['atmos'].ne)
    noLybbTau = compute_tau(ctx, mu=-1)
    noLybbCfn = lw.compute_contribution_fn(ctx, mu=-1)
    caPopsNoLybb = np.copy(ctx.eqPops['Ca'])

    # Now plot
    fig, ax = plt.subplots(1, 3, sharey=True, figsize=texfigure.figsize(pytex, scale=1, height_ratio=0.45),
    gridspec_kw={'wspace':0.1})
    fig.subplots_adjust(left=0.12, right=0.99)

    heightEdges = lw.compute_height_edges(ctx) / 1e6
    wlEdges = lw.compute_wavelength_edges(ctx)

    minVal = max(np.min(noLybbCfn), np.min(fullCfn))
    maxVal = max(np.max(noLybbCfn), np.max(fullCfn))

    fullCfnLog = scale_cfn(fullCfn, scaleLimits=None)
    noLybbCfnLog = scale_cfn(noLybbCfn, scaleLimits=None)
    ca = CaII()
    line = ca.lines[-1]
    lambda0 = line.lambda0
    waveRange = (-0.1, 0.1)
    waveRangeFull = (854.3444, 854.5444)
    lowerIdx = np.searchsorted(wlEdges-lambda0, waveRange[0]) - 1
    higherIdx = np.searchsorted(wlEdges-lambda0, waveRange[1]) + 1
    ax[0].pcolormesh(wlEdges[lowerIdx:higherIdx]-lambda0, heightEdges, fullCfn.T[:, lowerIdx:higherIdx], cmap='Blues', norm=SymLogNorm(linthresh=5e-14, vmin=1e-20, vmax=maxVal), rasterized=True)
    ax[1].pcolormesh(wlEdges[lowerIdx:higherIdx]-lambda0, heightEdges, noLybbCfn.T[:, lowerIdx:higherIdx], cmap='Blues', norm=SymLogNorm(linthresh=5e-14, vmin=1e-20, vmax=maxVal), rasterized=True)

    ax[0].set_xlim(*waveRange)
    ax[1].set_xlim(*waveRange)
    ax[0].set_ylim(None, 2.4)

    tau1LI = tau1_line(fullTau, atmost.z1[internalIdx] / 1e6)
    tau1LE = tau1_line(noLybbTau, atmost.z1[internalIdx] / 1e6)
    ax[0].plot(wavelength-lambda0, scale_profile(wavelength, liData['Iwave'][lwIdx, :, -1], waveRangeFull, ax[0].get_ylim()), alpha=0.5)
    ax[0].plot(wavelength-lambda0, tau1LI, 'r', alpha=0.5)
    ax[1].plot(wavelengthLE-lambda0, scale_profile(wavelengthLE, leData['Iwave'][lwIdx, :, -1], waveRangeFull, ax[0].get_ylim()), '--', alpha=0.5)
    ax[1].plot(wavelength-lambda0, tau1LE, 'r', alpha=0.5)

    ax[2].semilogx(caPopsFull[line.j], atmost.z1[internalIdx] / 1e6, c='C0', label='upper')
    ax[2].semilogx(caPopsFull[line.i], atmost.z1[internalIdx] / 1e6, c='C1', label='lower')
    ax[2].semilogx(caPopsNoLybb[line.j], atmost.z1[internalIdx] / 1e6, '--', c='C0')
    ax[2].semilogx(caPopsNoLybb[line.i], atmost.z1[internalIdx] / 1e6, '--', c='C1')
    ax[2].semilogx(caPopsFull[-1], atmost.z1[internalIdx] / 1e6, c='C3', label=r'Ca \textsc{iii}')
    ax[2].semilogx(caPopsNoLybb[-1], atmost.z1[internalIdx] / 1e6, '--', c='C3')
    ax[2].semilogx(caPopsNoLybb[-1][0], atmost.z1[internalIdx][0] / 1e6, 'C2', label='Temperature')

    ax[2].tick_params(axis='x', which='both')
    ax[0].set_xticks([-0.05, 0, 0.05])
    ax[0].xaxis.set_minor_locator(AutoMinorLocator())
    ax[1].set_xticks([-0.05, 0, 0.05])
    ax[1].xaxis.set_minor_locator(AutoMinorLocator())
    ax3 = ax[2].twiny()
    fig.subplots_adjust(top=0.82, bottom=0.18, hspace=0.5)
    ax3.semilogx(atmost.tg1[internalIdx], atmost.z1[internalIdx] / 1e6, c='C2')
    ax3.set_xlabel('T [K]', c='C2')
    ax[2].set_xlabel('Number Density [m$^{-3}$]')
    ax[0].set_xlabel('$\lambda$ [nm]')
    ax[1].set_xlabel('$\lambda$ [nm]')
    ax[0].set_ylabel('Height [Mm]')
    ax[0].set_title('Full treatment', size=11)
    ax[1].set_title('Lyman lines excluded', size=11)
    # for a in ax:
    #     a.tick_params(which='both', direction='in')
    # ax3.tick_params(which='both', direction='in')
    leg = fig.legend(*ax[2].get_legend_handles_labels(), loc=(0.75,0.23), frameon=False, handletextpad=0, handlelength=0)#, bbox_to_anchor=(0.5,0.53))
    legLines = leg.get_lines()
    for line in legLines:
        line.set_linestyle(' ')

    for handle, label in zip(leg.legendHandles, leg.texts):
        label.set_color(handle.get_color())
    fig.suptitle('Time: {:.2f} s'.format(atmost.time[internalIdx]))
    cfnData = {'LI': fullCfn.T[:, lowerIdx:higherIdx], 'LE': noLybbCfn.T[:, lowerIdx:higherIdx],
               'wavelengthEdges': wlEdges[lowerIdx:higherIdx]-lambda0, 'heightEdges': heightEdges, 'maxVal': maxVal, 'wavelengthTau1': wavelength - lambda0,
               'tau1LI': tau1LI, 'tau1LE': tau1LE}
    return fig, cfnData
    # fig.savefig('ContFn1e10_8542_%d.png' % atmost.time[lwIdx], dpi=300)

plotTimes = [11.0, 20.0]
F9Cfns = []
for timeToPlot in plotTimes:
    fig, cfnData = plot_cfn(timeToPlot, liData, leData, atmost)
    F9Cfns.append(cfnData)
    lFig = chRT.save_figure('F9ContFn{:.0f}s'.format(timeToPlot), fig, fext='.pgf', dpi=500)
    if timeToPlot == plotTimes[0]:
        lFig.caption = r'Contribution function and level populations for the two calcium treatments in the F9 simulation at $t = \SI{{{:.0f}}}{{\second}}$. The two left-hand panels show the contribution function, overlaid with the line profile in blue and the $\tau_\nu=1$ line in red. The right-hand panel shows the structure of the atmosphere, with populations from the LI treatment shown with solid lines and the LE treatment with dashed lines.'.format(timeToPlot)
    else:
        lFig.caption = r'Contribution function and level populations for the two calcium treatments in the F9 simulation at $t = \SI{{{:.0f}}}{{\second}}$. The panels present the same information as Fig.~\ref{{Fig:F9ContFn{:.0f}s}}.'.format(timeToPlot, plotTimes[0])
    lFig.placement = r'htbp'

F10Cfns = []
for timeToPlot in plotTimes:
    fig, cfnData = plot_cfn(timeToPlot, liDataF10, leDataF10, atmostF10)
    F10Cfns.append(cfnData)
    lFig = chRT.save_figure('F10ContFn{:.0f}s'.format(timeToPlot), fig, fext='.pgf', dpi=500)
    lFig.caption = r'Contribution function and level populations for the two calcium treatments in the F10 simulation at $t = \SI{{{:.0f}}}{{\second}}$. The panels present the same information as Fig.~\ref{{Fig:F9ContFn{:.0f}s}}.'.format(timeToPlot, plotTimes[0])
    lFig.placement = r'htbp'
\end{pycode}

\py[TimeDepRT]|chRT.get_figure('F9ContFn11s')|
\py[TimeDepRT]|chRT.get_figure('F9ContFn20s')|
\py[TimeDepRT]|chRT.get_figure('F10ContFn11s')|
\py[TimeDepRT]|chRT.get_figure('F10ContFn20s')|
%spell-checker: enable

The level populations for both treatments are plotted in the right-hand panel of these figures.
The LI and LE treatments produce significantly different populations for the upper and lower levels of the \CaLine{} transition.
The left-hand and centre panels present the contribution functions for the two different treatments with the $\tau_\nu=1$ line overlaid in red.
The $\tau_\nu=1$ line is reliably extended to higher altitudes in the line core of the LE treatment, suggesting that this core is formed in a different location between the two treatments.
There is a significant feature contributing to the violet wing of the LE models around the \SI{1.5}{\mega\metre} region.
In this same region both the upper and lower level populations for the \CaLine{} transition are significantly enhanced over their LI values creating an increase in opacity, whilst keeping the source function approximately constant, leading to the attenuation of radiation from deeper in the atmosphere.
Under the LI treatment we instead see that there is substantially more \Caiii{} in this region, likely due to \Caii{} to \Caiii{} photoionisation from Lyman lines formed in the upper chromosphere and transition region.
In the F10 simulation there is also a significant difference between the \Caiii{} populations computed in the two treatments around the temperature minimum region; this is much deeper than any of the \Caii{} spectral line cores typically form, but is likely due to the same photoionisation process and the effects of the much larger Lyman line intensity that occurs in the F10 model.

\subsection{Radiative Losses}
%spell-checker: disable
\begin{pycode}[TimeDepRT]
import matplotlib.ticker as ticker
from weno4 import weno4
def plot_loss_comparison(liData, leData, radyn):
    # Get the losses from RADYN for the appropriate transitions
    radynCaIdxs = []
    radynHCaIdxs = []
    radynTotIdxs = []

    for kr in range(radyn.ielrad.shape[0]):
        if radyn.ielrad[kr] == 2 and radyn.cont[kr] == 0:
            radynCaIdxs.append(kr)
        if radyn.ielrad[kr] == 1 or radyn.cont[kr] == 0:
            radynTotIdxs.append(kr)
        if str(radyn.atomid[0, radyn.ielrad[kr]-1]).startswith('he') and radyn.cont[kr] == 1 and radyn.alamb[kr] < 900.0:
            radynTotIdxs.append(kr)
        if (radyn.ielrad[kr] == 1 or radyn.ielrad[kr] == 2) and radyn.cont[kr] == 0:
            radynHCaIdxs.append(kr)
        if (radyn.ielrad[kr] == 1) and radyn.cont[kr] == 1:
            radynHCaIdxs.append(kr)
        if str(radyn.atomid[0, radyn.ielrad[kr]-1]).startswith('he') and radyn.cont[kr] == 1 and radyn.alamb[kr] < 900.0:
            radynHCaIdxs.append(kr)

    radynCaLosses = np.sum(np.abs(radyn.cool[:,:,radynCaIdxs]), axis=-1)
    radynAbsCool = np.sum(np.abs(radyn.cool[:,:,radynTotIdxs]), axis=-1)

    fig = plt.figure(figsize=texfigure.figsize(pytex, scale=1, height_ratio=0.45))
    fig.subplots_adjust(left=0.12, right=0.95, top=0.85, bottom=0.15)
    gs = fig.add_gridspec(1, 5, width_ratios=[1, 0.07, 0.18, 1, 0.07], height_ratios=[1])
#     gs.update(left=0.1, right=0.95, wspace=0.2, hspace=0.4)
    caLossesBig = []
    caLossesLEBig = []
    radynCaLossesBig = []
    radynAbsCoolBig = []
    tempInterp = []
    fixedZGrid = np.linspace(radyn.z1[0].min(), 2.5e8, 10000)
    # Get the losses for ~250 timesteps (0.2s cadence)
    for tIdx in range(liData['time'].shape[0]):
        rIdx = np.searchsorted(radyn.time, liData['time'][tIdx])
        tempInterp.append(weno4(fixedZGrid, radyn.z1[rIdx], radyn.tg1[rIdx]))
        caLosses = np.sum(np.abs(np.stack(liData['losses'][tIdx, -5:])), axis=0)
        caLossesLE = np.sum(np.abs(np.stack(leData['losses'][tIdx, -5:])), axis=0)
        caLossesBig.append(weno4(fixedZGrid, radyn.z1[rIdx], caLosses))
        caLossesLEBig.append(weno4(fixedZGrid, radyn.z1[rIdx], caLossesLE))
        radynCaLossesBig.append(weno4(fixedZGrid, radyn.z1[rIdx], radynCaLosses[rIdx]))
        radynAbsCoolBig.append(weno4(fixedZGrid, radyn.z1[rIdx], radynAbsCool[rIdx]))
    caLossesBig = np.stack(caLossesBig)
    caLossesLEBig = np.stack(caLossesLEBig)
    radynCaLossesBig = np.stack(radynCaLossesBig)
    radynAbsCoolBig = np.stack(radynAbsCoolBig)
    tempInterp = np.stack(tempInterp)

    zEdges = np.concatenate(((fixedZGrid[0] + 0.5 * (fixedZGrid[0] - fixedZGrid[1]),),
                    0.5 * (fixedZGrid[1:] + fixedZGrid[:-1]),
                    (fixedZGrid[-1] + 0.5 * (fixedZGrid[-1] - fixedZGrid[-2]),)
                   ))
    timeEdgesRadyn = np.concatenate(((0,), 0.5 * (radyn.time[:-1] + radyn.time[1:])))
    timeEdges = np.concatenate(((0,), 0.5 * (liData['time'][:-1] + liData['time'][1:])))

    ax0 = fig.add_subplot(gs[0])
    cb0 = fig.add_subplot(gs[1])
    ax1 = fig.add_subplot(gs[3])
    cb1 = fig.add_subplot(gs[4])
    lpanel = ((caLossesLEBig - caLossesBig) / (caLossesLEBig)).T
    rpanel = (radynCaLossesBig / radynAbsCoolBig).T
    maxVal = max(lpanel.max(), abs(lpanel.min()))
    mesh0 = ax0.pcolormesh(timeEdges, zEdges / 1e8,
                           lpanel
                           , cmap='RdBu_r', norm=SymLogNorm(linthresh=1e-2, vmax=maxVal, vmin=-maxVal),
                           rasterized=True)
    mesh1 = ax1.pcolormesh(timeEdges, zEdges / 1e8,
                           rpanel
                           , cmap='Spectral_r', vmax=0.4,
                           rasterized=True)
    fig.colorbar(mesh0, cax=cb0)
    fig.colorbar(mesh1, cax=cb1)
    ax0.set_title('Relative change of Ca line losses\nwith LE and LI treatments')
    ax1.set_title('Proportion of total radiative\nlosses due to Ca lines')
    ax0.set_xlabel('t [s]')
    ax1.set_xlabel('t [s]')
    ax0.set_ylabel('Height [Mm]')

    panelData = {'timeEdges': timeEdges, 'zEdges': zEdges / 1e8, 'data': lpanel * rpanel}

    return fig, panelData
    # fig.savefig('Losses1e10_Im.png', dpi=300)
    # with open('F10LossPanels.pickle', 'wb') as pkl:
    #     pickle.dump({'timeEdges': timeEdges, 'zEdges': zEdges / 1e8, 'data': lpanel * rpanel}, pkl)

fig, F9PanelData = plot_loss_comparison(liData, leData, radyn)
lFig = chRT.save_figure('F9LossComparison', fig, fext='.pgf', dpi=500)
lFig.caption = 'Time evolution of the calcium losses in the F9 simulation. The left-hand panel shows the absolute relative change in losses due to the different calcium treatments, and the right-hand panel shows the proportion of the total radiative losses due to the calcium lines.'

fig, F10PanelData = plot_loss_comparison(liDataF10, leDataF10, radynF10)
lFig = chRT.save_figure('F10LossComparison', fig, fext='.pgf', dpi=500)
lFig.caption = 'Time evolution of the calcium losses in the F10 simulation. The left-hand panel shows the absolute relative change in losses due to the different calcium treatments, and the right-hand panel shows the proportion of the total radiative losses due to the calcium lines.'
\end{pycode}
\py[TimeDepRT]|chRT.get_figure('F9LossComparison')|
\py[TimeDepRT]|chRT.get_figure('F10LossComparison')|
%spell-checker: enable

%spell-checker: disable
\begin{pycode}[TimeDepRT]
def plot_loss_variation(F9LossData, F10LossData):
    fig = plt.figure(figsize=texfigure.figsize(pytex, scale=1, height_ratio=0.45))
    fig.subplots_adjust(left=0.12, right=0.92, top=0.85, bottom=0.15)
    gs = fig.add_gridspec(1, 5, width_ratios=[1, 0.07, 0.18, 1, 0.07], height_ratios=[1])
    # gs.update(wspace=0.05)
    ax0 = fig.add_subplot(gs[0])
    cb0 = fig.add_subplot(gs[1])
    ax1 = fig.add_subplot(gs[3])
    cb1 = fig.add_subplot(gs[4])
    maxVal = max(F9LossData['data'].max(), abs(F9LossData['data'].min()))
    mesh0 = ax0.pcolormesh(F9LossData['timeEdges'], F9LossData['zEdges'],
                        F9LossData['data'], cmap='RdBu_r', norm=SymLogNorm(1e-2, vmin=-maxVal, vmax=maxVal), rasterized=True)
    # plt.colorbar()
    maxVal = max(F10LossData['data'].max(), abs(F10LossData['data'].min()))
    mesh1 = ax1.pcolormesh(F10LossData['timeEdges'], F10LossData['zEdges'], F10LossData['data'],
                        cmap='RdBu_r', norm=SymLogNorm(1e-2, vmin=-maxVal, vmax=maxVal),
                        rasterized=True)
    #                        , vmax=0.2)
    fig.colorbar(mesh0, cax=cb0)
    fig.colorbar(mesh1, cax=cb1)
    ax0.set_title('Variation in losses due to calcium\ntreatment in F9 simulation')
    ax1.set_title('Variation in losses due to calcium\ntreatment in F10 simulation')
    ax0.set_xlabel('t [s]')
    ax1.set_xlabel('t [s]')
    ax0.set_ylabel('Height [Mm]')
    return fig
fig = plot_loss_variation(F9PanelData, F10PanelData)
lFig = chRT.save_figure('LossVariation', fig, fext='.pgf', dpi=500)
lFig.caption = r'The absolute relative change of the radiative losses considered here due to the two different calcium treatments in each of the simulations (i.e. the product of the two panels in each of Figs.~\ref{Fig:F9LossComparison} and \ref{Fig:F10LossComparison}).'
\end{pycode}
\py[TimeDepRT]|chRT.get_figure('LossVariation')|
%spell-checker: enable

Whilst the term ``radiative losses'' is often used to describe the effects of radiation on the energy balance of the plasma, these effects are not uniquely negative.
In many regions of the plasma absorption leads to a net gain in plasma energy, especially considering each transition on an independent basis.
It is therefore difficult to immediately assess the effect that a change in radiative loss has on the system.
For this we adopt an absolute relative difference metric computed following
\begin{equation}
    \frac{\sum_{i\in\mathcal{C}}|\mathrm{loss}_{i,\,\mathrm{LE}}| - \sum_{i\in\mathcal{C}}|\mathrm{loss}_{i,\,\mathrm{LI}}|}{\sum_{i\in\mathcal{C}}|\mathrm{loss}_{i,\,\mathrm{LE}}|}
\end{equation}
where $\mathcal{C}$ is the set of calcium lines used on our model atom, and $\mathrm{loss}_i$ is the volumetric radiative loss of transition $i$.
This metric therefore quantifies the effect on the total energy being redistributed throughout the simulation (or leaving the simulation) from the different treatments of the \Caii{} lines.
To assess the importance of this it is also essential to know the importance of the \Caii{} lines on the total energy balance of the simulation.
Thus we also compute
\begin{equation}
    \frac{\sum_{i\in\mathcal{C}}|\mathrm{loss}_{i,\,\mathrm{\Radyn{}}}|}{\sum_j|\mathrm{loss}_{j,\,\mathrm{\Radyn{}}}|},
\end{equation}
which describes the proportion of all radiative losses considered with a detailed NLTE treatment in \Radyn{} (hydrogen, helium, and calcium, lines and continua) due to the calcium lines.
These two metrics are plotted in the left- and right-hand panels respectively of Figs.~\ref{Fig:F9LossComparison} and \ref{Fig:F10LossComparison} for the F9 and F10 simulations respectively.

Looking first at the F9 simulation shown in Fig.~\ref{Fig:F9LossComparison}, there is a significant difference between the calcium losses in the two treatments during heating (0--\SI{10}{\second}).
This is not surprising given the difference in the outgoing profiles shown in Fig.~\ref{Fig:F9Profiles}.
This difference remains important above an altitude of \SI{1}{\mega\metre} throughout the entire simulation.
The right-hand panel shows that these losses represent the largest proportion of the total radiative losses in the 0.6--\SI{1}{\mega\metre} region (after heating has ended), this is also the region in which the radiative losses between the two treatments agree the best.
Nevertheless, in the region above \SI{1}{\mega\metre} where there is significant disagreement between the two treatments, the calcium losses typically represent in excess of the 10\% of the total.

The effects are quite similar in the F10 simulation.
During energy deposition the region where the difference between the two treatments is largest is a smaller band, which is centred on $\sim$\SI{1.2}{\mega\metre}.
This is in agreement with the line-core formation region shown in the contribution functions.
This region expands significantly due to evaporation as the beam heating ends.
Similarly to the F9 simulation, the region where the calcium lines represent the largest proportion of the total radiative losses is between 0.6 and \SI{1}{\mega\metre} at later times in the simulation, and this is once again the region where the two treatments best agree.
In the region above this, where the difference between the two treatments is less but still significant, the calcium line losses typically represent 5--20\% of the total radiative losses.

For both of the simulations presented here there appears to be a similar difference between the LI and LE calcium treatments.
We can obtain a clearer estimate of the effects of the calcium treatment on the total radiative losses by plotting the product of the left- and right-hand panels of Figs.~\ref{Fig:F9LossComparison} and \ref{Fig:F10LossComparison}.
These are plotted in Fig.~\ref{Fig:LossVariation} and confirm our conclusions.
In both cases, throughout the upper chromosphere there is a variation in total radiative losses of up to 15\%.
Time-averaging this variation suggests that the average difference is larger in the F9 simulation than the F10 simulation, although these are both of the same order of magnitude.
This difference is likely due to a larger proportion of the total radiative losses from this region being mediated by the hydrogen transitions in the more energetic simulation, as a larger proportion of the calcium populations are ionised into the \Caiii{} state.
From these simulations, we can suggest that it is likely that using a self-consistent LI treatment (where the changes in radiative losses directly affect the hydrodynamic evolution) could produce a change in energy balance in the chromosphere of 10--15\%.
This is sufficiently large to noticeably modify the atmospheric evolution, which would further affect the outgoing calcium line profiles and formation heights, but also other chromospheric lines, such as the hydrogen Balmer series.

\section{Response Functions}

%spell-checker: disable
\begin{pycode}[TimeDepRT]

def rf_sym_range(rf):
    vmin = rf.min()
    vmax = rf.max()
    vmaxAbs = max(abs(vmin), abs(vmax))
    return vmaxAbs

def plot_cf_rf_comparison(cfnData, rfTempLI, rfVlosLI,
                          rfTempLE, rfVlosLE, wavelengthLI, wavelengthLE):
    fig, ax = plt.subplots(2, 3, figsize=texfigure.figsize(pytex, scale=1, height_ratio=0.7))
    fig.subplots_adjust(left=0.12, right=0.99)

    wavelengthEdgesLI = np.concatenate(([wavelengthLI[0]],
                                        0.5 * (wavelengthLI[1:] + wavelengthLI[:-1]),
                                        [wavelengthLI[-1]]))
    wavelengthEdgesLE = np.concatenate(([wavelengthLE[0]],
                                        0.5 * (wavelengthLE[1:] + wavelengthLE[:-1]),
                                        [wavelengthLE[-1]]))

    ca = CaII()
    lambda0 = ca.lines[-1].lambda0

    ax[0, 0].pcolormesh(cfnData['wavelengthEdges'], cfnData['heightEdges'], cfnData['LI'],
                        rasterized=True, cmap='Blues',
                        norm=SymLogNorm(linthresh=5e-14, vmin=1e-20, vmax=cfnData['maxVal']))
    ax[0, 0].plot(cfnData['wavelengthTau1'], cfnData['tau1LI'], c='r', alpha=0.5)
    ax[0, 0].set_xlim(-0.1, 0.1)
    ax[0, 0].set_ylim(None, 2.4)
    ax[0, 0].set_title('Contribution Function')
    vmaxAbs = rf_sym_range(rfTempLI['rf'])
    ax[0, 1].pcolormesh(wavelengthEdgesLI - lambda0, cfnData['heightEdges'], rfTempLI['rf'],
                        rasterized=True, cmap='RdBu_r',
                        norm=SymLogNorm(linthresh=1e-14, vmin=-vmaxAbs, vmax=vmaxAbs))
    ax[0, 1].plot(cfnData['wavelengthTau1'], cfnData['tau1LI'], c='r', alpha=0.5)
    ax[0, 1].set_xlim(-0.1, 0.1)
    ax[0, 1].set_ylim(None, 2.4)
    ax[0, 1].set_title('Temperature Response')
    vmaxAbs = rf_sym_range(rfVlosLI['rf'])
    ax[0, 2].pcolormesh(wavelengthEdgesLI - lambda0, cfnData['heightEdges'], rfVlosLI['rf'],
                        rasterized=True, cmap='RdBu_r',
                        norm=SymLogNorm(linthresh=1e-14, vmin=-vmaxAbs, vmax=vmaxAbs))
    ax[0, 2].plot(cfnData['wavelengthTau1'], cfnData['tau1LI'], c='r', alpha=0.5)
    ax[0, 2].set_xlim(-0.1, 0.1)
    ax[0, 2].set_ylim(None, 2.4)
    ax[0, 2].set_title('Velocity Response')

    ax[1, 0].pcolormesh(cfnData['wavelengthEdges'], cfnData['heightEdges'], cfnData['LE'],
                        rasterized=True, cmap='Blues',
                        norm=SymLogNorm(linthresh=5e-14, vmin=1e-20, vmax=cfnData['maxVal']))
    ax[1, 0].plot(cfnData['wavelengthTau1'], cfnData['tau1LE'], c='r', alpha=0.5)
    ax[1, 0].set_xlim(-0.1, 0.1)
    ax[1, 0].set_ylim(None, 2.4)
    vmaxAbs = rf_sym_range(rfTempLE['rf'])
    ax[1, 1].pcolormesh(wavelengthEdgesLE - lambda0, cfnData['heightEdges'], rfTempLE['rf'],
                        rasterized=True, cmap='RdBu_r',
                        norm=SymLogNorm(linthresh=1e-14, vmin=-vmaxAbs, vmax=vmaxAbs))
    ax[1, 1].plot(cfnData['wavelengthTau1'], cfnData['tau1LE'], c='r', alpha=0.5)
    ax[1, 1].set_xlim(-0.1, 0.1)
    ax[1, 1].set_ylim(None, 2.4)
    vmaxAbs = rf_sym_range(rfVlosLI['rf'])
    ax[1, 2].pcolormesh(wavelengthEdgesLE - lambda0, cfnData['heightEdges'], rfVlosLE['rf'],
                        rasterized=True, cmap='RdBu_r',
                        norm=SymLogNorm(linthresh=1e-14, vmin=-vmaxAbs, vmax=vmaxAbs))
    ax[1, 2].plot(cfnData['wavelengthTau1'], cfnData['tau1LE'], c='r', alpha=0.5)
    ax[1, 2].set_xlim(-0.1, 0.1)
    ax[1, 2].set_ylim(None, 2.4)

    axFlat = ax.ravel()
    for i in range(axFlat.shape[0]):
        if not (i == 0 or i == 3):
            axFlat[i].set_yticklabels([])
        else:
            axFlat[i].set_ylabel('Height [Mm]')

        if i < 3:
            axFlat[i].set_xticklabels([])
        else:
            axFlat[i].xaxis.set_major_locator(MaxNLocator(3))
            axFlat[i].set_xlabel(r'$\Delta\lambda$ [nm]')
    return fig

def read_rfs(folder, stepIdx, dt=1e-3):
    with open(chRT.data_file(folder + '/Rfs/LI/' + 'Rf_temp_5.00e+01_{:.2e}_{:d}.pickle'.format(dt, stepIdx)), 'rb') as pkl:
        rfTempLI = pickle.load(pkl)

    with open(chRT.data_file(folder + '/Rfs/LI/' + 'Rf_vlos_2.00e+01_{:.2e}_{:d}.pickle'.format(dt, stepIdx)), 'rb') as pkl:
        rfVlosLI = pickle.load(pkl)

    with open(chRT.data_file(folder + '/Rfs/LE/' + 'Rf_temp_5.00e+01_{:.2e}_{:d}.pickle'.format(dt, stepIdx)), 'rb') as pkl:
        rfTempLE = pickle.load(pkl)

    with open(chRT.data_file(folder + '/Rfs/LE/' + 'Rf_vlos_2.00e+01_{:.2e}_{:d}.pickle'.format(dt, stepIdx)), 'rb') as pkl:
        rfVlosLE = pickle.load(pkl)

    wavelengthLI = np.load(chRT.data_file(folder + '/Rfs/LI/Wavelength.npy'))
    wavelengthLE = np.load(chRT.data_file(folder + '/Rfs/LE/Wavelength.npy'))

    return rfTempLI, rfVlosLI, rfTempLE, rfVlosLE, wavelengthLI, wavelengthLE

timesToPlot = [11, 20]
for i, t in enumerate(timesToPlot):
    stepIdx = np.searchsorted(atmost.time, t)
    rfs = read_rfs('Flat1e9NoIncRad', stepIdx)
    fig = plot_cf_rf_comparison(F9Cfns[i], *rfs)
    lFig  = chRT.save_figure('F9RfComp{:d}s'.format(t), fig, fext='.pgf', dpi=500)
    if i == 0:
        lFig.caption = r'Comparative plots of the temperature and velocity response functions and the contribution function for the Ca\,\textsc{{ii}} \SI{{854.2}}{{\nano\metre}} line in the F9 simulation at {:d} s. The upper row shows the LI treatment, and the lower row the LE treatment. For the response functions, enhancement to a positive perturbation is shown in red, and reduction in blue. The $\tau_\nu=1$ line is overlaid on each plot.'.format(t)
    else:
        lFig.caption = r'Comparative plots of the response and contribution functions, equivalent to Fig.~\ref{{Fig:F9RfComp11s}} for the F9 simulation at {:d} s.'.format(t)

for i, t in enumerate(timesToPlot):
    stepIdx = np.searchsorted(atmostF10.time, t)
    rfs = read_rfs('Flat1e10NoIncRad', stepIdx)
    fig = plot_cf_rf_comparison(F10Cfns[i], *rfs)
    lFig  = chRT.save_figure('F10RfComp{:d}s'.format(t), fig, fext='.pgf', dpi=500)
    lFig.caption = r'Comparative plots of the response and contribution functions, equivalent to Fig.~\ref{{Fig:F9RfComp11s}} for the F10 simulation at {:d} s.'.format(t)
\end{pycode}

\py[TimeDepRT]|chRT.get_figure('F9RfComp11s')|
\py[TimeDepRT]|chRT.get_figure('F9RfComp20s')|
\py[TimeDepRT]|chRT.get_figure('F10RfComp11s')|
\py[TimeDepRT]|chRT.get_figure('F10RfComp20s')|
%spell-checker: enable

In Section~\ref{Sec:TimeDep8542Profiles} the contribution function was used to investigate the effects of the LI treatment on the \CaLine{} line.
It may be possible to obtain greater interpretability through the use of response functions, but so far these have only been defined for a model in statistical equilibrium.

For the time-dependent situation, a timestep by which to advance the system is needed.
This should be short to compared to the hydrodynamic evolution of our system, but sufficiently long to allow the population change to rise above our convergence threshold and correctly converge to the new solution.
\citet{Carlsson2002} note that a population perturbed out of statistical equilibrium will follow an exponential decay back to the steady state solution, further supporting the choice of a short timestep to attempt to remain within the more ``linear'' regime of this process.
Extreme care should therefore be taken when trying to make quantitative use of these time-dependent response functions over longer time periods, but for now we shall focus on qualitative aspects.

For a parameter $q$, measured in units of Q, and specific intensity in units of I, a statistical equilibrium response function has units of $\mathrm{I}\,\mathrm{Q}^{-1}$.
In the time-dependent case, we can further divide by the timestep used to obtain a response function in units of $\mathrm{I}\,\mathrm{Q}^{-1}\,\mathrm{s}^{-1}$.
As previously stated, care must be taken with extrapolating quantitative variations of outgoing intensity from the time-dependent response function, but in both cases the simple units present allow for easy comparison of the magnitude of the line's response to different effects.

The method for computing time-dependent response functions to perturbations in temperature and velocity has been applied to the same atmospheres for which the contribution functions were considered in Section~\ref{Sec:TimeDep8542Profiles}.
These properties were chosen due to the most common choices for response functions are temperature, velocity, electron density, microturbulent velocity and magnetic field.
The last three of these are not free parameters in the model presented here.
Following \Radyn{}, the microturbulence is assumed to be constant both in time and throughout the atmosphere, and this model does not consider any effects of the magnetic field.
The electron density is dependent on the rest of the atmosphere through charge conservation, and is therefore not a free parameter.
Our contribution are response functions are shown in Fig.~\ref{Fig:F9RfComp11s} -- \ref{Fig:F10RfComp20s} (LI in the upper rows and LE in the lower).
All of the response functions shown in these plots were computed with a timestep of \SI{1}{\milli\second}, but were validated for consistency against other timesteps.
In the response function plots red shows an enhancement in outgoing radiation as a response to an increase in the perturbed parameter at the particular depth, whereas blue indicates a reduction.
The shape of the temperature response function is immediately recognisable as similar to the contribution function shown in the first column.
This is not surprising, as temperature is the most important atmospheric parameter in spectral line formation, and will always affect the region where the observed photons form.
Nevertheless, at a particular wavelength, temperature response features can be seen at greater depth (well below the $\tau_\nu=1$ line) than any in the contribution function, as a change in radiation field at this depth can affect the radiative rates in the line-forming region.

The other immediately remarkable feature present in all of the temperature response functions show here is the presence of a negative response to temperature above $\sim$\SI{1.2}{\mega\metre} (i.e. an increase in temperature in this region decreases the outgoing intensity, effectively trapping radiation formed deeper in the atmosphere).
This same region is simply shown as contributing in the contribution function panels and tends to be more pronounced in models with the LE treatment, where the $\tau_\nu=1$ line is at a higher altitude.

There is a narrow blue bar in the line core of the LI temperature response function of Fig.~\ref{Fig:F9RfComp11s} around \SI{0.25}{\mega\metre}.
This is likely an artifact of the numerical method used to compute the response function, although it also appears for the other timesteps used to verify the response function.
When a feature like this appears only for one depth point it is usually a spurious numerical artifact, and we will discount it in the following.

In the right-most column of these figures we have plotted the velocity response function.
The structure of this plot below $\sim$\SI{1}{\mega\metre} is easy to interpret; an increase in velocity shifts the line-core towards bluer wavelengths, and away from redder wavelengths.
The effects on the far wings, visible below $\sim$\SI{0.4}{\mega\metre} are less immediately intuitive, but correspond to increased absorption of photospheric emission in the blue wing, and reduced in the red wing.
The structure in the line core is far more complex, and has a non-trivial response to variations in velocity, affecting the LE and LI cases differently.
This is most pronounced in the F10 response function at \SI{11}{\second} (Fig.~\ref{Fig:F10RfComp11s}).
There are also responses due to changes in velocity from well below the $\tau_\nu=1$ line in the line core due to changes in opacity in these regions affecting the radiation field in the line forming region.

We have presented a brief introduction to the concept and application of response functions to the simulations investigating the effects of the LI and LE treatments.
Response functions can provide additional information on line formation and how it is affected by the model atmosphere.
In this way they represent a powerful, but moderately computationally expensive, supplement to the traditional contribution function, allowing for additional insight into the formation of NLTE spectral lines and their domains of sensitivity.

\section{Is Full Time-Dependence Necessary?}\label{Sec:TimeDepSE}

\emph{The work in this section was undertaken in collaboration with P. Heinzel and J. Kašparová, in parallel with the study of \Caii{} photoionisation, as a result of the International Space Science Institute (ISSI) meeting: "Interrogating Field-Aligned Solar Flare Models: Comparing, Contrasting and Improving: led by G.S. Kerr and V. Polito.}

It has been repeatedly shown that a time-dependent treatment of the hydrogen populations is necessary in RHD simulations.
This was first investigated in wave heated chromospheric simulations by \citet{Carlsson2002}, who found a settling time for hydrogen to return to equilibrium ionisation of the order of thousands of seconds.
\citet{Brown2018} also compared the hydrogen line profiles, computed with \Radyn{}'s approximate PRD and time-dependence, and also with statistical equilibrium using a the full PRD treatment of RH (i.e. treating each atmospheric subsequent snapshot in statistical equilibrium).
They found that the time-dependence had a more significant effect than PRD on the Lyman lines, and could not be ignored.
More recently \citet{Kerr2019a} have investigated the effects of a time-dependent treatment of the level populations of Mg\,\textsc{ii}, and found that whilst there were differences between the statistical equilibrium and time-dependent treatments, the statistical equilibrium treatment was sufficient for most stages of the flare models investigated and for this line priority should be given to the PRD treatment.
Similarly \citet{Leenaarts2012a} found that for a correct synthesis of H$\alpha$ from three-dimensional RMHD models, only an equation of state taking into account the non-equilibrium ionisation and its effects on the electron density is necessary, and under this condition a full 3D treatment is more important than complete time-dependence.

It is therefore important to assess the importance of a time-dependent treatment of \Caii{} in solar flare models.
In the following, we shall briefly summarise our investigation of the importance of treating \Caii{} with time-dependence in the RHD model used for the comparison of the \Radyn{} and FLARIX codes presented in \citet{Kasparova2019}.
This simulation utilises a set of features common to both codes, considering only hydrogen and calcium in detailed radiative transfer, and using an analytic ``Emslie'' beam formalism \NeedRef{} (Hawley \& Fisher 1994).
The beam flux is modulated to have a symmetric triangular time profile, lasting \SI{20}{\second} and peaking at \SI{10}{\second} depositing a total of \SI{1e8}{\joule\per\square\metre} \footnote{\SI{1e11}{\erg\per\square\centi\metre}}.
A spectral index of 3 and low-energy cut-off of \SI{20}{\kilo\electronvolt} was also chosen, and similarly to the models shown previously the initial atmosphere was based on the VAL3C model of \citet{Vernazza1981}.

% spell-checker: disable
% \begin{pycode}[TimeDepRT]
% timesToSim = [2, 5, 10, 15, 20, 25]
% radOutput = []
% for t in timesToSim:
%     idx10s = np.searchsorted(atmost.time, t)

%     atmos = lw.Atmosphere.make_1d(scale=lw.ScaleType.Geometric, depthScale=np.copy(atmost.z1[idx10s]),
%                                   temperature=np.copy(atmost.tg1[idx10s]),
%                                   vlos=np.copy(atmost.vz1[idx10s]),
%                                   vturb=np.ones_like(atmost.tg1[idx10s]) * 2e3,
%                                   ne=np.copy(atmost.ne1[idx10s]),
%                                   nHTot=(atmost.d1[idx10s] / (lw.DefaultAtomicAbundance.massPerH * lw.Amu)),
%                         )
%     atmos.quadrature(5)

%     from lightweaver.rh_atoms import H_6_atom, C_atom, O_atom, OI_ord_atom, Si_atom, Al_atom, Fe_atom, FeI_atom, MgII_atom, N_atom, Na_atom, S_atom, CaII_atom, He_9_atom
%     from MsLightweaverAtoms import H_6, CaII, H_6_nasa, CaII_nasa, H_6_noLybb

%     Atoms = [H_6(), CaII(), He_9_atom(), C_atom(), O_atom(), Si_atom(), Fe_atom(),
%                     MgII_atom(), N_atom(), Na_atom(), S_atom()]
%     AtomsNoLybb = [H_6_noLybb(), CaII(), He_9_atom(), C_atom(), O_atom(), Si_atom(), Fe_atom(),
%                     MgII_atom(), N_atom(), Na_atom(), S_atom()]
%     aSet = lw.RadiativeSet(Atoms)
%     aSet.set_detailed_static('H')
%     aSet.set_active('Ca')
%     spect = aSet.compute_wavelength_grid()
%     eqPops = aSet.compute_eq_pops(atmos)
%     eqPops['H'][...] = atmost.nh1[idx10s, :]

%     aSetNoLy = lw.RadiativeSet(AtomsNoLybb)
%     aSetNoLy.set_detailed_static('H')
%     aSetNoLy.set_active('Ca')
%     spectNoLy = aSetNoLy.compute_wavelength_grid()
%     eqPopsNoLy = aSetNoLy.compute_eq_pops(atmos)
%     eqPopsNoLy['H'][...] = atmost.nh1[idx10s, :]

%     ctx = lw.Context(atmos, spect, eqPops, initSol=lw.InitialSolution.Lte, conserveCharge=False, Nthreads=12)
%     ctxNoLy = lw.Context(atmos, spectNoLy, eqPopsNoLy, initSol=lw.InitialSolution.Lte, conserveCharge=False, Nthreads=12)

%     for i in range(500):
%         dJ = ctx.formal_sol_gamma_matrices()
%         if i < 10:
%             continue
%         delta = ctx.stat_equil()
%         if dJ < 3e-3 and delta < 1e-3:
%             print(i)
%             break
%     for i in range(500):
%         dJ = ctxNoLy.formal_sol_gamma_matrices()
%         if i < 10:
%             continue
%         delta = ctxNoLy.stat_equil()
%         if dJ < 3e-3 and delta < 1e-3:
%             print(i)
%             break

%     radOutput.append({'Full': np.copy(ctx.spect.I), 'NoLybb': np.copy(ctxNoLy.spect.I)})
% \end{pycode}

\begin{pycode}[TimeDepRT]
from matplotlib.ticker import MaxNLocator
flarixComp = zarr.convenience.open(chRT.data_file('FlarixCompHard/FlarixCompHardFull.zip'), 'r')
flarixCompNoLy = zarr.convenience.open(chRT.data_file('FlarixCompHard/FlarixCompHardNoLybb.zip'), 'r')
with open(chRT.data_file('FlarixCompHard/RadynFlarixCompHardStatEqLightweaver.pickle'), 'rb') as pkl:
    flarixCompSe = pickle.load(pkl)

plotTimes = [2, 5, 10, 15, 20, 25]
fig, ax = plt.subplots(2, 3, figsize=texfigure.figsize(pytex, scale=1, height_ratio=0.7))
fig.subplots_adjust(left=0.12, right=0.99)
ax = ax.ravel()

maxI = flarixCompNoLy['Iwave'][...].max()
wave = flarixCompSe['wavelength']
waveNoLy = flarixCompSe['wavelengthNoLy']
ca = CaII()

for i, t in enumerate(plotTimes):
    zarrIdx = np.searchsorted(flarixComp['time'][...], t)
    ax[i].plot(wave - ca.lines[-1].lambda0, flarixComp['Iwave'][zarrIdx, :, -1], c='C1', linewidth=1.0)
    ax[i].plot(waveNoLy - ca.lines[-1].lambda0, flarixCompNoLy['Iwave'][zarrIdx, :, -1], c='C2', linewidth=1.0)
    ax[i].plot(wave - ca.lines[-1].lambda0, flarixCompSe['radOutput'][i]['Full'][:, -1], '--', c='C1')
    ax[i].plot(waveNoLy - ca.lines[-1].lambda0, flarixCompSe['radOutput'][i]['NoLybb'][:, -1], '--', c='C2')
    ax[i].set_xlim(-0.07, 0.07)
    ax[i].set_ylim(None, maxI * 1.05)
    ax[i].set_title('{:.1f} s'.format(t))

    if not (i == 0 or i == 3):
        ax[i].set_yticklabels([])
    else:
        ax[i].set_ylabel('Specific Intensity [SI]')

    if i < 3:
        ax[i].set_xticklabels([])
    else:
        ax[i].xaxis.set_major_locator(MaxNLocator(3))
        ax[i].set_xlabel(r'$\Delta\lambda$ [nm]')
lFig = chRT.save_figure('TimeDepSEComparison', fig, fext='.pgf')
lFig.caption = r'Comparison of time-dependent and statistical equilibrium treatments for the Ca\,\textsc{ii} \SI{854.2}{\nano\metre} line for LI and LE treatments in the simulation described in Section~\ref{Sec:TimeDepSE}. The time-dependent treatments are shown with solid lines, and the statistical equilibrium treatments with dashed lines. Orange is used for the LI treatment, and green for the LE treatment.'
\end{pycode}

\py[TimeDepRT]|chRT.get_figure('TimeDepSEComparison')|
% spell-checker: enable

In Fig.~\ref{Fig:TimeDepSEComparison} we present a comparison of both the LI and LE treatments of \CaLine{} line at different times in this simulation, having applied both time-dependent and statistical equilibrium treatments to the calcium populations.
In all cases the hydrogen populations were loaded from a fully time-dependent run and are used in \Lw{}'s ``detailed static'' mode to provide the correct radiation field.
The time-dependent treatments are treated as expected reference solutions shown with solid lines, whilst the statistical equilibrium treatments are shown with dashed lines.
Comparing the time-dependent LI (orange) and LE (green) line profiles, we see a very similar picture to that presented by our previous simulations, with the peak intensity during heating being higher in the LE case and the LI model remaining more dramatically double-peaked at later times.
Instead comparing the time-dependent and statistical equilibrium line profiles, we find very good agreement for all but the $t=\SI{2}{\second}$ snapshot, and the LI case of the $t=\SI{5}{\second}$ snapshot.
For the latter of these, the line shape is correct, but the intensity of the statistical equilibrium case is a few percent lower than that of the full time-dependent treatment.
At $t=\SI{2}{\second}$ the difference between the two different LI treatments is greater than the difference between the LE treatments, but for both the LI and LE cases the statistical equilibrium lines are narrower and less pronounced than their time-dependent counterparts.

For this particular simulation, after the first few seconds of heating, the statistical equilibrium treatment is perfectly valid with no obvious defects.
Clearly, this one simulation does not represent all RHD flare simulations, but we have qualitatively found this to be true when testing multiple timesteps from the simulations used in the previous sections.


\section{PRD}\label{Sec:TimeDepPrd}

As highlighted by \citet{Brown2018}, when considering the hydrogen Lyman lines it would be a significant improvement to simultaneously handle full time-dependence and PRD.
It is possible that this could prove important for the energy balance of the line-forming regions, in a similar manner to the photoionisation effects discussed previously.
Indeed, any significant variation in the hydrogen Lyman series may affect the populations \Caii{} and similar species through photoionisation, and also in \Ha{} through modifications of the level populations.
\citet{Leenaarts2012a} investigated the Doppler-like PRD approximation used in our \Radyn{} simulations and found it sufficient for the correct formation of H$\alpha$ in the quiet Sun case.
The version of \Radyn{} used by \citet{Brown2018} truncated the Lyman lines at several Doppler widths from the line-core, and thus conclusions drawn about the importance of PRD may not be directly applicable to our models.

The \Lw{} framework supports both time-dependence and PRD lines, thus we can attempt to modify the tool built in the previous section to also include PRD effects.
This is achieved by restoring the damping terms on the Ly$\alpha$ and Ly$\beta$ spectral line definitions (as these were adjusted to approximate PRD), solving the statistical equilibrium problem for the initial atmosphere in PRD, and then updating the PRD line emission ratio $\rho$ during each timestep based on the current atmospheric parameters and radiation field.
Unfortunately, this basic approach proved to have incredibly poor convergence.
Many timesteps fail to converge or the iteration scheme can enter a loop of repeatedly passing through the same states, getting no closer to the convergence threshold.
Of the timesteps that do converge, many take an exceedingly large number of iterations.

These convergence problems are somewhat unexpected due to the reliability of the methods used here when applied here to statistical equilibrium problems.
We are faced with an additional problem when performing time-dependent simulations, especially in the reprocessing context used here; when a timestep fails to converge we lose the ability to investigate later in the simulation, as the populations at every timestep are dependent on the preceding.
When reprocessing snapshots of an RHD simulation using a statistical equilibrium treatment, a failure for one of these to converge does not limit the analysis of any other snapshot.
These problems may in part be related to the convergence of the PRD scattering integral on the fine spatial grid that \Radyn{} produces, but as previously noted, this is rarely a problem in statistical equilibrium situations.

The following procedure was found to be relatively robust, sufficient for reprocessing the complete F9 simulation of the previous section.
At the start of each timestep, when the populations are advected from the previous grid to the next, the line emission ratio $\rho$ is interpolated onto the new grid.
Inherent to this assumption is the idea that $\rho$ will not change too drastically between subsequent timesteps.
The time-dependent problem is then solved to our normal tolerance whilst keep $\rho$ fixed at its interpolated values.
Once converged, we continue to compute the time-dependent population update, whilst now interleaving iterations of updating $\rho$.

In the F9 simulation this approach proves to be rapidly convergent at early times, but far less so at later times during the cooling phase.
Initially this appears unintuitive, but the non-thermal collisional rates from the electron beam depositing energy in the simulation are substantial during the heating phase and likely reduce the effects of PRD on these lines.
At later times the Lyman line forming regions are likely to be relatively non-collisional (hence the expectation of PRD effects), and the population transition rate is likely dominated by the radiative effects, increasing the relative importance of these PRD effects.
However, the bulk of the Ly$\alpha$ line core forms in the transition region, which is not as dramatically affected by direct energy deposition from the beam as the chromosphere, due to its decreased density, so the reason for this variation in convergence behaviour is not clear.
Similar behaviour occurred when reprocessing the F10 simulation, but the convergence deteriorates sooner and despite adjustments to the number of PRD iterations taken, usually fails to converge around $t=\SI{3.75}{\second}$.

%spell-checker: disable
\begin{pycode}[TimeDepRT]
from MsLightweaverAtoms import H_6
def plot_prd_profiles(liData, prdData, radyn):
    plotTimes = [5, 11, 20, 40]
    fig, ax = plt.subplots(1, 4, figsize=texfigure.figsize(pytex, scale=1, height_ratio=0.40),
                           sharex=True, sharey=True,
                           gridspec_kw={'wspace': 0.1, 'width_ratios':[1,1,1,1]})
    fig.subplots_adjust(left=0.12, right=0.99)
    ax = ax.ravel()

    lineData = line_intensity_with_cont(radyn, 0, -1)
    h = H_6()
    wavelength = liData['wavelength'][...]
    wavelengthPrd = prdData['wavelength'][...]
    for i, time in enumerate(plotTimes):
        lwIdx = np.searchsorted(liData['time'], time)
        radynIdx = np.searchsorted(radyn.time, time)
        lambda0 = h.lines[0].lambda0

        if i == 0:
            ax[i].plot(lineData[0].value - lambda0, lineData[1][radynIdx], label='RADYN')
            ax[i].plot(wavelength - lambda0, liData['Iwave'][lwIdx, :, -1], '--', label='CRD')
            ax[i].plot(wavelengthPrd - lambda0, prdData['Iwave'][lwIdx, :, -1], '--', label='PRD')
        else:
            ax[i].plot(lineData[0].value - lambda0, lineData[1][radynIdx])
            ax[i].plot(wavelength - lambda0, liData['Iwave'][lwIdx, :, -1], '--')
            ax[i].plot(wavelengthPrd - lambda0, prdData['Iwave'][lwIdx, :, -1], '--')

        ax[i].set_title('{:.2f} s'.format(time))
        ax[i].xaxis.set_minor_locator(AutoMinorLocator())

    ax[0].set_yscale('log')
    ax[0].set_ylim(1e-11, 4e-9)
    ax[0].set_xlim(-0.06, 0.06)

    ax[0].yaxis.offsetText.set_visible(False)
    ax[0].set_ylabel('Specific Intensity [SI]')
    for a in ax:
        a.set_xlabel('$\Delta\lambda$ [nm]')
    fig.subplots_adjust(bottom=0.15)
    fig.legend(*ax[0].get_legend_handles_labels(), loc=(0.80,0.66), frameon=False,
               handletextpad=0.5, handlelength=1.5, fontsize=9)#, bbox_to_anchor=(0.5,0.53))
    return fig

def plot_prd_K_profiles(liData, prdData, radyn):
    plotTimes = [5, 11, 20, 40]
    fig, ax = plt.subplots(1, 4, figsize=texfigure.figsize(pytex, scale=1, height_ratio=0.40),
                           sharex=True, sharey=True,
                           gridspec_kw={'wspace': 0.1, 'width_ratios':[1,1,1,1]})
    fig.subplots_adjust(left=0.12, right=0.99)
    ax = ax.ravel()

    lineData = line_intensity_with_cont(radyn, 17, -1)
    ca = CaII()
    wavelength = liData['wavelength'][...]
    wavelengthPrd = prdData['wavelength'][...]
    for i, time in enumerate(plotTimes):
        lwIdx = np.searchsorted(liData['time'], time)
        radynIdx = np.searchsorted(radyn.time, time)
        lambda0 = ca.lines[1].lambda0

        if i == 0:
            ax[i].plot(lineData[0].value - lambda0, lineData[1][radynIdx], label='RADYN')
            ax[i].plot(wavelength - lambda0, liData['Iwave'][lwIdx, :, -1], '--', label='CRD')
            ax[i].plot(wavelengthPrd - lambda0, prdData['Iwave'][lwIdx, :, -1], '--', label='PRD')
        else:
            ax[i].plot(lineData[0].value - lambda0, lineData[1][radynIdx])
            ax[i].plot(wavelength - lambda0, liData['Iwave'][lwIdx, :, -1], '--')
            ax[i].plot(wavelengthPrd - lambda0, prdData['Iwave'][lwIdx, :, -1], '--')

        ax[i].set_title('{:.2f} s'.format(time))
        ax[i].xaxis.set_minor_locator(AutoMinorLocator())

    ax[0].set_yscale('log')
    ax[0].set_ylim(5e-10, 14e-8)
    ax[0].set_xlim(-0.075, 0.075)

    ax[0].yaxis.offsetText.set_visible(False)
    ax[0].set_ylabel('Specific Intensity [SI]')
    for a in ax:
        a.set_xlabel('$\Delta\lambda$ [nm]')
    fig.subplots_adjust(bottom=0.15)
    fig.legend(*ax[0].get_legend_handles_labels(), loc=(0.80,0.66), frameon=False,
               handletextpad=0.5, handlelength=1.5, fontsize=9)#, bbox_to_anchor=(0.5,0.53))
    return fig

from matplotlib.ticker import SymmetricalLogLocator
def plot_K_losses(atmost, liData, prdData):
    plotTimes = [5, 11, 20, 40]
    fig, ax = plt.subplots(1, 4, figsize=texfigure.figsize(pytex, scale=1, height_ratio=0.40),
                           sharex=True, sharey=True,
                           gridspec_kw={'wspace': 0.1, 'width_ratios':[1,1,1,1]})
    fig.subplots_adjust(left=0.08, right=0.99)
    ax = ax.ravel()
    caKIndex = 11

    lineData = line_intensity_with_cont(radyn, 17, -1)
    for i, time in enumerate(plotTimes):
        lwIdx = np.searchsorted(liData['time'], time)
        atmostIdx = np.searchsorted(atmost.time, time)

        if i == 0:
            ax[i].plot(liData['losses'][lwIdx, caKIndex, :],
                       atmost.z1[atmostIdx] / 1e6, c='C1', label='CRD')
            ax[i].plot(prdData['losses'][lwIdx, caKIndex, :],
                       atmost.z1[atmostIdx] / 1e6, '--', c='C2', label='PRD')
        else:
            ax[i].plot(liData['losses'][lwIdx, caKIndex, :],
                       atmost.z1[atmostIdx] / 1e6, c='C1')
            ax[i].plot(prdData['losses'][lwIdx, caKIndex, :],
                       atmost.z1[atmostIdx] / 1e6, '--', c='C2')

        ax[i].set_title('{:.2f} s'.format(time))
        # ax[i].xaxis.set_minor_locator(AutoMinorLocator())

    ax[0].set_xscale('symlog', linthreshx=1e-5)
    ax[0].set_ylim(0.2, 2.0)
    ax[0].set_xlim(-1e-1, 1e-1)

    # ax[0].yaxis.offsetText.set_visible(False)
    ax[0].set_ylabel('Height [Mm]')
    for a in ax:
        a.set_xlabel('Loss [W\,m$^{-3}$]')
        a.set_xticks([-1e-2, -1e-4, 0, 1e-4, 1e-2])
    fig.subplots_adjust(bottom=0.17)
    fig.legend(*ax[0].get_legend_handles_labels(), loc=(0.86,0.48), frameon=False,
               handletextpad=0.5, handlelength=1.5, fontsize=9)#, bbox_to_anchor=(0.5,0.53))
    return fig

prdData = zarr.convenience.open(chRT.data_file('Flat1e9NoIncRadPrdFineGridThesis.zip'), 'r')
fig = plot_prd_profiles(liData, prdData, radyn)
lFig = chRT.save_figure('F9LyaProfiles', fig, fext='.pgf')
lFig.caption = r'Comparison of the CRD (with reduced broadening to approximate PRD), and PRD treatments of the Ly$\alpha$ line in the F9 model.'

fig = plot_prd_K_profiles(liData, prdData, radyn)
lFig = chRT.save_figure('F9KProfiles', fig, fext='.pgf')
lFig.caption = r'Comparison of the CRD and PRD treatments of the Ca\,\textsc{ii} K line in the F9 model.'

fig = plot_K_losses(atmost, liData, prdData)
lFig = chRT.save_figure('F9KLossesPrd', fig, fext='.pgf')
lFig.caption = r'Comparison of the chromospheric radiative losses under CRD and PRD treatments of the Ca\,\textsc{ii} K line in the F9 model. A negative value indicates a radiative loss and a positive value a radiative gain.'
\end{pycode}
\py[TimeDepRT]|chRT.get_figure('F9LyaProfiles')|
\py[TimeDepRT]|chRT.get_figure('F9KProfiles')|
\py[TimeDepRT]|chRT.get_figure('F9KLossesPrd')|
%spell-checker: enable

The Ly$\alpha$ line computed in the reprocessed F9 simulation, both with and without PRD effects, is shown in Fig.~\ref{Fig:F9LyaProfiles}.
Once again, our treatment of the problem with \Lw{} yields very good results when compared to \Radyn{} as a reference solution.
Other than the line wings at $t=\SI{5}{\second}$ and to a lesser extent at $t=\SI{40}{\second}$ the PRD and CRD (with reduced broadening terms) match well, although the PRD line core at $t=\SI{20}{\second}$ is a fair amount deeper than the CRD case.
This is encouraging for the use of this approximation, especially in light of the difficulties converging the PRD problem in time-dependent simulations.
Furthermore, the PRD solution, due to its poor convergence at later times, is extremely computationally costly when compared to the CRD solution, taking close to two orders of magnitude more CPU time (73 vs 1.2 wall hours).

Ly$\alpha$ is not the only line affected by PRD in this simulation; we also investigated the effects on Ly$\beta$ and the \Caii{} H and K resonance lines.
Ly$\beta$ was found to have very good agreement between the approximate and complete PRD treatments, similar or better to that found for Ly$\alpha$.
\Caii{} H and K are also affected by the use of the LI treatment, albeit less than \CaLine{}, this is likely due to the lack of overlap between Ly$\alpha$ and the \Caii{} resonance continuum.
In Fig.~\ref{Fig:F9KProfiles}, the variation of the \Caii{} K line computed using CRD with the LI treatment and PRD with the LI treatment is shown.
The differences between the CRD line profiles and the \Radyn{} line profiles are due to the LI treatment.
The PRD line cores agree very well with the CRD LI treatment, but as expected, when a significant proportion of the scattering is coherent the line wings are deeper and slowly return to the same continuum level as the CRD case.
\citet{Uitenbroek2002} undertook similar tests in a wave-heated quiet Sun \Radyn{} simulation and looked at the radiative losses in the \Caii{} K line when treated in PRD (under statistical equilibrium).
In the chromosphere these losses were found to vary between the CRD and PRD treatments by a factor of 2-5.
Qualitatively, there is a smaller difference in the \Caii{} wings in our flare simulation than their wave heated model.
The losses between these two different treatments in the chromosphere are shown in Fig.~\ref{Fig:F9KLossesPrd}.
The differences in the radiative losses are most significant at $t=\SI{5}{\second}$ with the inversion of the sign of the losses between the PRD and CRD treatments around \SI{1}{\mega\metre}.
Whilst less significant, at the other times shown there is also notable variation in radiative losses due to the treatment of these \Caii{} resonance lines in PRD, typically decreasing these relative to their CRD values.

Whilst we have not attempted to implement this, it is possible that applying a direct, rather than iterative solution for evaluating the emission profile ratio may be more stable in this situation.
The iterative method, implemented as first presented in \citet{Uitenbroek2001}, tends to have very good convergence when used in the statistical equilibrium case, whilst being less computationally expensive and much easier to apply in multi-dimensional geometry.
It is plausible here that the effective damping of the population update equations of the time-dependent kinetic equilibrium equations relative to statistical equilibrium is reducing the convergence rate, due to the slower rate (per iteration) at which the populations evolve.
It may therefore be worth investigating the direct solution in the hope that by more rapidly converging to the correct solution for the emission profile the populations do not pass through intermediate states that are not ``valid'' i.e. states that are intermediate to the iteration scheme, but do not occur at any point in the real world system we are computing.
It is plausible that many of the intermediate states that occur in both time-dependent and statistical equilibrium are not states that occur naturally, instead resulting from our numerical treatment of the system.
When additional iteration processes such as PRD and charge conservation are applied, whilst being combined with the damped nature of the time-dependent population update, it appears that cycles in the global iteration procedure can occur quite frequently, and no method that we have found reliably prevents these (including interleaving basic $\Lambda$-iterations and applying Ng acceleration).

\section{Discussions}

We have presented multiple applications of the \Lw{} framework to reprocessing the radiative transfer of \Radyn{} simulations.
Through the construction of simple tools, we are able to quantitatively investigate the importance of various radiative effects that may not be considered in \Radyn{}'s treatment (but without modifying the energy balance or hydrodynamics), more rapidly than would be possible incorporating the necessary changes into \Radyn{}.
These tools have been used to investigate the effects of photoionisation of \Caii{} to \Caiii{} by the hydrogen Lyman lines, the importance of treating the \Caii{} populations with time-dependence, and the possible difficulties in applying a PRD treatment in RHD simulations.

From the flare simulations presented here the hydrogen Lyman lines have significant effects on the \Caii{} photoionising radiation field.
This results in substantial changes in both the outgoing \CaLine{} line profiles, and the radiative energy balance in the upper chromosphere.
The radiative losses in this region were found to be affected by up to 15\%, which could in turn lead to differences in the hydrodynamic evolution of the simulation and thus greater difference in the line profiles.
We did not find a clear correlation between the magnitude of this effect and the increased heating in the F9 and F10 models; in both cases the effect was important, and therefore is likely to remain so at higher energy depositions.
It is therefore essential that RHD simulations start to consider this in a self-consistent way to gauge its full effect.
These photoionisation effects could also affect other species with continua overlapping the hydrogen Lyman lines.
For instance, Mg\,\textsc{ii} line profiles are often used for chromospheric diagnostics, but these are unlikely to be as significantly affected by the hydrogen Lyman lines as \Caii{} due to the resonance continuum edge being located at \SI{82.46}{\nano\metre}.
The Mg\,\textsc{ii} populations will be influenced to a lesser extent by photoionisation from the subordinate continua, some of which overlap the Lyman series.

On the other hand, we found that the deviations of the calcium populations due to full time-dependent kinetic equilibrium over statistical equilibrium were typically small in the simulations investigated.
This is interesting, as it theoretically allows for \Caii{} to be processed separately, but as the radiative losses from this species need to be known for the hydrodynamics of an RHD simulation, this species likely still needs to be treated in lockstep with the rest of the simulation.
Additionally, there is typically a loss in speed by computing the statistical equilibrium solution at each timestep in the simulation (even starting close to the solution from the previous timestep's solution) over the time-dependent solution when using traditional RT methods.
This could change with the application of machine learning, as it will be far easier to construct detailed models that provide the unique statistical equilibrium solution for a given atmosphere than determining the correct time-dependent solution.
As the hydrogen populations would continue to require a full time-dependent treatment there is not likely to be an immediate gain from such a model in the context of RHD simulations.
However, the nuanced analysis of the formation of H$\alpha$ in the quiet Sun by \citet{Leenaarts2012a} suggests that it may be sufficient to purely capture the effects of hydrogen non-equilibrium ionisation (i.e. the fraction of hydrogen that is fully ionised and its effects on the electron density) through the equation of state and then perform NLTE synthesis in statistical equilibrium with this given electron density.
This would also need to be validated for flares models, and could be done following the approach laid out in this chapter.
It would then become significantly easier to apply machine learning models to these separable components; this could provide massive computational gains in RHD modelling, whilst detailed spectral synthesis would remain possible through traditional NLTE RT approaches.
Parallels can be drawn between the application of machine learning to this problem and the use of interpolated rates following the method of Sollum \NeedRef{} as can be done with HYDRAD \citep{Reep2019}, and is used in BIFROST \citep{Gudiksen2011}, but it remains to be proven whether this method retains sufficient accuracy at the high energy depositions that occur in flares.

Despite the apparent simplicity of incorporating PRD into these tools, the iteration process was plagued with convergence problems that we have been unable to fully resolve.
Nevertheless, for the hydrogen Lyman lines in the F9 simulation presented in this chapter the PRD approximations (based on reducing the broadening of the hydrogen lines) currently present in \Radyn{} perform well, and come at no additional computational cost over the basic CRD treatment, validating the quiet Sun results of \citet{Leenaarts2012a}.
We therefore recommend that this approximation continue to be employed for Ly$\alpha$ and Ly$\beta$ until more advanced iteration methods are developed (that can simultaneously solve for the atomic level populations, electron density, and necessary PRD line emission profile ratios).
It is possible to apply the method outlined in Sec.~\ref{Sec:TimeDepPrd} to Mg\,\textsc{ii}, but it is likely, as shown by \citet{Kerr2019}, that treating it in statistical equilibrium with PRD will provide a sufficiently accurate solution whilst remaining relatively efficient, hopefully allowing this specie to be incorporated into RHD simulations in the near future.

The effects of treating the \Caii{} resonance lines in PRD were significantly larger than those seen with the hydrogen Lyman lines.
This is seen not only in the line profiles, but also in the chromospheric radiative losses in these lines, which vary substantially when treated with PRD (and are typically smaller than those computed in CRD).
It is therefore important to investigate whether applying PRD to the H and K lines can be done efficiently.
Empirically, we have found that the majority of convergence problems originate from the hydrogen Lyman lines, thus it may be relatively efficient to treat the \Caii{} resonance lines in PRD.
If similar convergence issues also affect these lines, then it would be desirable to devise and implement an approximation scheme similar to that applied to the Ly$\alpha$ and Ly$\beta$.
It has been suggested that \Radyn{}'s treatment of the \Caii{} resonance lines in CRD overestimates the radiative losses but this overestimation is compensated by not considering the Mg\,\textsc{ii} h and k lines \citep[e.g.][]{Kerr2019a}.
The techniques presented in this chapter should allow for a thorough investigation of this and the development of suitable PRD approximations if necessary.