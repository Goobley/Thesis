\chapter{Flare Modelling}\label{Chap:FlareModelling}
% spell-checker: disable
%TC:group pycode 0 0
\begin{pycode}[FlareModelling]
name = 'FlareModelling'
chFlareModelling = texfigure.Manager(
    pytex,
    './01aFlareModelling',
    number=1,
    python_dir='./01aFlareModelling/python',
    fig_dir=   './01aFlareModelling/Figs',
    data_dir=  './Data/01aFlareModelling'
)
\end{pycode}
% spell-checker: enable

% \begin{itemize}
%     \item Radiative Transfer Physics
%     \item Hydro and Radiation hydrodynamics
%     \item Numerical approaches to RT and RHD. (combined into the previous sections)
% \end{itemize}

Simulation is a powerful scientific approach that seeks both to validate our understanding of a phenomenon and also learn how it is influenced by various parameters.
Contrary to its dictionary definition, which suggests deceit or merely a surface level resemblance, simulations are essential tools in an astrophysical context.
Astrophysical observations differ greatly from laboratory experiments, due to our lack of knowledge of the configuration and parameters of the system, and inability to repeat particular events.
They represent our best tool for bridging the gap between a theory of the physical processes at work in an observed event, and the observations thereof.
A numerical approach is often needed as the coupled physical processes investigated are typically too complex and non-linear to analytically solve in detail.
There will commonly be free parameters left in these models, some of which can be directly inferred from observation, but others may need to be investigated and later constrained by comparing the model output to observations.
Due to computational or conceptual limitations simplifying assumptions are often required to make these models tractable.

% In the following we will describe the primary physical processes assumed to be at work in solar flares, and how these are modelled, including the primary approximations used.


% \section{Modelling Flares and Observables}

To design a model of solar flares it is first necessary to understand as much as possible from the available observations, so as to ascertain reasonable approximations and the most important processes to include.
By the same, it is necessary to understand which observables vary between flares, to be able to exploit their specific sensitivities and choose those that are sufficiently variable to describe the processes at work and distinguish between flares.
The following builds on many years of work by the solar physics community, and we start from the understanding that has slowly been accrued to present the current state of modelling, and why certain decisions are made.
A more detailed description of flare observations and some of the ways these are exploited is undertaken in Chap.~\ref{Chap:FlareObservations}.

\section{Radiation Hydrodynamics}

% In our discussion of radiative transfer thus far we have treated the thermodynamic structure of the atmosphere as something constant, however given the short timescales flares evolve over, we know that this is a poor approximation.

It is common to treat flares as a semi-ionised plasma consisting of a single compressible fluid, obeying the equations of hydrodynamics. The influence of the magnetic field can also be included, at which point the equations of magnetohydrodynamics (MHD) are used to describe the motion of the fluid.
Due to the complexity, and resultant numerical difficulties in investigating the widely varying spatial scales (the entire atmosphere, but requiring a dense sampling of the chromosphere and transition region) that occur in flares with a three-dimensional MHD treatment, it is common to use one-dimensional field-aligned hydrodynamic code.
The assumption here is that the vast majority of observed fluid motions in a flare are along the magnetic field lines, so a single flaring loop can be approximated by a quasi-one-dimensional simulation describing the movement of a fluid through a tube, and the propagation of energy through this medium.
This is due to the strength of the magnetic field, effectively locking the fluid within flux tubes to the field lines.
These are therefore known as field-aligned radiation hydrodynamic codes.

This gas dynamic system can be described by

\begin{equation}
    \begin{aligned}
    \frac{\partial \rho}{\partial t} + \frac{\partial \rho \varv}{\partial z} &= 0\\
    \frac{\partial \rho \varv}{\partial t} + \frac{\partial \rho \varv^2}{\partial z} - \rho g + \frac{\partial P}{\partial z} - \frac{\partial}{\partial z}\left(\mu \frac{\partial \varv}{\partial z}\right) &= 0\\
    \frac{\partial E}{\partial t} + \frac{\partial}{\partial z}\left( E\varv + P\varv - \kappa\frac{\partial T}{\partial z} \right)+ \mu\frac{\partial \varv^2}{\partial z} -\rho \varv g + L - S &= 0,
    \end{aligned}\label{Eq:RhdEquations}
\end{equation}

where $\rho$ is the mass density of the gas, $\varv$ is the bulk velocity, $z$ is the spatial coordinate, $g$ is the local gravitational acceleration, $P$ is the pressure, $\mu$ is the coefficient of dynamic viscosity, $L$ is the radiative loss term, and $S$ is all additional energy source terms, from radiative transfer and atmospheric heating.
In these models the plasma is typically assumed to behave as an ideal gas, and therefore uses the equation of state
$P = n_{\mathrm{tot}} k_B T$, where $n_{\mathrm{tot}}$ is the total particle number density, $k_B$ is Boltzmann's constant, and $T$ is the plasma temperature. Additionally, $\kappa=\kappa_0 T^{5/2}$ is the coefficient of heat conduction, and is discussed in detail in Sec.~\ref{Sec:NumericalConduction}.

All of the quasi-one dimensional codes solve a variant the RHD equations in \eqref{Eq:RhdEquations}. The first of these describes mass continuity, the second conservation of momentum, and the third conservation of energy.
The nuance typically occurs in ensuring that all terms are solved in a self-consistent fashion and the treatment of the optically thick radiation source and sink terms appearing in the energy equation.

The first generation of hydrodynamic flare models \citet{Nagai1980,Mariska1982,McClymont1983} focused on capturing the gas dynamics of the flaring event, using simplified radiative treatment.
These early models were much more limited in general due to computational constraints. \citet{Nagai1980} and \citet{Mariska1982} both employ optically thin losses with ad hoc corrections to avoid over-cooling the lower atmosphere.
\citet{McClymont1983} employ an escape probability formalism for determining the transition rates of hydrogen, which is a faster, less precise method than detailed radiative transfer, but vastly more accurate than assuming the chromosphere to be optically thin (or an ad hoc modulation thereof).
Escape probability methods are unable to take radiative backwarming into account -- where radiation produced higher in the atmosphere is absorbed at a lower point -- which can be an important factor for strong solar optical transitions used to diagnose atmospheric properties.

The current generation of RHD codes consists of RADYN \citep{Carlsson1992a,Carlsson1995,Carlsson1999, Allred2015}, FLARIX \citep{Varady2010,Heinzel2015}, and HYDRAD \citep{Bradshaw2003, Bradshaw2013}. RADYN and FLARIX both apply detailed treatment of the radiative losses for certain chromospheric transitions, whilst HYDRAD uses partially precomputed radiative rates for hydrogen (based on the treatment of Sollum \NeedRef{}) and radiative losses interpolated following the method of \citet{Carlsson2012}.
HYDRAD originally focused more on the investigation of non-equilibrium optically thin radiative losses in the corona, and less on the chromosphere, however, recent development has also moved in the direction of an improved chromospheric treatment.
It also differs in its use of a two-fluid model, treating electrons and ions as separate, but coupled, fluids but in current applications this does not appear to provide significantly different results when applied to flare modelling.

RADYN is derived from the MULTI RT code \citep{Scharmer1985, Carlsson1986, Carlsson1992}, and applies the linearisation approach described therein to the entire RHD system, ensuring the self-consistency of all terms. The equations of RHD are solved in an implicit linearised form by Newton-Raphson iteration on the dynamic grid of \citet{Dorfi1987}.
RADYN was originally constructed to investigate the effects of waves propagating through the chromosphere, but was extended by \citet{Abbett1999} to perform some of the earliest simulations of the dynamic flares with detailed radiation treatment in a self-consistent fashion. The code has since been developed further to include improved energy transport treatments, primarily focusing on electron beam energy deposition \citep{Allred2005, Allred2015}.


FLARIX, on the other hand consists primarily of three separate modules. The hydrodynamics is solved by a variant of the NRL Solar Flux Tube Model described in \citet{Mariska1982,Mariska1989}, extended with a MALI module (considering non-overlapping spectral lines with constant background continuum as described in \citet{Rybicki1991}) for detailed radiation transfer, and a test-particle code for determining heating and electron deposition \citep{Varady2010, Heinzel2015}.

RADYN and FLARIX have recently been tested against each other and shown to provide remarkable agreement, despite their different heritage \citep{Kasparova2019}, and early tests also show good consistency with HYDRAD when enabling its recent extensions\footnote{Initial comparisons undertaken following the International Space Science Institute meeting: ``Interrogating Field-Aligned Solar Flare Models: Comparing, Contrasting and Improving'' led by G.S. Kerr and V. Polito.}.

\section{An Eye to the Future: Radiative Magnetohydrodynamics}

Much scientific effort is being invested into the creation of three-dimensional radiative MHD (RMHD) models, which aim to accurately describe all of the physics of a flaring system through the use of large models on supercomputers. The two leading codes are \textit{Bifrost} \citep{Gudiksen2011}, and MURaM \citep{Rempel2009,Rempel2016}. MURaM was originally focused on photospheric magnetoconvection, but has been extended into the corona. It adopts a grey radiative transfer technique that treats all outgoing radiation using a wavelength averaged approach, but has successfully demonstrated the ability to drive self-consistent flare-like eruptions with time-dependent photospheric magnetograms as a boundary condition \citep{Cheung2019}.

\textit{Bifrost} is more focused on a detailed chromospheric treatment; it currently uses multi-group opacities for wavelength dependent radiation transport and the Sollum model for hydrogen \NeedRef{} to better treat the radiative losses from this region.
It has been used to investigate solar enhanced networks \citep{Carlsson2016}, the generation of spicules \citep{Martinez-Sykora2017}, and the magnitude of magnetic energy present in the chromosphere \citep{Martinez-Sykora2019} \TODO{Should probably reference the 2021 Martinez-Sykora on spicules too}.

Currently, neither code can handle the scale of the energy deposition used in the field-aligned flare models, or provide an equivalent chromospheric spatial resolution, but this is an area of very active development.
The field-aligned models remain complementary to these much more complex and computationally intensive models allowing for more rapid investigation of the relative importance of phenomena to be implemented within the RMHD models, the use wider parameter spaces and higher energy inputs, whilst also remaining usable by smaller teams of researchers.


\section{Solar Flare Heating}

The aforementioned modern field-aligned RHD codes are primarily designed to simulate the response of a tube of initially quiet solar atmosphere to heating, typically presumed to be due to a beam of energetic electrons precipitating from the corona due to magnetic reconnection.

The direct effects of these electrons must also be considered, as their flux is sufficiently large that their collisions with particles in the lower atmosphere can substantially change the distribution of these particles, exciting and ionising them.
The evolution of the atmosphere will also affect how and where it interacts with these precipitating electrons, coupling an additional problem to the extant RHD system.

There are different methods of solving this problem, the simplest of which is the analytic solution of \citet{Emslie1978} which provides a simple solution to beam energy deposition along the column of plasma under the assumption that all electron energy is lost due to Coulomb collisions with the plasma acting as a cold target.
This is a useful approximate treatment, however terms such as relativistic effects on high energy electrons, return current (heating the corona), and magnetic mirroring are all important here, and ignored in this model. RADYN and FLARIX both include more advanced treatments including these effects; FLARIX uses a test-particle module \NeedRef{}, whereas RADYN solves the Fokker-Planck equation \citep[e.g.][]{Hamilton1990}, but both also include the option to use the the simpler analytic Emslie formulation.

Another proposed model for the energy transport and heating in flares is Alfvén heating \citep{Emslie1982, Fletcher2007}, which suggests that energy is transported by Alfvén waves\footnote{These  are transverse waves that propagate along the magnetic field \citep{TandbergHanssen1988}.} from the corona to the denser layers at the base of a flaring loop where electrons are locally accelerated.
One argument for this is the so-called ``number problem'' which expresses the difficulty in resupplying the acceleration site in the low density coronal plasma with sufficient electrons to reflect the number observed at their chromospheric impact (this number can be bounded from hard X-ray observations \citep[e.g.][]{Simoes2013}).
The denser regions closer to the electrons' impact location do not suffer from this same scarcity of electrons, and thus represent a possible resolution to this problem.

A simplified variant of this Alfvénic heating model has been investigated by \citet{Kerr2016} inside the \Radyn{} code, and produced notably different spectral line profiles which may agree better with observations than those from an electron beam model, however further investigation of the implementation of this method and its results are needed.
This approach was also incorporated into HYDRAD by \citet{Reep2016}, which showed the viability of these waves heating the deep chromosphere and triggering explosive chromospheric evaporation.
It is non-trivial to incorporate a full treatment of this phenomenon into RHD codes as it is coupled to the magnetic field, and future improvements are needed to more accurately model these effects and investigate to what extent Alfvénic and electron beam heating occurs simultaneously.

The simulations of flares discussed here allow us to predict the line and continuum emission from the time-evolution of heating a starting atmosphere.
These detailed results can be compared against observations, and have provided significant insight into chromospheric properties (e.g. \citet{Kuridze2015,RubioDaCosta2016,Kowalski2017,Simoes2017}).
The manual forward-fitting process involved in attempting to reproduce these observations with simulations is both time-consuming and difficult and lies close to the field of automated inversions, which we will address later in Chapters~\ref{Chap:FlareObservations} and \ref{Chap:Radynversion}.

We will now present a more detailed overview of the physics involved in the most important terms of the RHD equations \eqref{Eq:RhdEquations}, starting with complexities of radiative transfer outside of local thermodynamic equilibrium.

\section{Introduction to Radiative Transfer}\label{Sec:IntroRT}

\emph{The content of this section draws primarily from \citet{Hubeny2014} and the paper describing \Lw{} \citep{Osborne2021}}

Radiative transfer is the science of how radiation propagates through a material; the absorptions, scatterings and emission that happens therein.
Radiation is the close to the only conduit through which information can arrive from celestial bodies, and by far the most widely exploited.
It allows us to derive proxies for \emph{in situ} measurements, that cannot otherwise be obtained, due to the distances and extreme conditions being observed.
Everyone is familiar with the concept of images, which show the spatial variation of light but a lot of additional information can be gleaned by analysing it in terms of its wavelength variation and polarisation projections.
Using both of these properties is referred to as \emph{spectropolarimetry}, and \emph{spectroscopy} when only the unpolarised intensity is considered.
The most basic property to consider here is the specific intensity, commonly denoted $I(\nu, \vec{d})$ for a particular frequency $\nu$ and direction $\vec{d}$ at a location in space with typical SI units \si{\joule\per\square\metre\per\s\per\hertz\per\steradian}.

A ray propagating through a medium, such as a neutral gas or plasma, will gain a certain amount of energy per unit length due to emission processes, whilst also losing another amount due to absorption and scattering processes. These will depend on the local parameters of the plasma as well as the direction of the ray. For a plasma where the primary interacting species are atomic, we can distinguish bound-bound and bound-free transitions. In the former a bound electron moves between two different sublevels of an atom\footnote{Here "atom" refers to either a neutral atom or an ion}, whilst in the latter the atom either absorbs sufficient energy to free a previously bound electron, or an ion loses sufficient energy to recombine with a free electron.

In addition to the obvious spontaneous emission and absorption processes, there is also a process of stimulated emission which is needed to balance the transitions. This occurs when an electron is stimulated to transition between levels by photons with the same frequency and direction as the photon produced by this transition.

In the following we will discuss how to obtain the frequency- and direction-dependent outgoing radiation given the emissivity and opacity of the plasma, and how to obtain a self-consistent radiation field and populations for the atomic species outside of the approximations of local thermodynamic equilibrium.

\subsection{The Formal Solution}

For a one-dimensional planar atmosphere the radiative transfer equation (RTE) can be written as
\begin{equation}
    \frac{1}{c}\frac{\partial I(\nu, \vec{d})}{\partial t} + \mu \frac{\partial I(\nu, \vec{d})}{\partial z} = \eta(\nu, \vec{d}) - \chi(\nu, \vec{d})I(\nu, \vec{d}).
\end{equation}
We consider that the light crossing time for the propagation of light on a solar scale is small compared to the time-evolution of the atmosphere and our observations and therefore ignore the time-derivative term.
Defining the source function $S(\mu, \vec{d}) = \eta(\nu, \vec{d}) / \chi(\nu, \vec{d})$, and the optical depth along a ray from the observer as the number of photon mean free paths along this segment $\tau(z, \nu, \vec{d}) = \int_z^{z_{\mathrm{obs}}} = \chi_\nu(z^\prime) / \mu\, dz^\prime$ we can write the RTE as.
\begin{equation}
    \frac{\partial I(\nu, \vec{d})}{\partial \tau(\nu, \vec{d})} = I(\nu, \vec{d}) - S(\nu, \vec{d}).
    \label{Eq:1DRte}
\end{equation}

Equation \ref{Eq:1DRte} is a first-order linear differential equation and can be solved with the integrating factor $e^{-\tau(\nu, \vec{d})}$ giving

\begin{equation}
I(\tau_0, \nu, \vec{d}) = I(\tau_1, \nu, \vec{d}) e^{-(\tau_1 - \tau_0)} + \int_{\tau_0}^{\tau_1}S(t_\nu, \nu, \vec{d})e^{-(t_\nu - \tau_0)}\, dt_\nu,
\label{Eq:IntegratedRte}
\end{equation}
for $\tau_0$ the optical depth at the observer and $\tau_1 > \tau_0$ along the line of sight.

The solution in equation \ref{Eq:IntegratedRte} prescribes nothing about the form of the source function in the atmosphere, and assumes that it varies continuously.
Whilst there are approaches such as Feautrier's \citep{Feautrier1964} that involve casting the problem as a second order differential equation we shall focus on the so-called short-characteristic method consisting of solving the RTE directly between discrete points by prescribing a functional form for its variation between these points. Due to the Feautrier method solving the problem for both an up-going and a down-going ray simultaneously, it cannot handle both Doppler shifts and overlapping lines, for these reasons, we will not discuss it further.

\subsection{Short-Characteristics Methods}\label{Sec:ShortChar}

If a functional form with an analytic integral is chosen for the variation of the source function between defined points then an atmosphere can be treated as a sum of analytic integrals. We shall consider the simplest useful functional form, a linear variation as an illustrative example.
This approach was first presented by \citet{Olson1987}.

The RTE for one slab of a plane-parallel atmosphere (in the case of outgoing radiation (i.e. $\mu > 0$)) can then be written

\begin{equation}
    I(\tau_0) = I(\tau_1) \exp(- |\tau_0 - \tau_1|) + \int_{\tau_0}^{\tau_1} S(t) \exp(-(t - \tau_0))\, dt.
    \label{Eq:ShortCharForm}
\end{equation}

Now, assuming a linear variation of $S$ with $\tau$ in this slab gives

\begin{equation}
    S(t) = S_{\tau_0} \frac{\tau_1-t}{\tau_1-\tau_0} + S_{\tau_1} \frac{t-\tau_0}{\tau_1-\tau_0},
\end{equation}

where $S_{\tau_i}$ indicates the value of the source function at optical depth $\tau_i$.
This can then be substituted into \eqref{Eq:ShortCharForm} (with $\Delta := \tau_1 - \tau_0$) giving

\begin{equation}
    I(\tau_0) = I(\tau_1) \exp(- |\tau_1 - \tau_0|) +
    \frac{\Delta - 1 + \exp(-\Delta)}{\Delta} S_{\tau_0} +
    \frac{1 - \exp(-\Delta) - \Delta\exp(-\Delta)}{\Delta} S_{\tau_1}.
\end{equation}

In atmospheres with very well resolved spatial grids, this method works quite well, however whenever the true source function has positive curvature, the intensity is overestimated, and underestimated for negative curvature. These effects can become quite significant in more sparsely sampled atmospheres.

The short characteristics method can be improved by using higher order polynomial interpolants, however these can lead to spurious ringing artifacts, negatively affecting their precision. One commonly used robust alternative is the monotonic piecewise parabolic method of \citet{Auer1994}. This method assumes a parabolic variation of the source function across local three point stencils, but limits it to the value obtained from linear interpolation if the parabolic interpolant exits the range bounded by these three points.

Other interpolating functions can be used. For example, the cubic Bézier spline interpolant of \citet{DelaCruzRodriguez2013}, provides a higher order approximation in regions of smooth variation, and can be limited through the control points to prevent any ringing instability. A similar approach has been taken with the BESSER quadratic Bézier spline approach of \citet{Stepan2013}.
All of these methods can be derived analagously to the linear formal solver presented above.

\subsection{Other Formal Solvers}

\citet{Janett2018} proposes a novel approach to the formal solver,  using an optimised solver for the differing optical thickness in each slab. They show that this leads to substantial performance benefits whilst also being more numerically stable. They comment that whilst higher order formal solvers will theoretically converge better to the true result, due to the assumptions that are made in their derivation, this will only occur if the variation of the source function in relevant regions of the atmosphere is sufficiently smooth. The modern 3D RMHD simulations use relatively coarse spatial grids with large transients in atmospheric parameters that risk provoking instability in the higher order formal solvers, especially in the case of full Stokes radiative transfer.
As work continues on these higher resolution RMHD simulations an investigation into how each formal solver handles discontinuous parameters is needed, but an accurate treatment of steep gradients and discontinuities is important to all RT modelling, as a reduction in the spatial resolution needed to correctly evaluate radiative transfer can lead to significant reductions in computational requirements, making more complex simulations possible.


\subsection{LTE vs NLTE}

\TODO{Rewrite from here}

With the formal solvers discussed in the previous section, and knowledge of the emissivity and opacity throughout an atmospheric model, the outgoing radiation can be computed directly. As the emissivity and opacity of the plasma depend primarily on the atomic level populations, knowledge of these is sufficient for computing the radiation.
This is the case if the plasma is in local thermodynamic equilibrium (LTE), which typically occurs if the plasma is sufficiently collisional, for example in the photosphere. The atomic populations are then described entirely by the thermodynamic properties (temperature and density) of the atmosphere and can be computed by application of the Saha-Boltzmann equation.\footnote{If the electron density is not known \textit{a priori} then an iteration scheme using the Saha-Boltzmann equation is necessary to determine consistent values of both the electron density and the atomic populations.}

\TODO{https://science.sciencemag.org/content/132/3429/707}
Unfortunately, the LTE description is inadequate, as discussed by Jefferies and Thomas \NeedRef{}, and everything outside of this is termed non-LTE (NLTE). In fact, due to the detailed balance of an LTE treatment, if detailed balance applied throughout the stellar atmosphere, no radiation would be able to escape. As photons are able to escape from the upper layers of the atmosphere, there is insufficient absorption processes to balance the emission processes and these layers must be NLTE. This is particularly clear for the chromosphere and transition region where a non-monotonic temperature gradient could not arise if the atmosphere were in LTE.
Departures from an LTE description of the plasma are therefore expected when the radiative rates become comparable or larger than the collisional rates, and where the radiation field is not black-body like.
We distinguish here, and in the following, between radiative transitions (due to spontaneous emission and absorption, and stimulated emission), and collisional transitions (due to collisions between particles).

Thus for an $N$-level atom we have the total transition rate between levels $i$ and $j$ (by convention $i < j$)
\begin{equation}
    P_{ij} = R_{ij} + C_{ij},
\end{equation}
where $R_{ij}$ is the rate of radiative transitions and $C_{ij}$ is the rate of collisional transitions.
As the total population of each element must remain constant we can write the kinetic equilibrium equation (which can be derived from the Boltzmann equation)
\begin{equation}
    \frac{\partial n_l}{\partial t} + \nabla \cdot (n_l \vec{\varv}) = \sum_{l^\prime\neq l} (n_{l^\prime} P_{l^\prime l}) - n_l \sum_{l^\prime\neq l} P_{ll^\prime}.
    \label{Eq:KinEq}
\end{equation}

Equation \eqref{Eq:KinEq} is commonly simplified to the statistical equilibrium equation, whereby the left-hand side is set to 0. In this case we are solving for a time-independent equilibrium value of the atomic populations, whereas the full kinetic equilibrium equation requires knowledge of the historic populations.

To solve \eqref{Eq:KinEq}, we require the values of $P_{ij}$ for the atoms present in the atmosphere; the collisional rates can be determined purely from local parameters, however due to the effects of stimulated emission the radiative rates are coupled to the local radiation field, which originates from elsewhere in the atmosphere. This effect couples all layers of the atmosphere together and is the primary source of the complexity of the NLTE problem. In collisional LTE plasmas the collisional rates dominate and the Saha-Boltzmann equation holds.

To mathematically describe these effects we must first arrive at a definition of emissivity and opacity.
Spectral lines have a rest frequency $\nu_{ij}$  defined by
\begin{equation}
    \nu_{ij} = \frac{h}{\Delta E_{ji}},
\end{equation}
where $h$ is Planck's constant and $\Delta E_{ji}$ is the energy difference between levels $j$ and $i$.
Such a transition between states in a plasma with no bulk velocity is not infinitely fine, but is broadened by a number of factors such as natural broadening from uncertainty in the lifetime of the upper state, Doppler broadening due to random thermal motions in the plasma, and collisional broadening.
The net effects of these processes typically leads to spectral line profiles being modelled as a Voigt function (the convolution of Gaussians and Lorentzians). The normalised line absorption profile then describes the probability of a photon with a certain energy being absorbed by the transition.

\TODO{Discuss line profile construction in more depth, discuss emission/PRD.}

Returning now to the radiative rates for bound-bound processes; the Einstein coefficients $A_{ji}$, $B_{ij}$, and $B_{ji}$ respectively describe the spontaneous emission, absorption, and stimulated emission processes.
The radiative rates can then be written
\begin{align}
    R_{ij} &= \oint \int B_{ij} \phi(\nu, \vec{d}) I(\nu, \vec{d})\,d\nu\,d\Omega,\\
    R_{ji} &= \oint \int \left[\left(A_{ji} + B_{ji} I(\nu, \vec{d})\right)\psi(\nu, \vec{d}) \right]\,d\nu\,d\Omega,
    \label{Eq:BbRates}
\end{align}
where $\phi$ is the line absorption profile, $\psi$ is the line emission profile, $A$ and $B$ are the Einstein coefficients for the transition, and $I(\nu, \vec{d})$ is the specific intensity at this location for a given frequency and direction.
These can be expressed similarly for bound-free transitions
\begin{align}
    R_{ij} &= \oint \int \alpha_{ij}(\nu) I(\nu, \vec{d})\,d\nu\,d\Omega,\\
    R_{ji} &= \oint \int \left[\left(I(\nu, \vec{d}) + \frac{2h\nu^3}{c^2}\right) \alpha_{ij}(\nu)n_e\Phi_{ij}(T) e^{-h\nu/k_B T} \right]\,d\nu\,d\Omega,
\end{align}
where $h$ is Planck's constant, $c$ is the speed of light, $\alpha_{ij}$ is the photoionisation cross-section, $k_B$ is Boltzmann's constant, and $n_e$ is the electron number density.
$\Phi$ is the Saha-Boltzmann equation defined such that
\begin{equation}
    n_e\Phi_{ij}(T) = \frac{n^*_i}{n^*_j} = \frac{g_i}{2g_j}\left( \frac{h^2}
    {2\pi m_e k_B T} \right)^{3/2} \exp{\left(  \frac{\Delta E_{ji}}{k_B T}\right)},
\end{equation}
where $n^*$ is the population of the species in LTE, $m_e$ is the electron mass, $\Delta E_{ji}$ is the energy difference between levels $j$ and $i$, and $g_i$ is the statistical weight of level $i$.

Following now the notation of \citet{Rybicki1992} and \citet{Uitenbroek2001} the emissivity $\eta$ and opacity $\chi$ for a transition are written
\begin{align}
    \label{Eq:Emis}
    \eta_{ij} &= n_j U_{ji}(\nu, \vec{d}), \\
    \label{Eq:Opac}
    \chi_{ij} &= n_i V_{ij}(\nu, \vec{d}) - n_j V_{ji}(\nu, \vec{d}),
\end{align}
where $n_i$ is the population density level $i$.
The $U$ and $V$ terms are defined for bound-bound and bound-free transitions as
\newlength{\WidestCase}
\settowidth{\WidestCase}{$n_e\Phi_{ij}(T)\left(\frac{2h\nu^3}{c^2}\right)e^{-h\nu/k_B T}\alpha_{ij}(\nu),$}
\begin{align}
    \label{Eq:Uji}
    U_{ji} =&
    \begin{cases}
        \frac{h\nu}{4\pi}A_{ji}\psi_{ij}(\nu, \vec{d}), & \textrm{bound-bound} \\
        n_e\Phi_{ij}(T)\left(\frac{2h\nu^3}{c^2}\right)e^{-h\nu/k_B T}\alpha_{ij}(\nu), & \textrm{bound-free},
    \end{cases}\\
%
    \label{Eq:Vij}
    V_{ij} =&
    \begin{cases}
        \makebox[\WidestCase][l]{$\frac{h\nu}{4\pi}B_{ij}\phi_{ij}(\nu, \vec{d}),$} & \textrm{bound-bound} \\
        n_e\Phi_{ij}(T)e^{-h\nu/k_B T}\alpha_{ij}(\nu), & \textrm{bound-free},
    \end{cases}\\
%
    \label{Eq:Vji}
    V_{ji} =&
    \begin{cases}
        \makebox[\WidestCase][l]{$\frac{h\nu}{4\pi}B_{ji}\psi_{ij}(\nu, \vec{d}),$} & \textrm{bound-bound} \\
        \alpha_{ij}(\nu), & \textrm{bound-free}.
    \end{cases}
\end{align}
By convention we define $U_{ij} = U_{ii} = V_{ii} = 0$ and $\chi_{ij} = -\chi_{ji}$.

In the approximation of complete redistribution (which we will return to later) we have $\phi_{ij} = \psi_{ij}$ then
\begin{align}
    R_{ij} &= B_{ij}\bar{J}_{ij} \\
    R_{ji} &= A_{ji} + B_{ji}\bar{J}_{ij},
\end{align}
where $\bar{J}_{ij}$ is the absorption profile weighted integrated mean intensity, i.e.
\begin{equation}
    \bar{J}_{ij} = \frac{1}{4\pi}\oint\int \phi_{ij}(\nu, \vec{d}) I(\nu, \vec{d})\, d\nu\, d\Omega.
\end{equation}

Where multiple atomic species are present, the total emissivity and opacity are simply the sum of the emissivity and opacity for every transition on each atom at the current frequency and direction. It is common to additionally consider scattering by processes such as Thomson scattering, in which case the source function will be written
\begin{equation}
    S(\nu, \vec{d}) = \frac{\eta_\mathrm{tot}(\nu, \vec{d}) + \sigma(\nu)J(\nu)}{\chi_\mathrm{tot}(\nu, \vec{d})},
\end{equation}
where $\sigma$ describes the frequency dependent scattering cross-section, and $J(\nu)$ is the angle-averaged intensity at a frequency.

Now we have an expression for the radiative rates in each line that can be computed numerically given the local value of the intensity, however the radiation field is not known \textit{a priori}. Clearly an iteration scheme will therefore be needed to find a stable set of populations yielding a self-consistent radiation field.

If we treat the formal solver as an operator yielding the intensity from the source function throughout the atmosphere, i.e.
\begin{equation}
    I(\nu, \vec{d}) = \Lambda_{\nu,\vec{d}}[S(\nu, \vec{d})],
    \label{Eq:LambdaOperator}
\end{equation}
then starting from an initial estimate of the atomic populations (e.g. LTE) we can compute the radiation field throughout the atmosphere and iteratively use this to update the populations by solving \eqref{Eq:KinEq}. This is known as Lambda iteration and presents woefully poor convergence in optically thick conditions as the size of the population updates stagnate long before the true NLTE populations are obtained.

The failure of Lambda iteration can be remedied by a process known as operator splitting, first introduced by \citet{Cannon1973} whereby we set
\begin{equation}
    \Lambda = \Lambda^* + (\Lambda - \Lambda^*),
\end{equation}
with $\Lambda^*$ an approximation of $\Lambda$. The iteration scheme them becomes
\begin{equation}
    I(\nu, \vec{d}) = \Lambda_{\nu, \vec{d}}^*[S(\nu, \vec{d})] + (\Lambda_{\nu, \vec{d}} - \Lambda_{\nu, \vec{d}}^*)[S^{\dagger}(\nu, \vec{d})],
    \label{Eq:Ali}
\end{equation}
where $\dagger$ identifies values from the previous iteration. This method is termed accelerated Lambda iteration (ALI), and can be shown to accelerate convergence by significantly amplifying the size of the corrections at large optical depths, for an appropriately chosen $\Lambda^*$.
From \eqref{Eq:Ali} we can see that it is necessary to invert $\Lambda^*$ to obtain the updated value of $S$ (on which $I$) is also dependent. For a two-level atom this is discussed at length in Chapters 12 and 13 of \citet{Hubeny2014}.
The full coupling of these terms in the multi-level NLTE problem will be made explicit in a following section when the MALI methods are presented; for now it is clear that the source function depends on the emissivity and opacity of each species, which in turn are controlled by the atomic populations, which are affected by the local radiation field (see \eqref{Eq:BbRates}).

A good choice for $\Lambda^*$ is not immediately evident, as it should be cheap to construct and invert, whilst providing a good approximation of $\Lambda$. \citet{Scharmer1981} presented an approximate operator that fits these criteria and showed its congruency with the core-saturation approach of Rybicki \NeedRef{} (where the net rates in the line core and wing are treated separately to precondition the net radiative rates by removing the large proportion of photons that are emitted in the wing and immediately reabsorbed).

\citet{Olson1986} proposed the use of the diagonal of the true $\Lambda$ operator as an approximate operator, and showed that this is close to optimal, and is clearly trivial to invert (as it is a scalar). Now, the diagonal of $\Lambda$ is easy to obtain by setting a test source function $\mathcal{S}=\delta_{dd^\prime}$ (where $\delta$ is the Kronecker delta) and computing
\begin{equation}
    \Lambda^* = \Lambda[\mathcal{S}].
\end{equation}
Taking the example of the linear short characteristic formal solver presented in Sec.~\ref{Sec:ShortChar} and substituting this definition of $\mathcal{S}$ we obtain
\begin{equation}
    \Lambda^*_{\nu, \vec{d}} = \frac{\Delta - 1 + \exp(-\Delta)}{\Delta}.
\end{equation}
The approximate operator can be computed analogously for other formal solvers.

\subsection{Solving the multilevel NLTE problem}

Starting from the radiative transfer equation \eqref{Eq:1DRte} and the kinetic equilibrium equation \eqref{Eq:KinEq} we can construct a framework with which to solve the multilevel NLTE problem. We follow the approach of \citet{Rybicki1992} and \citet{Uitenbroek2001}, and present the problem in statistical equilibrium, although it generalises directly to non-zero left-hand sides on \eqref{Eq:KinEq}.

Substituting \eqref{Eq:LambdaOperator} into \eqref{Eq:KinEq}, and expanding the radiative rates gives
\begin{equation}
\begin{aligned}
   &\sum_{l^\prime\neq l} (n_{l^\prime}C_{l^\prime l}) +
   \sum_{l^\prime\neq l} \oint \int \frac{1}{h\nu} n_{l^\prime} (U^\dagger_{l^\prime l} + V^\dagger_{l^\prime l} I(\nu, \vec{d}))\, d\nu\, d\Omega\\
   -
   n_l &\sum_{l^\prime\neq l} C_{l l^\prime} -
   n_l \sum_{l^\prime\neq l} \oint \int \frac{1}{h\nu} (U^\dagger_{l l^\prime} + V^\dagger_{l l^\prime} I(\nu, \vec{d}))\, d\nu\, d\Omega
   = 0.
   \label{Eq:StatEqExpanded}
\end{aligned}
\end{equation}
$U$ and $V$ are marked with daggers despite their constant appear in the CRD case, as this will be needed when discussing partial frequency redistribution later.
\citet{Rybicki1992} defined a new operator $\Psi$ such that
\begin{equation}
    \Psi_{\nu, \vec{d}}[y] = \Lambda_{\nu, \vec{d}}[(\chi^\dagger)^{-1}y]
\end{equation}
These two operators are equivalent for a converged solution as $\chi^\dagger = \chi$.

The operator splitting technique can again be applied here. We then have
\begin{equation}
    I(\nu, \vec{d}) = \Psi^*[\eta(\nu, \vec{d})] + (\Psi - \Psi^*)[\eta^\dagger(\nu, \vec{d})],
\end{equation}
and then considering the effects on one atom, under the assumption that background emissivity and opacity do not change during an iteration
\begin{equation}
    I(\nu, \vec{d}) = I^\dagger(\nu, \vec{d})
                    - \sum_j\sum_{i<j}\Psi^*[n^\dagger_j U^\dagger_{ji}]
                    + \sum_j\sum_{i<j}\Psi^*[n_j U^\dagger_{ji}].
\end{equation}

The first two terms of this expression are often termed $I^\mathrm{eff}$ and in the case of a diagonal $\Psi^*$ operator this represents the non-local contribution to the radiation field from the current atom, and the contribution from all other species.

We can write \eqref{Eq:StatEqExpanded} as
\begin{equation}
    \Gamma \vec{n} = 0,
    \label{Eq:StatEqMatVec}
\end{equation}
where $\Gamma$ is a matrix consisting of the sum of $\Gamma^R$ due to the radiative contributions, and $\Gamma^C$ from the collisional contributions. $\vec{n}$ is the vector of the current level populations for the species at this point in the atmosphere.
We can then write
\begin{align}
\begin{split}\label{Eq:GammaR}
    \Gamma^R_{ll^\prime} = \oint \int \frac{1}{h\nu} \bigg( U^\dagger_{l^\prime l} + V^\dagger_{l^\prime l}I_{\nu, \vec{d}}^\mathrm{eff} -
    \left(\sum_{m\neq l}\chi^\dagger_{lm}\right) \Psi^*_{\nu, \vec{d}} \left[ \sum_p U^\dagger_{l^\prime p} \right] \bigg)\, d\nu\,d\Omega
\end{split}
\end{align}
for $l\neq l^\prime$. The problem is now represented by a system of linear equations. Due to the necessity of total number conservation each column of $\Gamma$ must be 0, which allows us to compute the diagonal terms as
\begin{equation}
    \Gamma_{ll} = -\sum_{m\neq l} \Gamma_{ml}.
\end{equation}

Iterating the populations through \eqref{Eq:StatEqMatVec} with interleaved formal solutions gives us a reliable and rapidly converging method for solving the multilevel NLTE problem with multiple atoms and overlapping transitions as used in the \Lw{} framework. More detail on the implementation are provided in the associated technical report \citep{Osborne2021} and in the documentation \NeedRef{}.

\subsection{Time-Dependent Population Updates}\label{Sec:TimeDepPopUpdates}

As discussed previously an update to the populations solving for statistical equilibrium can be phrased as $\Gamma \vec{n} = \vec{0}$. A variant of this method can also be applied to the time-dependent form of the kinetic equilibrium equations. We will not directly treat the advection term of equation \eqref{Eq:KinEq}, as this requires consideration of hydrodynamic effects and the discretisation schemes used therein (due to the large gradients of these populations that occur in the solar atmosphere).
We can, however, discretise $\partial n / \partial t = \Gamma \vec{n}$ as
\begin{equation}
    \label{Eq:ThetaDisc}
    \frac{\vec{n}^{t+1} - \vec{n}^t}{\Delta t} = \theta \Gamma^{t+1} \vec{n}^{t+1} + (1-\theta)\Gamma^{t} \vec{n}^{t},
\end{equation}
where $\theta$ indicates the degree of implicitness, the $t$ and $t+1$ indices indicate the start and end of the timestep being integreated respectively, and $\Delta t$ the duration of the timestep.
$\vec{n}^{t+1}$ can then be found by rewriting \eqref{Eq:ThetaDisc} as
\begin{equation}
    \label{Eq:TimeDepSystem}
    (\mathbb{I} - \theta\Delta t \Gamma^{t+1}) \vec{n}^{t+1} = (1-\theta)\Delta t \Gamma^{t}\vec{n}^{t} + \vec{n}^{t},
\end{equation}
with $\mathbb{I}$ the identity matrix, and iterating until $\vec{n}^{t+1}$ converges, for a new evaluation of $\Gamma^{t+1}$ at each iterate.

\subsection{Collisional Rates}

There are many collisional processes by which electrons can transition between levels in a plasma, including ionisation and recombination processes. These include excitation of ions by electrons, ionisation and excitation of neutral by electrons, excitation by protons and neutral hydrogen, as well as charge exchange with these species. There are other more advanced formulations too. Typically these are all empirical functional fits from laboratory and observational data, and are simply provided in a tabulated form. They are assumed to only depend on local plasma properties, such as the temperature, total particle density and electron density.

\NeedRef{}

\subsection{Partial Frequency Redistribution}

Most solar spectral lines form in regions where complete frequency redistribution (CRD) holds. That is to say that the plasma is sufficiently collisional that elastic collisions redistribute electrons across all sub-states of an energy level prior to emission. In this case the emission frequency of a photon is not correlated with the frequency of the photon absorbed to excite the atom into this state i.e. photons are completely redistributed in frequency and the line emission and absorption profiles are equal. In lower density regions with strong (typically resonance) lines, where radiative effects dominate over collisional effects, there is said to be a natural population of a certain level; a population where the emission frequency is correlated to the absorption frequency, and has not been redistributed by collisions \citep{Hubeny2014}.
In this case the emission and absorption profiles for the line differ and this coherent scattering must be treated explicitly. This imposes substantial computational effort, but we will briefly describe the key points of the process, and how it fits into MALI following \citet{Uitenbroek2001} and \citet{Hubeny2014}.

We can define the emission profile coefficient $\rho_{ij} = \psi_{ij} / \phi_{ij}$, at which point all $U$ and $V$ terms can be rewritten in terms of $\rho$ and $\phi$, and $\dagger$ on these terms refers to the value of $\rho_{ij}$ evaluated at the previous iterate (analogous to $n^\dagger$).

From this definition of $\rho$, under the assumptions of a line with an infinitely sharp lower level and broadened upper level, and the validity of PRD being in the atomic frame being approximated by PRD in the observer's frame \citep{Uitenbroek2001}, following \citet{Hubeny2014} we then have
\begin{align}
\begin{split}
    \rho_{ij}(\nu, \vec{d}) = 1 + &\gamma\frac{\sum_{l < j}n_j B_{lj}}{n_j P_j} \oint\frac{1}{4\pi}\int I(\nu^\prime, \vec{d}^\prime) \\ &\cdot \left[ \frac{R^{II}_{lji}(\nu^\prime, \vec{d}^\prime; \nu, \vec{d})}{\phi_{ij}(\nu, \vec{d})} - \phi_{lj}(\nu^\prime, \vec{d}) \right]\,d\nu^\prime\,d\Omega^\prime,
\end{split}
\end{align}

where $R^{II}$ is the generalised redistribution function for transitions of this kind \citep{Hubeny1982}, and $\gamma$ is the branching ratio, or coherency fraction.
The summation over $l$ and $lji$ subscript on $R^{II}$ describe the scattering process.
When ignoring cross-redistribution (Raman scattering), we have $l=i$, and the summation is replaced by a single term, as we are only considering resonance scattering within the line $i\rightarrow j$.

The coherency fraction $\gamma$ describes the normalised probability of a photons being re-emitted from the same sublevel of energy level $j$ before an elastic collision that will redistribute it across sublevels, provided that it is re-emitted at all.
This is then given by
\begin{equation}
    \gamma = \frac{P_j}{P_j + Q_j},
\end{equation}
where $P_j$ is the total rate of transitions out of level $j$ (depopulation rate), and $Q_j$ is the total rate of elastic collisions affecting this level.

Defining $g_{II}(\nu, \nu^\prime) = R^{II}(\nu, \nu^\prime)/\phi_{ij}(\nu^\prime)$, which is normalised such that
\begin{equation}
    \label{Eq:gIINorm}
    \frac{1}{4\pi}\oint\int g_{II}(\nu, \nu^\prime) \,d\nu^\prime\,d\Omega= 1,
\end{equation}
as per \citet{Gouttebroze1986} and \citet{Uitenbroek1989} wherein fast approximations to this function are derived, and ignoring cross-redistribution we then have
\begin{align}
\begin{split}
    \label{Eq:RhoPrd}
    \rho_{ij}(\nu, \vec{d}) = 1 + & \gamma \frac{n_i B_{ij}}{n_j P_j} \oint \frac{1}{4\pi} \int I(\nu^\prime, \vec{d}^\prime) \\ & \cdot\left[ g_{II}(\nu, \nu^\prime) - \phi_{ij}(\nu^\prime, \vec{d}) \right]\,d\Omega^\prime\,d\nu^\prime.
\end{split}
\end{align}

Ignoring bulk plasma flows, the integrals over angle and frequency can then be split, providing an angle-averaged form of $\rho$ that is much easier to compute. The hybrid PRD method of \citet{Leenaarts2012} provides an approximate solution to the angle-dependent PRD problem with bulk flows, by interpolating the radiation field to the rest frame of the plasma where this simpler form approximately holds.

\subsection{Charge Conservation}
\subsubsection{Statistical Equilibrium}
\subsubsection{Time-Dependent}

\subsection{Determining Numerical Convergence}

\section{The \Lw{} Framework}

The \Lw{} framework \citep{Osborne2021, LightweaverZenodo}\footnote{\Lw{} is freely available under the permissive MIT license and is developed on GitHub (\url{https://github.com/Goobley/Lightweaver}) with archival on Zenodo.} is a Python package built around a C++ core in which we have implemented the methods for numerical NLTE radiative transfer discussed in Sec.~\ref{Sec:IntroRT}.
As can be seen from the referencing of the previous section, none of these methods are novel on their own -- they represent the most robust methods encountered in our survey of NLTE RT -- and it is in the combination of these methods and in the implementation strategies employed that \Lw{} differs from current \Sota{} RT codes.
An overview of the key components and functions that users will typically interact with is presented in \citet{Osborne2021}, in the following we describe the most important design decisions made in \Lw{} and explain how they can enable new forms of RT simulations whilst also increasing productivity.

\subsection{Philosophy}

The design of the \Lw{} framework is inspired by deep learning frameworks, such as PyTorch \citep{PyTorch}.
These have risen to prominence in recent years, due to their low barrier to entry, whilst still providing a customisable, full-featured, interface to the underlying methods that can be manipulated with pure Python code.
Machine learning frameworks provide a collection of building blocks that can be combined in multiple ways to allow researchers to construct new tools, specifically tailored to the problem they wish to address.
Whilst there can be slight performance gains from using a specialised, optimised, \Sota{} method implemented in a performance-focused language for this particular task, the benefits are likely outweighed by the additional development time.
This is especially true in research environments where tools are often used by a small group of researchers in a transient fashion, and the return on \emph{possible} optimisations is rarely sufficiently large compared to the benefits of increased development speed that a framework allows.
The use of a tested framework also allows researchers confidence in the core numerics they are reusing, whether they understand every detail or not.

The steps involved in solving the NLTE RT problem are quite modular, and we provide optimised methods for most of these following the standard techniques outlined previously.
They are building blocks that can be combined in different ways (with some omitted), to produce different tools.
These building blocks are the core offering of the \Lw{} framework, and are intended to be combined by the user in a new Python program to solve their particular problem.
If at any point a user wishes to fully replace a core component of \Lw{}, this can be done in Python, inside their program, with no modification the framework itself, whilst the other components can continue to be used as before.
This flexibility is encompassed by one of the core design goals, which is to allow Python code written by the user to ``interfere'' with all of the numerical treatment of the NLTE problem.

All other RT codes that the author has interacted with have been designed with a strict limit of one simulation per computer process.
Whilst this limitation does make the design of the program easier, especially in Fortran and C, it is not beneficial to an end user who may, for example, wish to couple multiple simulations with different atomic configurations, or use one as a radiative boundary condition for another.
This latter configuration is applied extensively in Chap.~\ref{Chap:2DRT} where two plane-parallel models are used as boundary conditions for a two-dimensional slab.
Whilst there are other solutions to this problem, such as saving necessary data and loading it in a reconfigured program, these are typically more error-prone than a simple program which can flexibly represent the coupling between these models in its code, even allowing for memory sharing of certain components.
To this end, each RT simulation performed in \Lw{} occurs in a self-contained \texttt{Context}, a Python object containing all necessary configuration and storage needed for this model.
These can be serialised using the \texttt{pickle} package of the Python standard library, allowing for a complete simulation to be dumped to disk or transferred between processes using the standard approach expected in the Python ecosystem.
This has impacts on parallelisation which will be discussed in Sec.~\ref{Sec:LwParallelisation}.

\subsection{Accessibility \& Code Overview}

One of the aims of \Lw{} is to attempt to reduce the barrier to entry for new users, thus we ensure that it is simple to install with pre-compiled libraries available.
Thus a user with a Python environment (version $\ge3.8$) using an x86-64 CPU supporting AVX vector extensions (essentially any Intel or AMD chip from the past decade) on any of macOS\footnote{Preliminary support of Apple's ARM CPUs is present, but several underlying libraries do not yet support this.}, Windows, or Linux, can install the package in one command using the Python package manager \texttt{pip}.
No additional compilation steps are necessary, and any additional libraries are automatically sourced during installation.
Whilst slight performance benefits can likely be acquired by using a modern compiler to tune the code generated to the user's machine (and this option is available for advanced users), the option of automatically installing a tested release version of the library in under \SI{60}{\second} was an important goal that has easily been achieved thanks to Python's well-supported packaging systems.

All interfaces to the framework are thoroughly documented through the Python docstring convention (internally to the source files) and can be used to automatically generate HTML or \LaTeX{} documentation.
This can also be viewed online at \url{https://goobley.github.io/Lightweaver}.

As of v0.7.3, excluding automatically generated code (of which we make extensive use), the \Lw{} frontend consists of 4520 lines of Python, with 2326 lines of comments and documentation.
777 of these consist of an implementation of the equation of state originally authored by Wittmann following \citet{Mihalas1978}, and ported to Python by J. de la Cruz Rodriguez and is used here with permission.
This is an LTE equation of state that has been used in both the SIR \citep{1992RuizCobo} and NICOLE \citep{Socas-Navarro2015} codes.

The backend consists of 9896 code lines of personally authored C++, along with two external libraries: Faddeeva\footnote{\url{http://ab-initio.mit.edu/wiki/index.php/Faddeeva_Package}} (Steven G. Johnson, 2066 lines of code, MIT license) used for computing Voigt functions, and a lightweight multi-platform thread pool and scheduler\footnote{\url{https://github.com/vurtun/lib/blob/master/sched.h}} (Doug Binks \& Micha Mettke, 788 lines of code, zlib license).
As both of these libraries are small and permissively licensed, they are included directly in \Lw{}'s distribution, so there is no concern about these links going stale.
Multiple routines present in the calculation of the background terms are thread-safe reimplementations of those used in RH \citep{Uitenbroek2001}, with permission.
There are also 2439 lines of Cython \citep{Behnel2011} code present in the backend.
Cython is a language used to bridge the Python interfaces to the C++ core.
It allows us to share NumPy \citep{Harris2020} arrays by reference between Python and C++, allowing changes to the array's contents to be visible from either language with no duplication necessary.
This data sharing is not just efficient but allows the Python frontend to be ``involved'' with the RT calculations on a deep level in line with \Lw{}'s design goals.

\subsection{Model Atoms}

An oft-quoted aphorism in programming circles is that of \emph{Greenspun's tenth rule of programming}\footnote{e.g. \url{https://philip.greenspun.com/research/}} which states: ``Any sufficiently complicated C or Fortran program contains an ad hoc, informally-specified, bug-ridden, slow implementation of half of Common Lisp''.
The implementation of model atoms in the codes the author is personally familiar with are examples of this.
This is not to say that configuration files containing the data needed to run a program are bad, but we are instead referring to the large amount of logic associated with these files, that eventually turns into an \emph{ad hoc} domain specific language.
These models are structured and contain methods of specifying the approximations to be used for different terms, such as van der Waals broadening and bound-free cross sections.
Any new method that a user wishes to implement then has to be added to the custom interpreter responsible for parsing these files and propagating this information into the numeric core of the program.

A different approach to the problem of needing to specify data with \emph{associated} methods and approximations is to define a contract describing the information needed by the numerical core and allow the specific model to fulfil this contract through any means.
It is this approach we take in \Lw{}.
This means that model atoms need to be ``smart'' and have the ability to execute arbitrary code.
Implementing these models in Python makes this trivial, and its wide array of scientific libraries are also available\footnote{We stress that other languages could be used for this task, and they need not be dynamic ``scripting'' languages; for example, a similar approach could be achieved in C/C++ through the use of dynamic libraries.}.
As a ``free bonus'', thanks to the models being standard Python objects stored in source code, the Python interpreter will take care of parsing these models, through extremely well-tested code paths.

An \texttt{AtomicModel} in \Lw{} is the definition of an object containing an element or isotope identifier, and a list of each of levels, lines, continua, and collisional rate approximations.
Each of these terms is itself a Python object which must conform to a particular contract describing the form of the information it must be capable of supplying when a particular method is called.
Many of these objects also contain components with their own contracts.
These contracts are defined through the use of Python classes, and basic implementation of features, comparable to those in extant RT codes are implemented in the \Lw{} standard library.
These can be further extended with new functionality through the use of inheritance.
A user can therefore implement a new method for computing, say, the absorption profile \citep[e.g. the non Voigt profile of][]{Kowalski2017} of a spectral line and employ this by defining a new model atom with no changes needed in the \Lw{} package.

Atomic models can be supplied to user code in two different ways, in the textual source code, which is both human and machine readable, or in a \texttt{pickle}, which is only machine readable, possibly from a previously serialised \texttt{Context}.
The former of these is treated as a canonical form, and it can always be recovered by asking Python for the representation of the object (via the \texttt{repr} function).
This imposes certain a minor constraint on the way user constructed classes extending the components of these models need to be defined i.e. they must define a \texttt{\_\_repr\_\_} function defining how to recover a textual representation of themselves.
This is due to our adherence to the standard Python convention that \texttt{obj == eval(repr(obj))}, requiring that the evaluation (in the Python interpreter) of the textual representation of an object give an equivalent object.
This is explained in depth with the examples shown in \citet{Osborne2021}.

The use of Python objects and data structures to describe the model atoms does not only allow the models to execute arbitrary code, but also for the models to be manipulated for user code.
This makes managing and modifying atomic models easier as transformations (modifications of parameters) can be undertaken in bulk by code, rather than a painstaking manual process.
This is all achieved through the use of standard Python, with no custom code needed to support this.

\subsection{Parallelisation}\label{Sec:LwParallelisation}

The self-contained nature of the \texttt{Context} makes \Lw{} programs for computing grids of models easy to adapt to paradigms such as the Message Passing Interface \citep[MPI, e.g.][for an overview of the MPICH implementation]{Gropp1996} commonly used in high performance computing environments.
A proof of concept implementation utilising MPI for a grid of models was undertaken by Asensio Ramos (\emph{private communication}), running 10,000 models in 4 hours across 15 CPUs with no need to modify \Lw{}.

A secondary form of parallelisation is also incorporated into \Lw{}.
This form of parallelisation consists of splitting time-consuming work from a single simulation over multiple threads in the same machine.
This work primarily consists of the formal solution, accumulation of terms into the $\Gamma$ matrix, and calculation of any scattering integrals needed for PRD, which are parallelised over wavelength, and typically represent the vast majority of the program's runtime for non-trivial simulations.
The calculation of line absorption profiles, when using atomic models with the default Voigt profile implementation, along with the optional \texttt{FastBackground} implementation of background opacities, emissivities, and scatterings, are also parallelised.
The choices of the terms to parallelise has been motivated by our observations of the time-consuming processes when using \Lw{} to undertake the numerical experiments presented in Chaps.~\ref{Chap:TimeDepRt} and \ref{Chap:2DRT}.

\subsection{Validation}

The \Lw{} framework was extensively validated during development, primarily against RH \citep{Uitenbroek2001}, but also the synthesis module of SNAPI \citep{Milic2018} when discrepancies were found.
RH is a well-established code that serves as a cornerstone of NLTE RT in the solar physics community.
It assumes a stationary, time-independent atmospheric input, for which the statistical equilibrium solution of the atomic populations is computed.
The MALI method with full preconditioning \citep{Rybicki1992} is used, allowing for multiple atomic species with overlapping transitions to be considered, and implementations of angle-averaged and angle-dependent PRD are present following the method outlined in \citet{Uitenbroek2001}.
RH can also be used for NLTE modelling of molecular lines, but we do not make use of this here.
In the examples presented here, we make use of v2 of the RH code, distributed by H. Uitenbroek, and not the massively parallel RH 1.5D presented in \citet{Pereira2015}.

The synthesis module of SNAPI also uses a MALI method allowing for overlapping lines, with an implementation of the method entirely distinct to the one used in RH.
It assumes a CRD treatment of all spectral lines.

In the following we will present just a few of the validation cases that have been used during the development of \Lw{}.

%spell-checker: disable
\setpythontexautoprint{false}
\begin{pycode}[FlareModelling]
import lightweaver as lw
from lightweaver.rh_atoms import H_6_atom, C_atom, O_atom,  Si_atom, Al_atom, CaII_atom, Fe_atom, He_atom, MgII_atom, Mg_atom, N_atom, Na_atom, S_atom
from helita.sim.rh import Rhout
from lightweaver.fal import Falc82

atmos = Falc82()
atmos.quadrature(5)

aSet = lw.RadiativeSet([H_6_atom(), C_atom(), O_atom(), Si_atom(), Al_atom(),
                        CaII_atom(), Fe_atom(), He_atom(), Mg_atom(), N_atom(),
                        Na_atom(), S_atom()])
aSet.set_active('H', 'Ca')
spect = aSet.compute_wavelength_grid()

molPaths = [lw.get_default_molecule_path() + m + '.molecule' for m in ['H2']]
mols = lw.MolecularTable(molPaths)

eqPops = aSet.compute_eq_pops(atmos, mols)
ctx = lw.Context(atmos, spect, eqPops, Nthreads=8)
for i in range(5):
    ctx.formal_sol_gamma_matrices()

for i in range(300):
    dJ = ctx.formal_sol_gamma_matrices()
    dPops = ctx.stat_equil()

    if dJ < 3e-3 and dPops < 1e-3:
        break

atmos = Falc82()
atmos.quadrature(5)
eqPopsChargeCons = aSet.iterate_lte_ne_eq_pops(atmos, mols)
ctxCc = lw.Context(atmos, spect, eqPopsChargeCons, Nthreads=8, conserveCharge=True)
for i in range(5):
    ctxCc.formal_sol_gamma_matrices()

for i in range(300):
    dJ = ctxCc.formal_sol_gamma_matrices()
    dPops = ctxCc.stat_equil()

    if dJ < 3e-3 and dPops < 1e-3:
        break

atmos = Falc82()
atmos.quadrature(5)
eqPopsLte = aSet.iterate_lte_ne_eq_pops(atmos, mols)
ctxLte = lw.Context(atmos, spect, eqPopsLte, Nthreads=8, conserveCharge=False)
for i in range(5):
    ctxLte.formal_sol_gamma_matrices()

for i in range(300):
    dJ = ctxLte.formal_sol_gamma_matrices()
    dPops = ctxLte.stat_equil()

    if dJ < 3e-3 and dPops < 1e-3:
        break

wave = np.linspace(853.9444, 854.9444, 1001)
Iwave = ctx.compute_rays(wave, 1.0)
IwaveCc = ctxCc.compute_rays(wave, 1.0)
IwaveLte = ctxLte.compute_rays(wave, 1.0)

rh = Rhout(chFlareModelling.data_file('LwRhComparison/RhConfigAndOutput'))
rh.read_ray(chFlareModelling.data_file('LwRhComparison/RhConfigAndOutput/spectrum_1.00'))

ca = CaII_atom()
lambda0 = ca.lines[4].lambda0
fig = plt.figure(figsize=texfigure.figsize(pytex, scale=1.0, height_ratio=0.55))
plt.plot(rh.wave - lambda0, rh.int, label='RH')
plt.plot(wave - lambda0, Iwave, '--', label='Lightweaver')
plt.plot(wave - lambda0, IwaveLte, label='Lightweaver LTE $n_e$')
plt.plot(wave - lambda0, IwaveCc, label='Lightweaver Charge Cons.')
plt.xlabel(r'$\Delta\lambda$ [nm]')
plt.ylabel(r'Intensity [J\,m$^{-2}$\,s$^{-1}$\,Hz$^{-1}$\,sr$^{-1}$]')
plt.xlim(wave[0] - lambda0, wave[-1] - lambda0)
plt.legend(frameon=False)
lFig = chFlareModelling.save_figure('LwRhComparison', fig, fext='.pgf')
lFig.caption = r'Comparison of \Lw{} and RH synthesis of \CaLine{} from the FALC atmosphere with different electron density solutions.'
lFig.placement = 'htbp'
\end{pycode}
\begin{pycode}[FlareModelling]

_, atmos = lw.read_multi_atmos(chFlareModelling.data_file('FalSillyVelRunRh/FalVelocity.atmos'))
atmos.quadrature(5)

aSet = lw.RadiativeSet([H_6_atom(), C_atom(), O_atom(), Si_atom(), Al_atom(),
                        CaII_atom(), Fe_atom(), He_atom(), Mg_atom(), N_atom(),
                        Na_atom(), S_atom()])
aSet.set_active('Ca')
spect = aSet.compute_wavelength_grid()

molPaths = [lw.get_default_molecule_path() + m + '.molecule' for m in ['H2']]
mols = lw.MolecularTable(molPaths)

eqPops = aSet.compute_eq_pops(atmos, mols)
ctx = lw.Context(atmos, spect, eqPops, Nthreads=8)
for i in range(5):
    ctx.formal_sol_gamma_matrices()

for i in range(300):
    dJ = ctx.formal_sol_gamma_matrices()
    dPops = ctx.stat_equil()

    if dJ < 3e-3 and dPops < 1e-3:
        break

wave = np.linspace(853.9444, 854.9444, 1001)
Iwave = ctx.compute_rays(wave, 1.0)

rh = Rhout(chFlareModelling.data_file('FalSillyVelRunRh'))
rh.read_ray(chFlareModelling.data_file('FalSillyVelRunRh/spectrum_1.00'))

ca = CaII_atom()
lambda0 = ca.lines[4].lambda0
fig = plt.figure(figsize=texfigure.figsize(pytex, scale=1.0, height_ratio=0.55))
plt.plot(rh.wave - lambda0, rh.int, label='RH')
plt.plot(wave - lambda0, Iwave, '--', label='Lightweaver')
plt.xlabel(r'$\Delta\lambda$ [nm]')
plt.ylabel(r'Intensity [J\,m$^{-2}$\,s$^{-1}$\,Hz$^{-1}$\,sr$^{-1}$]')
plt.xlim(wave[0] - lambda0, wave[-1] - lambda0)
plt.legend(frameon=False)
lFig = chFlareModelling.save_figure('LwValidationSillyVel', fig, fext='.pgf')
lFig.caption = r'Comparison of \Lw{} and RH synthesis of \CaLine{} from the FALC atmosphere with complex velocity profile.'
lFig.placement = 'htbp'
# TODO(cmo): Add SNAPI here.
\end{pycode}
\begin{pycode}[FlareModelling]

_, atmos = lw.read_multi_atmos(chFlareModelling.data_file('RadynSnapT05NoPrd/Flat1e9NoIncRad_t05.atmos'))
atmos.quadrature(5)

aSet = lw.RadiativeSet([H_6_atom(), C_atom(), O_atom(), Si_atom(), Al_atom(),
                        CaII_atom(), Fe_atom(), He_atom(), MgII_atom(), N_atom(),
                        Na_atom(), S_atom()])
aSet.set_active('H', 'Ca')
spect = aSet.compute_wavelength_grid()

molPaths = [lw.get_default_molecule_path() + m + '.molecule' for m in ['H2']]
mols = lw.MolecularTable(molPaths)

eqPops = aSet.compute_eq_pops(atmos, mols)
ctx = lw.Context(atmos, spect, eqPops, Nthreads=16)
for i in range(5):
    ctx.formal_sol_gamma_matrices()

for i in range(300):
    dJ = ctx.formal_sol_gamma_matrices()
    dPops = ctx.stat_equil()

    if dJ < 3e-3 and dPops < 1e-3:
        break

eqPopsPrd = aSet.compute_eq_pops(atmos, mols)
ctxPrd = lw.Context(atmos, spect, eqPopsPrd, Nthreads=16, hprd=False)
for i in range(5):
    ctxPrd.formal_sol_gamma_matrices()

for i in range(300):
    dJ = ctxPrd.formal_sol_gamma_matrices()
    dPops = ctxPrd.stat_equil()
    dRho = ctxPrd.prd_redistribute()

    if dJ < 3e-3 and dPops < 1e-3:
        break

# eqPopsHPrd = aSet.compute_eq_pops(atmos, mols)
# ctxHPrd = lw.Context(atmos, spect, eqPopsHPrd, Nthreads=16, hprd=True)
# for i in range(5):
#     ctxHPrd.formal_sol_gamma_matrices()

# for i in range(300):
#     dJ = ctxHPrd.formal_sol_gamma_matrices()
#     dPops = ctxHPrd.stat_equil()
#     dRho = ctxHPrd.prd_redistribute()

#     if dJ < 3e-3 and dPops < 1e-3:
#         break

wave = np.linspace(393.377, 393.577, 1001)
Iwave = ctx.compute_rays(wave, 1.0)
IwavePrd = ctxPrd.compute_rays(wave, 1.0)
# IwaveHPrd = ctxHPrd.compute_rays(wave, 1.0)

rh = Rhout(chFlareModelling.data_file('RadynSnapT05NoPrd'))
rh.read_ray(chFlareModelling.data_file('RadynSnapT05NoPrd/spectrum_1.00'))
rhPrd = Rhout(chFlareModelling.data_file('RadynSnapT05Prd'))
rhPrd.read_ray(chFlareModelling.data_file('RadynSnapT05Prd/spectrum_1.00'))

ca = CaII_atom()
lambda0 = ca.lines[1].lambda0
fig = plt.figure(figsize=texfigure.figsize(pytex, scale=1.0, height_ratio=0.55))
plt.plot(rh.wave - lambda0, rh.int, label='RH CRD')
plt.plot(wave - lambda0, Iwave, '--', label='Lightweaver CRD')
plt.plot(rhPrd.wave - lambda0, rhPrd.int, label='RH PRD')
plt.plot(wave - lambda0, IwavePrd, '--', label='Lightweaver PRD')
# plt.plot(wave - lambda0, IwaveHPrd, '--', label='Lightweaver PRD (Angle Approximate)')
plt.yscale('log')
plt.xlabel(r'$\Delta\lambda$ [nm]')
plt.ylabel(r'Intensity [J\,m$^{-2}$\,s$^{-1}$\,Hz$^{-1}$\,sr$^{-1}$]')
plt.ylim(1e-10, None)
plt.xlim(wave[0] - lambda0, wave[-1] - lambda0)
plt.legend(frameon=False)
lFig = chFlareModelling.save_figure('LwValidationPrd', fig, fext='.pgf')
lFig.caption = r'Comparison of \Lw{} and RH synthesis of \Caii{} K from a RADYN snapshot comparing the effects of PRD.'
lFig.placement = 'htbp'
\end{pycode}
\begin{pycode}[FlareModelling]
from lightweaver.rh_atoms import H_4_atom
from matplotlib.ticker import MaxNLocator

Prd = False

def iterate_ctx(ctx, prd=True, Nscatter=3, NmaxIter=500):
    for i in range(NmaxIter):
        dJ = ctx.formal_sol_gamma_matrices()
        if i < Nscatter:
            continue
        delta = ctx.stat_equil()
        if prd:
            dRho = ctx.prd_redistribute(maxIter=5)

        if dJ < 3e-3 and delta < 1e-3:
            print(i)
            print('----------')
            return

atmos = Falc82()
atmos.quadrature(5)
if Prd:
    aSet = lw.RadiativeSet([H_6_atom(), C_atom(), O_atom(), Si_atom(), Al_atom(), CaII_atom(), Fe_atom(), He_atom(), MgII_atom(), N_atom(), Na_atom(), S_atom()])
else:
    aSet = lw.RadiativeSet([H_4_atom(), C_atom(), O_atom(), Si_atom(), Al_atom(), CaII_atom(), Fe_atom(), He_atom(), MgII_atom(), N_atom(), Na_atom(), S_atom()])
aSet.set_active('H')
spect = aSet.compute_wavelength_grid()

eqPops = aSet.compute_eq_pops(atmos)
# eqPops = aSet.iterate_lte_ne_eq_pops(atmos)
ctx = lw.Context(atmos, spect, eqPops,
                 hprd=Prd, conserveCharge=False, Nthreads=8)
iterate_ctx(ctx, prd=Prd)

print('Achieved initial Stat Eq')

dt = 0.1
NtStep = int(60 / dt)
NsubStep = 100

prevT = np.copy(atmos.temperature)
for i in range(11, 31):
    di = (i - 20.0) / 3.0
    atmos.temperature[i] *= 1.0 + 2.0 * np.exp(-di**2)

hPops = [np.copy(eqPops['H'])]
subIters = []
for it in range(NtStep):
    ctx.update_deps()

    prevState = None
    for sub in range(NsubStep):
        dJ = ctx.formal_sol_gamma_matrices()
        delta, prevState = ctx.time_dep_update(dt, prevState, ngUpdate=None)
        # deltaNr = ctx.nr_post_update(timeDependentData={'dt': dt, 'nPrev': prevState})
        # delta = max(delta, deltaNr)
        if Prd:
            ctx.prd_redistribute(maxIter=5)

        if delta < 1e-3 and dJ < 3e-3:
            subIters.append(sub)
            break
    else:
        raise ValueError('No converge')

    hPops.append(np.copy(eqPops['H']))
    print('Iteration %d (%f s) done after %d sub iterations' % (it, (it+1)*dt, sub))


initialAtmos = Falc82()

fig, ax = plt.subplots(2,2, sharex=True, figsize=texfigure.figsize(pytex, scale=1, height_ratio=0.7))
ax = ax.flatten()
cmass = np.log10(atmos.cmass/1e1)

lowerIdx = np.searchsorted(cmass, -4.936)
upperIdx = np.searchsorted(cmass, -4.930)

ax[0].plot(cmass[lowerIdx:upperIdx], initialAtmos.temperature[lowerIdx:upperIdx], 'r', label='Initial')
ax[0].plot(cmass[lowerIdx:upperIdx], atmos.temperature[lowerIdx:upperIdx], '-+b', label='Final')
ax[0].legend(frameon=False)

for p in hPops[1::5]:
    ax[1].plot(cmass[lowerIdx:upperIdx], np.log10(p[0, lowerIdx:upperIdx]/1e6), 'k', lw=0.5)
    ax[2].plot(cmass[lowerIdx:upperIdx], np.log10(p[1, lowerIdx:upperIdx]/1e6), 'k', lw=0.5)
    ax[3].plot(cmass[lowerIdx:upperIdx], np.log10(p[-1, lowerIdx:upperIdx]/1e6), 'k', lw=0.5)

p = hPops[0]
ax[1].plot(cmass[lowerIdx:upperIdx], np.log10(p[0, lowerIdx:upperIdx]/1e6), 'r')
ax[2].plot(cmass[lowerIdx:upperIdx], np.log10(p[1, lowerIdx:upperIdx]/1e6), 'r')
ax[3].plot(cmass[lowerIdx:upperIdx], np.log10(p[-1, lowerIdx:upperIdx]/1e6), 'r')

p = hPops[-1]
ax[1].plot(cmass[lowerIdx:upperIdx], np.log10(p[0, lowerIdx:upperIdx]/1e6),  '-+b')
ax[2].plot(cmass[lowerIdx:upperIdx], np.log10(p[1, lowerIdx:upperIdx]/1e6),  '-+b')
ax[3].plot(cmass[lowerIdx:upperIdx], np.log10(p[-1,lowerIdx:upperIdx]/1e6), '-+b')

ax[0].set_xlim(-4.935, -4.931)
ax[0].xaxis.set_major_locator(MaxNLocator(3))
ax[0].set_ylim(0, 6e4)
ax[1].set_ylim(6, 11)
ax[2].set_ylim(1, 6)
ax[3].set_ylim(10, 11)

ax[2].set_xlabel('$\log\,m$ [cm$^{-2}$]')
ax[3].set_xlabel('$\log\,m$ [cm$^{-2}$]')

ax[0].set_ylabel('$T$ [K]')
ax[1].set_ylabel('$\log\,n(n=1)$ [cm$^{-3}$]')
ax[2].set_ylabel('$\log\,n(n=2)$ [cm$^{-3}$]')
ax[3].set_ylabel('$\log\,n(\kappa)$ [cm$^{-3}$]')

fig.tight_layout()

lFig = chFlareModelling.save_figure('LwValidationJudge', fig, fext='.pgf')
lFig.caption = r'Validation of the time-dependent population update scheme in \Lw{}. Compare with Fig. 4 of \citet{Judge2017}, cgs units are employed to allow a direct comparison. The response of hydrogen levels ($n=1, 2$) and continuum ($\kappa$) are shown for an instantaneous perturbation of the temperature of the FALC model (top-left panel). Each black line shows the population densities once every \SI{0.5}{\second}.'
lFig.placement = 'ht'
\end{pycode}
\setpythontexautoprint{true}

\begin{pycode}[FlareModelling]
from ReadAtmost import read_atmost
import zarr

atmost = read_atmost(chFlareModelling.data_file('Flat1e9NoIncRad/atmost.dat'))
atmost.to_SI()

data = zarr.convenience.open(chFlareModelling.data_file('Flat1e9NoIncRad/Flat1e9NoIncRadLIThesis.zip'), 'r')

timesToPlot = [5, 11, 20, 40]
fig, ax = plt.subplots(2, 2, figsize=texfigure.figsize(pytex, scale=1.0, height_ratio=0.7))
ax = ax.ravel()

for i, a in enumerate(ax):
    time = timesToPlot[i]
    radynIdx = np.searchsorted(atmost.time, time)
    lwIdx = np.searchsorted(data['time'][...], time)

    label = 'RADYN' if i == 0 else None
    a.semilogy(atmost.z1[radynIdx] / 1e6, atmost.ne1[radynIdx], label=label)
    label = 'Lightweaver' if i == 0 else None
    a.semilogy(atmost.z1[radynIdx] / 1e6, data['ne'][lwIdx], '--', label=label)
    a.set_xlim(None, 2.5)
    a.set_title('{:.2f} s'.format(time))

    if i in [0, 2]:
        a.set_ylabel(r'$n_e$ [m$^{-3}$]')
    else:
        a.set_yticklabels([])

    if i in [2, 3]:
        a.set_xlabel(r'$z$ [Mm]')
    else:
        a.set_xticklabels([])

ax[0].legend(frameon=False)
fig.tight_layout()

lFig = chFlareModelling.save_figure('LwValidationTimeDepNe', fig, fext='.pgf')
lFig.caption = r'Comparison of electron density in a RADYN simulation and time-dependent reprocessing using \Lw{} that will be presented as the F9 model of Chap.~\ref{Chap:TimeDepRt}.'
lFig.placement = 'ht'
\end{pycode}

\py[FlareModelling]|chFlareModelling.get_figure('LwRhComparison')|
\py[FlareModelling]|chFlareModelling.get_figure('LwValidationSillyVel')|
\py[FlareModelling]|chFlareModelling.get_figure('LwValidationPrd')|

%spell-checker: enable

Fig.~\ref{Fig:LwRhComparison} presents a comparison of the synthesis of \CaLine{} by \Lw{} and RH in the FALC atmosphere of \citet{Fontenla1993}.
This is a static, semi-empirical quiet sun atmosphere, so the synthesis is performed in statistical equilibrium.
RH's solution is shown in blue, with the \Lw{} solution overlaid in dashed orange.
There is clearly very good agreement between these codes in this simple static test.
This figure also shows the sensitivity of \CaLine{} to the electron density when computed under the assumption of LTE populations (green), and how the the charge conservation method implemented in \Lw{} can help to mitigate these effects (red).
The line profile computed from the simulation with the charge conservation strategy approaches the reference solution, where the electron density is provided by the FAL model.
The primary differences between these treatments is likely due to other species, such as Fe, being treated in LTE.

\TODO{Add SNAPI if we get it}.
In Fig.~\ref{Fig:LwValidationSillyVel} we once again present the synthesis of \CaLine{} in the FALC atmosphere, but here a complex velocity profile is imposed on the atmospheric model.
The vertical velocity structure of the atmosphere is defined to be two periods of a sine wave with amplitude \SI{30}{\kilo\metre\per\second} mapped over the vertical extent of the FALC model (approximately \SI{2}{\mega\metre}).
Here RH's solution is once again shown in blue, and \Lw{}'s in dashed orange.
This problem serves primarily as a test of the formal solver; the piecewise parabolic method of \citet{Auer1994} implemented in RH, which falls back to monotonic linear interpolation if the parabolic terms under- or overshoot, was unable to correctly solve the problem, causing the iteration to fail.
The cubic Bézier method of \citet{DelaCruzRodriguez2013} normally used in both RH and \Lw{}, along with their standard MALI iteration machinery, provides a very similar solution from both codes.
The slight differences apparent around $\Delta\lambda=\SI{-0.1}{\nano\metre}$ is likely to be caused by differences in the formal solver implementations; the version implemented in RH uses the method of \citet{Fritsch1984} to compute numerical estimates of the necessary derivatives, whereas we use the method of \citet{Steffen1990} in \Lw{} following the recommendation of \citet{Janett2018}, as the accuracy of \citet{Fritsch1984} falls to first-order on non-uniform grids.
Additionally, the implementation present in RH chooses to limit the control points on the spline interpolants to positive values, but following the advice of de la Cruz Rodríguez (\emph{private communication}) we remove this limitation as negative absorption can occur with sufficient stimulated emission.
Nevertheless, the agreement between RH and \Lw{} is very good on this difficult test.

Fig.~\ref{Fig:LwValidationPrd} shows a simple validation test for the PRD method implemented in \Lw{}.
We show the synthesis of the \Caii{} K line in statistical equilibrium from a snapshot of a \Radyn{} simulation.
This snapshot is taken from the F9 simulation discussed in Chap.~\ref{Chap:TimeDepRt}, at \SI{5}{\second} after flare heating starts.
The CRD solutions are shown in blue and dashed orange for RH and \Lw{} respectively.
The PRD solutions both employ angle-averaged PRD and are presented in green (RH) and dashed red (\Lw{}).
The agreement between these solutions is again very good, with a slight observable difference around $|\Delta\lambda=\SI{0.012}{\nano\metre}|$ where the line in \Lw{}'s PRD solution appears slightly wider than in RH's.
This difference is present only over a very small range of wavelengths and we consider the agreement between the two implementations to be very good.

\py[FlareModelling]|chFlareModelling.get_figure('LwValidationJudge')|

Slightly more complex examples are needed to test the time-dependent machinery present in \Lw{}, and neither SNAPI nor RH, with their time-independent viewpoints can be used for comparison here.
We instead use the example of a perturbed FALC atmosphere presented by \citet{Judge2017}.
After converging to the statistical equilibrium solution in a standard FALC atmosphere, the temperature is perturbed as presented in blue line of the top-left panel of Fig.~\ref{Fig:LwValidationJudge}.
This model uses a three level plus continuum model hydrogen atom, and the populations of the ground, first excited, and continuum states are shown in the top-right, bottom-left, and bottom-right panels of this figure respectively.
The red line shows their starting values, and the blue line their final values after the simulation has been allowed to run for \SI{60}{\second}.
The black lines represent the solutions for each population every \SI{0.5}{\second}.
The $x$-axis on these plots is the atmospheric column mass, and this figure is prepared in cgs to  allow direct comparison to the one presented by \citet{Judge2017}.
We see good overall agreement with \citet{Judge2017}, but the differences are larger than those presented in the previous figures.
The method used by \citet{Judge2017} is different to ours, and uses full preconditioning but with an approximate operator based on the escape probability formalism of \citet{Hummer1982}.
This approach is much more approximate than the full MALI treatment applied in \Lw{}, as it only performs the formal solution at one wavelength per transition, and computes the integrals over wavelength and angle analytically.
The advantage of this treatment is that it is much less computationally intensive.
Thus, the use of this approximate method by \citet{Judge2017} is likely to be the origin of the differences between our results, and we find that the level populations converge to similar final solutions, at apparently similar rates.
The most substantial difference between our results is for the $n=2$ population; in the results of \citet{Judge2017}, the points close to a column mass of \SI{-4.9315}{\per\square\centi\metre} do not vary from their initial values, whereas in our model they vary quite dramatically, with an enhancement of up to 1.5\,dex, but converge back to the expected final solution.
This simple example is meant to illustrate that \Lw{}'s behaviour is reasonable when applied to time-dependent problems, and the quality of its treatment will become apparent in the in-depth comparisons with \Radyn{} presented in Chap.~\ref{Chap:TimeDepRt}.

\py[FlareModelling]|chFlareModelling.get_figure('LwValidationTimeDepNe')|

In Fig.~\ref{Fig:LwValidationTimeDepNe} we show the electron density in the lower atmosphere at four different timesteps of a \Radyn{} simulation that has been reprocessed using \Lw{}.
This simulation is the F9 simulation that will be discussed in Chap.~\ref{Chap:TimeDepRt}, and the \Lw{} model presented is run with time-dependent charge conservation, starting from the same initial electron density as \Radyn{}, but maintaining self-consistency throughout the remainder of the simulation.
The electron density in the \Radyn{} model is shown in blue, and the \Lw{} model in dashed orange.
The agreement between the two models is extremely good, including the fine features around $z=\SI{1.2}{\mega\metre}$ shown in the \SI{11}{\second} panel.

\Lw{} agrees well with the other models against which it has been tested here; it is easy to construct new validation tests for statistical equilibrium cases that can be run with many different extant RT codes, but the validation of time-dependent treatments on their own is more difficult, due to current tools often coupling these equations to hydrodynamics.
Other tests have been undertaken to verify the performance of \Lw{}, but those presented here should be sufficient to demonstrate its capabilities.


\subsection{\emph{Lightspinner}}

During the development of \Lw{}, a simpler pedagogic framework was also constructed.
This framework, \emph{Lightspinner}\footnote{Developed on GitHub (\url{https://github.com/Goobley/Lightspinner}), with archival on Zenodo.} \citep{Lightspinner}, is written in pure Python and focuses on documenting the internal numerics of a simple formal solver and the MALI method using full preconditioning (under the assumption of CRD).
It is accompanied by a slide deck highlighting the most important terms that need to be understood to implement these methods following \citet{Rybicki1992} and \citet{Uitenbroek2001} for iteration, and \citet{Kunasz1988} and \citet{Auer1994} for the short-characteristics formal solver (although only a linear formal solver is implemented in the code). This framework can be employed to help users familiarise themselves with the concepts of NLTE RT and some of the techniques present in \Lw{}; it presents the core concepts clearly, and naïvely without focusing on performance, so can easily be dismantled and understood by a single person over the course of a few days.

\section{Introduction to Hydrodynamics and Conservation Laws}
\emph{The majority of the basic theory in this section follows the two texts by \citet{LeVeque1997,LeVeque2002}.}

In the previous sections we have explained the basis of the radiative transfer methods used throughout this work.
The difficulty in radiative transfer primarily lies in the nuance of implementing the various integration terms.
To provide a clear understanding of RHD we also need a numerical description of hydrodynamics, and an explanation of solving the coupled systems of partial differential equations (PDE) that represent the other major facet of RHD.

The scalar radiative transfer equation, solved via the formal solver is a good example of an ordinary differential equation.
It is relatively easy to solve via a variety of methods, typically striving for a balance of speed, reliability, and accuracy.
Unfortunately, PDEs are difficult to solve numerically in a general way.

A generic second-order PDE of a quantity $q$ depending on two independent variables $x$ and $y$ can be written as
\begin{equation}
    aq_{xx} + bq_{xy} + cq_{yy} + dq_x + eq_y + fq = g,
\end{equation}
wherein the subscripts represent partial derivatives with respect to these variables.
The sign of the discriminant ($\Delta = b^2-4ac$) of this equation determines the class of the problem:
\begin{itemize}
    \item $\Delta < 0$: Elliptic problem (e.g. Poisson equation).
    \item $\Delta = 0$: Parabolic problem (e.g. Heat equation).
    \item $\Delta > 0$: Hyperbolic problem (e.g. Advection equation).
\end{itemize}
Here, we will focus primarily on hyperbolic problems, with a brief discussion of parabolic terms.
Hyperbolic problems take the form
\begin{equation}\label{Eq:ConsLaw}
    q_t + f(q)_x = 0,
\end{equation}
where $f$ is a function describing the the flux of $q$ at each location in the domain, $t$ indicates a temporal coordinate, and $x$ a spatial coordinate.
There is an inherent assumption that the flux function is local, and acts only on the local state variables $q$.

Equations of the form \eqref{Eq:ConsLaw} are known as conservation laws, and the quantities $q$ are often termed ``conserved quantities'', implying that $\int_{-\infty}^{\infty} q\, dx$ is constant in time.
This does not preclude the addition of sources and sinks of this quantity, but simply requires that the total of a conserved quantity not change \emph{without} being acted on in such a way.
The simplest equation of this form is advection, which arises from conservation of mass in a moving fluid and is written for mass density $\rho$ and velocity $\varv$ as
\begin{equation}\label{Eq:Advection}
    \rho_t + (\rho \varv)_x = 0.
\end{equation}

The advection equation can be augmented with two further equations to form the Euler equation set.
These three equations are the conservation of mass, momentum, and energy.
Together they describe the evolution of ideal fluids.
The complete set is written
\begin{equation}\label{Eq:EulerEqns}
\begin{split}
    \rho_t + (\rho \varv)_x &= 0,\\
    (\rho \varv)_t + (\rho \varv^2 + p)_x &= 0,\\
    E_t + (\varv(E + p))_x &= 0,
\end{split}
\end{equation}
where $E$ is the total energy and $p$ is the gas pressure.
This system is already recognisable as the simplified roots of the RHD equations.
As our three conserved quantities are the mass density, momentum density, and energy, the pressure must be expressed as a combination of these so as to be able to write this system in the form of \eqref{Eq:ConsLaw}.
The simplest way to achieve this is to use the equation of state for an ideal gas
\begin{equation}
    E = \frac{p}{\gamma-1} + \frac{1}{2}\rho \varv^2.
\end{equation}
Here $\gamma$ is the ratio of gas' specific heat at constant pressure and constant volume, which is 5/3 for monatomic gasses, typically assumed in the case of solar plasma.

The Euler equations \eqref{Eq:EulerEqns} describe the evolution of an ideal fluid without any energy losses.
In practice we often need to model some loss terms.
Ignoring radiative effects for now, the most important of these is heat conduction\footnote{In the plasmas considered here there is additional nuance to heat conduction, which we will return to in Sec.~\ref{Sec:NumericalConduction}.}, which is typically described by parabolic equations.
This adds a second spatial derivative term to the right-hand side of the energy conservation equation.
It is also common to need source and sink terms when modelling real world problems; these can account for fluids entering and leaving a volume, the non-local emission and absorption of energy, or simply the effects of gravity.
These terms are also added to the right-hand side of the equations of \eqref{Eq:EulerEqns}, and together with the effects of viscosity, these describe the Navier-Stokes equations.

\subsection{Numerical Approaches}

The typical first choice for numerically solving differential equations is to apply a finite difference method.
In this class of method, the problem is discretised, similarly to the approach taken in radiative transfer, and the values associated with each grid point represent the local pointwise value.
The local gradient of the conserved quantities can then be estimated from pointwise difference between in the quantity between adjacent cells.
This method can be applied to discrete problems in both space and time.
Applying a basic one-sided method to the advection equation \eqref{Eq:Advection} gives
\begin{equation}\label{Eq:FdmAdvection}
    \frac{q^{t+1}_i - q^t_i}{\Delta t} + \varv \left( \frac{q^t_{i+1} - q^t_i}{\Delta x} \right),
\end{equation}
where the subscript refers to the location of the conserved quantity, the superscript the discrete timestep, with $\Delta x$ and $\Delta t$ being the local grid spacing and timestep duration respectively.

It is clear that without loss of generality we could have also chosen to spatially difference our problem in the other direction (i.e. $q^t_i - q^t_{i-1}$).
From the infinitesimal definition of the derivative, these two formulations are equivalent.
This is not the case in discretised problems.
It is better to locally use the formulation such that information from points ``upwind'' in terms of the fluid velocity are used to update the points downwind of themselves.
In this sense the information used to update points is following the fluid flow.
Equation \eqref{Eq:FdmAdvection} can be rewritten to explicitly determine the approximate value of the quantity at the next timestep,
\begin{equation}
    q^{t+1}_i = q^t_i - \frac{\varv \Delta t}{\Delta x}\left( q^t_{i+1} - q^t_i \right).
\end{equation}

This simple first order accurate approach can be applied to any conservation law, and higher-order accurate methods can be derived from using finite difference methods over larger stencils, or deriving similar approaches from combinations of the local finite difference approximations using Taylor series.

Many other spatial and temporal discretisations can be devised for conservation laws, and it is important to choose a discretisation that introduces minimal error.
In general, we term discretisations where $q^{t+1}$ depends only on $q^{t}$ as \emph{explicit}, and those also depending on $q^{t+1}$ as \emph{implicit}, necessitating the solution of a system of typically non-linear equations.

Whilst the finite difference method provides an intuitive formulation for discretising these equations, it is difficult to ensure conservation of the quantities that we desire be conserved with only pointwise values and no formal description of the variation between these points.
Instead the finite volume description is often preferable and consists of treating $q_i^t$ as the average value over a grid cell.
Conservation can then be ensured by evolving this value based on the fluxes in and out of the cell.
This implies
\begin{equation}
    q_i^t \approx \frac{1}{\Delta x}\int_{x_i}^{x_{i+1}} q^t(x)\, dx.
\end{equation}
Rewriting the conservation law \eqref{Eq:ConsLaw} in an integral form then gives
\begin{equation}
    \int_{x_i}^{x_{i+1}} q^{t+1}(x)\, dx = \int_{x_i}^{x_{i+1}} q^{t}(x)\, dx
                                         + \int_{t_t}^{t_{t+1}} q_i(t)\, dt
                                         - \int_{t_t}^{t_{t+1}} q_{i+1}(t)\, dt,
\end{equation}
which can then be written as the flux-differencing form
\begin{equation}\label{Eq:FiniteVolumeMethod}
    q_i^{t+1} = q_i^t - \frac{\Delta t}{\Delta x}\left( F^t_{i+1} - F^t_{i} \right),
\end{equation}
where $F_i$ represents the flux due between cells $i$ and $i-1$, and $F_{i+1}$ the flux between cells $i$ and $i+1$.
In the case of an explicit method with a correctly chosen timestep for the grid, where information cannot move further than one cell in a timestep, each of these flux functions depends only on cell $i$ and one of its neighbours.
An important strength of this method for solving conservation law problems is that if $F_i$ and $F_{i+1}$ are respectively the left and right edge fluxes for cell $i$, then $F_{i+1}$ will be the left edge flux for cell $i+1$, and $F_{i}$ will be the right edge flux for cell $i-1$.
Thus the numerical integration of $q^{t+1}$ is conserved with respect to $q^t$ as all numerical fluxes, other than the left- and right-most, will cancel due to the formulation of \eqref{Eq:FiniteVolumeMethod}.
These left- and right-most fluxes will need to consider the boundary conditions of the finite simulation volume to ensure the correctness of the conservation law.


\subsection{Riemann Problems}

% spell-checker: disable
\begin{pycode}[FlareModelling]
from shocktubecalc import sod
from matplotlib.ticker import MaxNLocator

gamma = 1.4
positions, regions, values = sod.solve(left_state=(1.0, 1.0, 0.0), right_state=(0.1, 0.125, 0.0),
                                       geometry=(0.0, 1.0, 0.5), t=0.2, gamma=gamma, npts=500)
fig, ax = plt.subplots(2, 2, figsize=texfigure.figsize(pytex, scale=1, height_ratio=0.6),
                       constrained_layout=True)
ax = ax.ravel()
grid = values['x']
pressure = values['p']
density = values['rho']
velocity = values['u']
totE = pressure / (gamma - 1.0) + 0.5 * density * velocity**2

ax[0].plot(grid, density)
ax[0].set_xticklabels([])
ax[1].plot(grid, velocity)
ax[1].set_xticklabels([])
ax[2].plot(grid, pressure)
ax[3].plot(grid, totE)

ax[0].set_ylabel(r'$\rho$')
ax[1].set_ylabel(r'$\varv$')
ax[2].set_ylabel(r'$p$')
ax[3].set_ylabel(r'$E$')

ax[2].set_xlabel(r'$x$')
ax[3].set_xlabel(r'$x$')

lFig = chFlareModelling.save_figure('SodTubeAnalytic', fig, fext='.pgf')
lFig.caption = r'Solution to the classic Sod shock tube problem at $t=\SI{0.2}{\second}$.'

fig = plt.figure(figsize=texfigure.figsize(pytex, scale=1, height_ratio=0.55))
ax = plt.gca()
ax.plot(grid, density)
ax.set_ylabel(r'$\rho$', c='C0')
ax.set_xlabel(r'$x$')

ax2 = ax.twinx()
# ax2.plot([0.5, 0.7], [0, 0.2], c='#222222')
for i, p in enumerate(positions.values()):
    ax2.axvline(p, c='k')
    if i != 1:
        ax2.plot([0.5, p], [0, 0.2], c='#555555')
regionLims = np.array([0, *positions.values(), 1])
regionCentres = 0.5 * (regionLims[1:] + regionLims[:-1])
labels = [r'$\alpha$', r'$\beta$', r'$\gamma$', r'$\delta$', r'$\epsilon$']
for i, c in enumerate(regionCentres):
    ax2.text(c, 0.02, labels[i])

ax2.set_ylabel(r'$t$')
ax2.yaxis.set_major_locator(MaxNLocator(5))
lFig = chFlareModelling.save_figure('RiemannFan', fig, fext='.pgf')
lFig.caption = r'Riemann fan of different wave speeds and associated regions for the Sod shock tube problem.'
\end{pycode}

\py[FlareModelling]|chFlareModelling.get_figure('SodTubeAnalytic')|
\py[FlareModelling]|chFlareModelling.get_figure('RiemannFan')|
% spell-checker: enable

The finite volume method we have described therefore depends on finding expressions for the numerical flux between two adjacent cells.
This is often framed as a Riemann problem at the cell interface.
A Riemann problem consists of solving a conservation law with an initial parameter distribution consisting of two constant states meeting at a discontinuity.
Without loss of generality this discontinuity can be placed at $x=0$, and the value of $q$ for $x<0$ is termed $q_l$ and $q_r$ for $x>0$.

A very well studied Riemann problem, that is often used as a test case for numerical hydrodynamics, is that of the Sod shock tube \citep{Sod1978}.
The problem is a single Riemann problem, with gas at a different pressure and density on each side of a membrane.
At $t=0$ the membrane is removed, and multiple waves with different velocities are launched in both directions.
A solution to the classic Sod shock tube with initial states $q_l = \{\rho=1, p=1, \varv=0\}, q_r = \{\rho=0.125, p=0.1, \varv=0\}$ at $t=\SI{0.2}{\second}$ is shown in Fig.~\ref{Fig:SodTubeAnalytic}.
At this time, a complex pressure and density structure has formed in the shock tube.
The Riemann problem is often considered in terms of the propagating waves.
In Fig.~\ref{Fig:RiemannFan} we show the same density profile, but divided into regions by black lines, with grey lines showing a time-distance plot of the different waves in the system.
This plot, and manner of considering the waves in the system is known as a Riemann fan.

The left- and right-most regions of density ($\alpha$ and $\epsilon$) shown in Fig.~\ref{Fig:RiemannFan}, are simply the initial left and right states of the fluid, as these are currently unperturbed by the waves propagating from the initial discontinuity.
Starting from the initial discontinuity, a rarefaction wave (reduction in density) moves into the high density region (to the left), and a shock wave propagates into the low density region (to the right).
The rarefaction wave is present in region $\beta$, with the shock front being the boundary between $\delta$ and $\epsilon$.
There is an additional front between regions $\beta$ and $\gamma$, which we note is not visible on either the velocity or pressure panels of Fig.~\ref{Fig:SodTubeAnalytic}.
This is a contact discontinuity and represents the boundary between two regions of different entropy.
This is the original interface between the two gases at $t=0$, and it is advected along with the flow at the velocity $u$, so there is no mixing between the two sides of this contact discontinuity (in the case of an ideal gas).

From analysis of the Jacobian of the flux function of the Euler equations, the structure of this solution can be revealed.
There are three waves, associated with the eigenvalues of this Jacobian.
The contact discontinuity propagates at the fluid velocity $\varv$ (as the fluid expands into the low density region), the other two eigenvalues are $\varv\pm c_s$, where $c_s$ is the sound speed of the fluid.
Unfortunately these waves are non-linear and do not necessarily propagate at the characteristic velocity given by their associated eigenvalue.
Instead it is necessary to apply the Rankine-Hugoniot jump conditions, at both the shock front and the contact discontinuity, and solve the resultant transcendental equation to determine the parameters of regions $\gamma$ and $\delta$.
These problems can be solved using iterative methods and knowledge of the expected wave form of the solution.

As the complexity of the system and the equation of state increases, it becomes harder (or impossible) to compute this solution in an efficient manner.
Fortunately, it is rarely necessary to compute the exact solution to the Riemann problem as many efficient approximate solvers exist, but it is important to understand the the structure originating from this simple case to interpret and validate the numerical methods described later.

% N.B. The characteristic of a system like this is a line for which the the solution q is constant. i.e. for advection this is x(t) = x0 + ut
% For linear systems we can transform to characteristic variables, for which the coefficient matrix is diagonal and we have a system of independent scalar advection equations.
% The velocity is time/space varying along the rarefaction wave.
% The characteristic field of an equation is an eigenvector, if this is linearly
% degenerate then we can only have contact discontinuities.
% Integral curves are curves which connect two points by an integral of one of the eigenvectors of the system.
% A function of q that is invariant along any integral curve is called a Riemann invariant, these are used for solving problems related to rarefaction waves.
% These Riemann invariants are conserved along the characteristic. For the u eigenvector, we have u and p as invariant, hence only the pressure can change => contact discontinuity.
% Characteristics on each side of shock linked by Hugoniot locus

\subsection{Godunov's Method and Higher Order Reconstructions}

Godunov's method \citep{Godunov1959} consists of assuming that the data $q$ is piecewise constant in each cell of our simulation domain.
At this point the values on the left- and right-hand side of each interface are known and the flux through this interface can be determined by solving a Riemann problem.
The Riemann problem at each interface can be treated independently under the assumption that the fastest wave from one interface not carry information to the next.
This is a fundamental requirement of stability and will be discussed in more detail in Sec.~\ref{Sec:HydroStability}.

This method provides a basic framework for solving conservation laws.
It is limited by the assumption that the data is piecewise constant, but nevertheless paved the way for some of the most accurate numerical methods for conservation laws.
\citet{VanLeer1979} provided one of the first higher order extension to Godunov's method.
It is tempting to attempt to estimate the value of $q$ at cell interfaces with higher accuracy by using some form of reconstruction (a method closely related to interpolation), but care must be taken with this approach.
The MUSCL method of \citet{VanLeer1979} uses a piecewise linear approach to reconstruction in each grid cell, but limits the gradient of the reconstruction to prevent the addition of under- or over-shoots to the data.
This is achieved through use of a slope-limiter such that a monotonic series of cell averages be preserved by ensuring that the reconstructed slope not take values beyond the average of the adjacent cells.
If the current cell is an extremum then the slope is set to 0.
Different slope-limiters have been designed and present different trade-offs in terms of accuracy in smooth regions against the risk of introducing spurious oscillations in the solution, these are discussed at length in introductory texts, such as \citet{LeVeque1997}.
This method tracks the data to second-order in regions of smooth variation, but degenerates to the first-order Godunov method at discontinuities.

There are further high-order extensions to the concept of reconstruction including the parabolic method of \citet{Colella1984} providing third-order accuracy in smooth regions, and the general weighted essentially non-oscillatory (WENO) methods.
WENO methods are a cornerstone of reconstruction\footnote{The properties that make WENO methods a good choice for reconstruction also render them applicable to interpolation. Throughout \Lw{} and the other numerical tools presented in this thesis we make use of a fourth-order WENO interpolation method described by \citet{Janett2019} for its accuracy in smoothly varying regions and reliable behaviour around sharp variations.} in modern finite volume codes, and as such we will describe them briefly here.

WENO methods were first proposed by \citet{Liu1994}, and formalised for arbitrary order by \citet{Jiang1996}.
These methods form a convex combination of polynomials over overlapping regions.
For example, in the case of the commonly used fifth-order WENO method of \citet{Jiang1996}, three parabolae are constructed over five adjacent points, i.e. the first uses the stencil $\{x_1, x_2, x_3\}$ the second $\{x_2, x_3, x_4\}$, and the third $\{x_3, x_4, x_5\}$.
We can equivalently define a fifth-order polynomial over the stencil $\{x_1, \ldots, x_5\}$, which can also be written as a linear combination of our interpolating parabolae at each point in this region.
These linear weights can be further weighted by a term known as the \emph{smoothness indicator}, which estimates the local smoothness, such that the weight of each term is equal to its expected linear weight in smooth regions, and heavily biased towards a parabola in a smooth region if other regions present discontinuities.

The process of computing these initial interpolating functions is somewhat complex due to the finite volume framework often applied in hydrodynamics.
These should be computed such that the integral over the interpolating polynomial in each cell is close to the average value, rather than simply taking it as a pointwise value.
For a fixed uniform grid, the integration weights for each interface can be computed analytically, and the lack of conditional branches in the calculation of the final weighted value renders the method highly performant.
For non-uniform grids, the weights can be precalculated if the grid remains fixed, or computed on the fly if necessary.
There are also a number of approximate methods for handling non-uniform grids at low computational cost such as WENO-NM \citep{Huang2018}.
The WENO method has been extended many times to provide increased accuracy or meet certain requirements; its strong reconstructive ability and reliable behaviour around shocks makes it a workhorse of modern hydrodynamics and enables simpler flux functions to be reliably used, as will be discussed in the next section.


\subsection{Numerical Fluxes}

Whilst there are many approximate Riemann solvers that can accurately and efficiently solve the Riemann problems arising from the Euler equations including the addition of source terms, it does not appear feasible to express the evolution of the entire RHD system in this way.
Instead, in explicit methods we use numerical approximations to the flux based on the reconstructed values at the interfaces is used.
For implicit methods we can instead use a Newton iterative scheme to minimise the residual of the discretised conservation law across the cell interfaces with the fluxes typically computed from the upwind value of the reconstructed parameter.

With high-order reconstructions, simple expressions for the fluxes can be used and give accurate results.
An obvious first choice would be the average flux from the reconstructed states left and right of the interface.
Unfortunately, this leads to numerical instabilities, and some artificial damping (numerical viscosity) is needed.
This leads to a flux known as the Local Lax-Friedrichs, or Rusanov Flux \citep{Rusanov1962}
\begin{equation}
    F_{\mathrm{LLF}} = \frac{1}{2}(f(q_{i+1}^L) + f(q_i^R)) - \frac{1}{2}\alpha(q_i^R - q_{i+1}^L).
\end{equation}
Here $q_i^L$ and $q_i^R$ represent the left and right hand reconstructed states of the $i$-th Riemann problem, $f$ represents the flux function of the conservation law, and $\alpha$ is the local maximum wave propagation speed for this system.
Whilst $\alpha$ can often be formally derived from the Jacobian of $f$, it can often be replaced with either the maximum absolute value of the sum of the sound speed on each side of the interface and the local fluid velocity, or the average of these on both sides of the interface.
General symmetric fluxes like this are simple and efficient, but tend to be diffusive, smearing features across many grid cells, especially if the first-order Godunov or van Leer-style reconstruction methods are used.
This can be effectively combatted by the use of high-order reconstruction schemes and adaptive mesh refinement techniques, although when available, a specialised Riemann solver for the current problem is often a better choice.

\subsection{Time Integration and Stability}\label{Sec:HydroStability}

Explicit schemes are only stable (i.e. do not diverge or introduce spurious oscillations) if the Courant-Friedrichs-Lewy (CFL) condition is met.
The CFL condition states that the numerical domain of dependence of the the equation (i.e. the terms used in the computation of a value in the next timestep) must encompass the analytic domain of dependence to ensure that all necessary information is taken into account.
This is a necessary, but not sufficient condition, and the exact requirements of each scheme can often be derived analytically, although it is common to apply an additional safety margin to the maximum permitted value of the CFL condition.

For explicit methods the CFL condition sets the maximum timestep that can be used based on the current simulation conditions.
In a hyperbolic system the CFL condition takes the form
\begin{equation}
    C = \frac{\varv\Delta t}{\Delta x},
\end{equation}
and will be constrained to a maximum value ($\leq 1$) for stability of an explicit method.
Most implicit methods do not place an upper limit on the CFL condition for stability (as all points are coupled), but typically need to remain $\sim 1$ to avoid losing fine detail in the solution.
This is discussed \citet{Viallet2011}, who comment that CFL $\sim 1$ serves as an accuracy criterion and typically represents the optimum accuracy/computational cost ratio despite the method being nominally stable for large CFL values.

It is difficult to achieve better than second order accuracy due to the temporal discretisations discussed so far, but by viewing $F_i^t$ as the flux at time $t$, we can achieve higher order accuracy by applying a multi-step method to more accurately integrate these fluxes (and any associated source terms) over time.
A good choice for this is a method in the family of total-variation diminishing Runge-Kutta methods \citep[e.g.][]{Shu1988}.
These multi-step time integration methods can be combined with fractional step methods that allow us to perform \emph{operator splitting}.
That is, splitting an equation into two subproblems that can solved independently.
An example of this would be the radioactive decay of an isotope transported by advection.
Splitting this into an advection and a reaction problem allows for standard methods to be used in both of these problems, but clearly their results need to be coupled to each other.
A naive first approach is to solve one of the subproblems over the timestep, and then solve the other, but this method cannot be better than first order accurate in time for coupled subproblems.
A commonly used approach that is second order is known at Strang splitting \citep{Strang1968}, which consists of time-advancing the first subproblem by half the timestep, then the second by the whole timestep, before once again advancing the first subproblem by a timestep.
This method can provide second-order accuracy.
Many more advanced splitting procedures have been developed, but Strang splitting remains widely used due to its ease of implementation.

\citet{LeVeque1997} comments that in many situations the first-order splitting described above performs better than would be commonly expected from its formal first-order accuracy.
This is because the errors introduced are equivalent to solving the problem at a slightly different time, differing by up to a single timestep.
Whilst this renders the method first-order accurate, the quality of the solution is still primarily controlled by the quality of the methods used to solve the subproblems, and this exceedingly simple splitting scheme can often be applied with no problems.

There are many nuances to each of the techniques needed to accurately and robustly solve conservation laws numerically, and no single \emph{correct} method to use.
The above is intended to serve as an introduction to the complexities of these methods, but by no means present a conclusion on how conservation laws should be solved.
It is hoped that this introduction will improve general understanding of this aspect of RHD codes.

\section{Conduction}\label{Sec:NumericalConduction}

When expressed in terms of energy the heat equation in a plasma along a magnetic field line is given by
\begin{equation}
    \frac{\partial E}{\partial t} = \frac{\partial}{\partial z}\left( \kappa_0 T^{5/2} \frac{\partial T}{\partial z} \right),
\end{equation}
with spatial coordinate $z$, and coefficient $\kappa_0$ varying, but typically taken to be approximately \SI{1e-6}{\erg\per\centi\metre\per\second\per\kelvin\tothe{7/2}} \citep{Spitzer1953,Braginskii1965} based on deviations from a fully ionised hydrogen plasma.
The form of this equation poses several problems, the most significant being that in regions of sufficiently steep temperature gradients, the conductive flux approaches infinity.
Clearly this is not physical and there is a maximum limit, known as the free-streaming limit, at which all electrons in the plasma are flowing at their thermal speed with this heat gradient, representing a finite limit on this term.
As this free-streaming limit is approached the heat flux becomes non-local and depends on the global temperature and density structure in the loop \citep{Battaglia2009}.
\citet{Campbell1984} provides an expression for the transport coefficients used to determine the conductive flux through an ionised plasma and smoothly handles both the Spitzer-H\"{a}rm, locally limited, and non-locally limited regimes.
This approach can be applied in numerical simulations but more frequently (such as in RADYN) the method of \citet{FISHER1985} is applied which smoothly limits the local flux to remain less than the local free-streaming limit, helping to stabilise this equation.

Due to its parabolic nature, an explicit solution of the heat equation can be extremely costly; stability requirements provide a timestep requirement scaling with the inverse square of the grid spacing, rather than linearly as in the case of most hyperbolic equations.
Any attempt to explicitly integrate the heat equation on a timestep limit set by the hydrodynamic equations will likely be met with rapid divergence of any small perturbation in the data.
This renders the conduction term stiff compared to the hydrodynamical terms and it may therefore be advantageous to use an implicit method  to guarantee stability.
Several alternative methods have been developed, such as expressing the parabolic equation as a hyperbolic wave equation \citep{Rempel2016}, implicit-explicit methods (which may also be used for integrating stiff source terms such as the atomic level population transition rates) \citep[e.g.][]{Ascher1995}, or accepting the cost of an explicit discretisation in exchange for simplicity and accuracy \citep{Bradshaw2003, Bradshaw2013}.

Recently, discussion has emerged around the concept of turbulence suppressed conduction \citep{Bian2016}, where turbulence restricts the motion of electrons along the loop, and it has been suggested that the standard assumption of collisionally-dominated conduction may be a significant overestimation of true conduction rates.
Simulations using the zero-dimensional enthalpy based EBTEL code \NeedRef{} currently suggest that this turbulent suppression alone is insufficient to maintain the high coronal temperatures and slow cooling times seen in observations, but likely represents an important component of this effect \citep{Bian2018}.
As part of further investigation, work is currently under way to integrate these effects in the \Radyn{} and HYDRAD codes.

\section{Discussions}

We have provided an overview of the commonly used techniques for simulating solar flares and the observable radiation produced from these events.
The core components of radiative transfer, hydrodynamics, and heat conduction have been discussed in depth, along with an overview of the numerical treatments of these terms.
Whilst there are other important terms in the RHD equations, such as the heating model, these represent the core of any flare simulation.

We have also presented a description and validation of the \Lw{} radiative transfer framework and the intentions behind its design.
Frameworks can substantially enhance productivity, and enable the construction of specialised tools without the need to focus on the implementation or performance of the common core of dense numerical code shared by programs of this style.
The power of this will be demonstrated with the experiments presented in Chapters~\ref{Chap:TimeDepRt} and \ref{Chap:2DRT} which leverage \Lw{} significantly, and demonstrate how the addition of small amounts of Python can yield tools that would otherwise require in-depth modification and coupling of existing tools such as RH and \Radyn{}.

Modern RHD simulations have significantly enhanced our understanding of flares, but remain limited in the dimensionality of their treatments and cannot currently produce plausible synthetic light-curves without the artificial superposition of many individual simulations.
It is likely that significant progress will be made on these limitations in the coming 1--2 decades as computing power and numerical techniques improve.
In the meantime, we can undertake numerical experiments to evaluate individual components of these larger treatments (along with re-evaluating certain current assumptions) and we will present several of these using our \Lw{} based experiments.