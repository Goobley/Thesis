\chapter{RADYNVERSION}\label{Chap:Radynversion}
% spell-checker: disable
%TC:group pycode 0 0
\begin{pycode}[Radynversion]
name = 'Radynversion'
chRad = texfigure.Manager(
    pytex,
    './04Radynversion',
    number=4,
    python_dir='./04Radynversion/python',
    fig_dir=   './04Radynversion/Figs',
    data_dir=  './Data/04Radynversion'
)
\end{pycode}
% spell-checker: enable

% \begin{itemize}
%     \item Introduction to inverse problems
%     \item Spectral line inversions
%     \item Introduction to machine learning
%     \item Model description
%     \item Model validation
%     \item 2014-09-06 flar results
% \end{itemize}

\emph{The contents of this chapter are based on my contributions to the research presented in \citet{Osborne2019}.}

As discussed in Sec.~\ref{Sec:InverseProblems}, the assumptions that render NLTE response function based approach to inversions tractable, such as hydrostatic equilibrium, cannot reasonably be applied in flares where flows often approach the sound speed.
We therefore need an inversion technique that can operate outside of these constraints.
In the notation of Sec.~\ref{Sec:InverseProblems}, our standard radiative transfer forward process can be framed as a function $y = f(x)$ with atmospheric inputs $x$ and line profiles $y$.
Clearly this function is not bijective, but if we also capture the information lost in the forward process, we can instead define a bijective function $x = g(y, z)$ such that $g^{-1}$ represents the forward process, and $g$ the inverse process.
Our theory of radiative transfer does not give any immediate insight into the formulation of $g$ with so few constraints, so we instead turn to the field of machine learning from RHD simulations with the intention of learning the form of the information lost in the forward process.

The RADYNVERSION model was the first machine learning model for solar inversions to address the problem of degeneracies in the inversion, but not the first to approach inversions of solar observations.
Simple fully connected networks have long been used to obtain plausible atmospheric parameters based on Milne-Eddington inversions \citep[e.g.][]{Carroll2001, SocasNavarro2005}.
\citet{AsensioRamos2019} and \citet{Milic2020} both presented models focused on the photosphere, that learn to mimic the results of traditional inversions with convolutional neural networks, the former using spatial correlations and inferring the depth of the Wilson depression, the latter using a much simpler model and taking a pixel-by-pixel approach.
These models are not theoretically capable of handling degeneracies, but in practice produce plausible results, much faster than is possible with any traditional gradient-based inversion code.
\citet{Gafeira2021} caution the direct use of these CNN models directly, and instead applied the model of \citet{Milic2020} to initialise traditional inversions, allowing them to converge substantially faster, and in some cases, produce more accurate fits.
More recently, \citet{DiazBaso2021} have presented an elegant Bayesian method using normalising flows, a family of methods related to the one we present below.
They present the results of this method and show that it is capable of providing plausible inversions and posterior distributions using observations of \CaLine{} and Fe\,\textsc{i} \SI{630.15}{\nano\m}.
The field of machine learning based, and assisted, inversions is undergoing rapid development and appears to have a very exciting future.

The RADYNVERSION model and associated training methods are available under the permissive MIT license on GitHub\footnote{\url{https://github.com/Goobley/Radynversion}} with archival on Zenodo \citep{RadynversionZenodo}.

\section{The RADYNVERSION Model}\label{Sec:RadynversionModel}

Our approach to inversions of solar flares is based upon the application of machine learning to the problem as it is framed in Fig.~\ref{Fig:BijectiveMapping}.
We wish to learn the form of the latent space, and by sampling this space sufficiently for a given observation we can infer the likelihoods of parameters at each location in the flaring atmosphere.
Nevertheless, we have no data on which to train which directly characterises the latent space, and thus we turn to the technique of invertible neural networks (INNs) which naturally learn bijective functions to learn the bijective mapping \emph{and} the form of the latent space simultaneously.

The INN is a form of DNN in which invertible blocks are used.
A traditional fully connected or convolutional layer used in an ANN is not generally invertible.
Indeed, whilst a fully connected layer with equal number of inputs and outputs and an invertible activation function \emph{can} be inverted, it is extremely computationally expensive to do so due to the cost of inverting the potentially large square matrix of weights.
The INN is instead built on trivially invertible blocks which can be trained to naturally learn our bijective function.
These blocks are built using DNNs, and are thus universal function approximators themselves, meaning they can learn to map different density (in the sense of probability \emph{density}) distributions to each other.
This is the cornerstone of how the form of the latent space is learned; the INN is trained to map the samples of the latent distribution to a known distribution.
Provided there is sufficient dimensionality to represent the original distribution, it can be remapped to another without any loss of information.
We can therefore choose to represent the latent space as any smooth continuous distribution desired and the INN will internally learn the mapping to the form of the ``true'' latent space contained within the training data.
For simplicity we choose to represent the latent space as the unit multivariate Gaussian distribution with mean 0 and variance 1, which we denote $\mathcal{N}(0, \mathcal{I}_n)$ for an $n$ dimensional case.
Due to the speed of our neural network based solution relative to the cost of the formal solution and iteration that is required in conventional NLTE inversions, we can simply take a large number of samplings of our chosen latent space, and thus generate a probability density function for the atmospheric parameters at each location in the atmosphere, conditioned by our training set.
The approach to inferring atmospheric parameters using the INN therefore differs to the approach of traditional methods that take guided explorations of the latent space by taking much broader samplings of this space and constructing a posterior distribution from these, but similarities can also be drawn between this rapid direct sampling and the ``exploration'' approach of traditional inversion codes.
Pre-trained models such as INNs can have significant performance advantages when applied to many similar inputs, as regression-based approaches will tend to treat these independently and repeat similar trajectories, whereas an INN's training is shared between each application.

The invertible blocks on which our INN is built are known as \emph{affine coupling layers} \citep{2014Dinh,2016Dinh} of the form first presented by \citet{2018Ardizzone}.
The input vector $\vec{x}$ is first split into two halves $[x_1, x_2]$ which undergo the following affine transformations
\begin{align}
    y_1 &= x_1 \otimes \exp(s_2(x_2)) + t_2(x_2),\\
    y_2 &= x_2 \otimes \exp(s_1(y_1)) + t_1(y_1),
\end{align}
where $\otimes$ represents the elementwise product of tensors and $s_i$ and $t_i$ ($i \in \{1, 2\}$) are arbitrarily complex differentiable functions (that need not be invertible).
It is worth noting the order of operations here, as $y_1$ must be computed before $y_2$.
The output $\vec{y}$ is then constructed from the concatenation of $y_1$ and $y_2$.
The inverse of these affine transforms is given by
\begin{align}
    x_2 &= (y_2 - t_1(y_1)) \oslash \exp(s_1(y_1)),\\
    x_1 &= (y_1 - t_2(x_2)) \oslash \exp(s_2(x_2)),
\end{align}
where $\oslash$ represents the elementwise division of tensors.
We have stated that the $s_i$ and $t_i$ functions can be of arbitrary complexity, but clearly they need to be tailored to the particular task and for this reason we apply DNNs in this role.
The networks used for $s_i$ and $t_i$ are identical, save for the application of a $\tan^{-1}$ transformation on the output of the $s_i$ block, which prevents extreme values from being produced whereby the exponential term would dominate, or have no effect on the output of the block.

In the spirit of DNNs we then stack multiple affine coupling layers to allow for increased representational capability within the INN.
As the the input is split in half upon entering each affine layer, we can see that the data in each half is only combined at the elementwise multiplication step in each layer on its journey through the network.
To alleviate this, and further increase the generalisation capabilities of the network, we interleave a permutation layer between each affine coupling layer.
This layer shuffles the data in a random, but fixed order which is different for each permutation layer, before it is split, whilst allowing for trivial reversibility.

\begin{figure}[htbp]
\centering
\begin{tikzpicture}[line width=1pt, >=latex,
    block/.style={
    draw,
    rectangle,
    minimum width={width("Affine Coupling Layer")+2pt},
    font=\small}]
    \node [draw, anchor=center] (Input) {Input};

    \node [block, right=1cm of Input.0, rotate=90, anchor=north] (Acl1) {Affine Coupling Layer};
    \node [block, right=of Acl1.north, rotate=90, anchor=north] (P1) {Permutation Layer};

    \node [block, right=of P1.north, rotate=90, anchor=north] (Acl2) {Affine Coupling Layer};
    \node [block, right=of Acl2.north, rotate=90, anchor=north] (P2) {Permutation Layer};

    \node [block, right=of P2.north, rotate=90, anchor=north] (Acl3) {Affine Coupling Layer};
    \node [block, right=of Acl3.north, rotate=90, anchor=north] (P3) {Permutation Layer};

    \node [block, right=of P3.north, rotate=90, anchor=north] (Acl4) {Affine Coupling Layer};
    \node [block, right=of Acl4.north, rotate=90, anchor=north] (P4) {Permutation Layer};

    \node [block, right=of P4.north, rotate=90, anchor=north] (Acl5) {Affine Coupling Layer};

    \node [draw, below right=1cm and 1cm of Acl5.center, anchor=180] (LatentSpace) {Latent Space};
    \node [draw,
           minimum width={width("Latent Space")+2pt},
           above right=1cm and 1cm of Acl5.center, anchor=180] (Output) {Output};

    \draw[->, color=TolBlue] (Input.20) to (Input.20 -| Acl1.north);
    \draw[->, color=TolBlue] (Input.20 -| Acl1.south) -- (Input.20 -| P1.north);
    \draw[->, color=TolBlue] (Input.20 -| P1.south)   -- (Input.20 -| Acl2.north);
    \draw[->, color=TolBlue] (Input.20 -| Acl2.south) -- (Input.20 -| P2.north);
    \draw[->, color=TolBlue] (Input.20 -| P2.south)   -- (Input.20 -| Acl3.north);
    \draw[->, color=TolBlue] (Input.20 -| Acl3.south) -- (Input.20 -| P3.north);
    \draw[->, color=TolBlue] (Input.20 -| P3.south)   -- (Input.20 -| Acl4.north);
    \draw[->, color=TolBlue] (Input.20 -| Acl4.south) -- (Input.20 -| P4.north);
    \draw[->, color=TolBlue] (Input.20 -| P4.south)   -- (Input.20 -| Acl5.north);
    \draw[->, color=TolBlue] (Input.20 -| Acl5.south) to[out=0, in=180] (Output.180);

    \node [draw, circle, fill, inner sep=0pt, minimum size=2pt,
           right=2cm of Acl5.center] (Mix) {};

    \draw[->, color=TolTeal] (Output.south -| Mix) -- (Mix);
    \draw[->, color=TolTeal] (LatentSpace.north -| Mix) -- (Mix);
    \draw[->, color=TolTeal] (Mix) to[out=180, in=0] (Input.340 -| Acl5.south);
    \draw[->, color=TolTeal] (Input.340 -| Acl5.north) -- (Input.340 -| P4.south);
    \draw[->, color=TolTeal] (Input.340 -| P4.north) -- (Input.340 -| Acl4.south);
    \draw[->, color=TolTeal] (Input.340 -| Acl4.north) -- (Input.340 -| P3.south);
    \draw[->, color=TolTeal] (Input.340 -| P3.north) -- (Input.340 -| Acl3.south);
    \draw[->, color=TolTeal] (Input.340 -| Acl3.north) -- (Input.340 -| P2.south);
    \draw[->, color=TolTeal] (Input.340 -| P2.north) -- (Input.340 -| Acl2.south);
    \draw[->, color=TolTeal] (Input.340 -| Acl2.north) -- (Input.340 -| P1.south);
    \draw[->, color=TolTeal] (Input.340 -| P1.north) -- (Input.340 -| Acl1.south);
    \draw[->, color=TolTeal] (Input.340 -| Acl1.north) -- (Input.340);
\end{tikzpicture}
\caption[Structure of the invertible RADYNVERSION network.]{Structure of the final RADYNVERSION network. The forward process is shown with the {\color{TolBlue}blue} arrows, and the inverse process with {\color{TolTeal}teal} arrows.}
\label{Fig:RadynversionDiagram}
\end{figure}

For the RADYNVERSION\footnote{RADYNVERSION is a portmanteau of \Radyn{} and ``inversion''.} model we use five affine coupling layers, with four interleaved permutation layers.
This is shown schematically in Fig. \ref{Fig:RadynversionDiagram}.
Given the presence of four DNNs per affine coupling layer, our final model is composed of twenty DNNs.
Each of these networks is an individual four-layer fully connected network utilising leaky ReLU activation functions after each of the first three layers, and a ReLU following the final layer.
This architecture was developed empirically, guided both by the examples presented in \citep{2018Ardizzone} and machine-learning best practices.
A commonly used approach that we applied extensively is to take a small subset of the the training data and attempt to find a model which can successfully overfit this mapping; a model that can memorise the mapping for a subset of inputs can demonstrably learn the problem (although it may not have enough dimensionality to generalise, depending on the range and complexity of the input data).
Models with both three and five affine coupling layers were trialled, with the latter performing significantly better.
Whilst it is possible to continue to increase the depth of this network, this is not without significant computational cost, and did not seem necessary given the quality of the results.

RADYNVERSION is trained using RHD simulations generated with \Radyn{}, which contain the structure of a model flaring atmosphere and the synthesised emergent radiation (here the \Ha{} and \CaLine{} spectral lines).
The input to the RADYNVERSION network then consists of a reduced set of atmospheric parameters at a given point in time; in our case the temperature $T$, electron density $n_e$, and velocity $v$.
These are provided to the network on a fixed height stratification, with 50 points covering the entire atmosphere.
The large dynamic range of these parameters (both across a single atmosphere, and between different timesteps at a fixed location in the atmosphere) can have a negative impact on the training and accuracy of the ANN, and we therefore map $T\mapsto\log_{10} T$, $n_e\mapsto\log_{10} n_e$, and $\varv\mapsto\textnormal{sign}(\varv)\log_{10} \left( |\varv_{\si{\kilo\metre\per\s}}| + 1\right)$.
The mapping for $\varv$ serves to scale it based on its base-10 logarithmic value, whilst preserving its sign information.
These logarithmic mappings preserve detail better over each decade than a simple linear rescaling.

The output consists of line profiles, in this case \Ha{} and \CaLine{}.
Both of these are interpolated onto fixed wavelength grids, with 30 points each (a half width of \SI{0.14}{\nano\metre} for \Ha{} and \SI{0.1}{\nano\metre} for \CaLine{}).
The intensity values of the spectral lines are scaled to cover the range [0, 1] whilst preserving the relative intensity of the two (which conveys important information regarding continuum emission).

Our model then has an input dimensionality of 150 and an output dimensionality of 60.
We choose, by experimentation, to set the size of the latent space to the same as the input, however we cannot prove the optimality of such a choice as it depends on the (unknown) intrinsic dimensionality of the problem.
Thus the input and total output (i.e. output and latent space) must be of length at least 210.
To improve the generalisation performance of the network and allow it a greater dimensionality for its representation of the data we choose to set the input and output size to 384.
The input to the network is zero-padded to this length, and the output and latent space are concatenated with zero-padding in between.
This width was also determined empirically, as it was found that the model had difficulties converging for the minimum width of 210.
This problem was greatly mitigated by increasing the width, a technique that was found in the examples associated with \citep{2018Ardizzone}, so no other values were trialled.
The deep neural networks used inside the affine coupling layers have an input and output of length 192, but this is increased to 384 for the inner layers, to further increase their representational ability.

The RADYNVERSION model presented here considers each set of atmospheric parameters and observables as instantaneous quantities.
As we have discussed, it is usually necessary to consider time-dependent populations in flares, and clearly we do not do so here.
The atomic populations are not considered directly with this model, thus we are interested in determining whether there is sufficient information present in this reduced description of the atmosphere (under the inherent assumption in the training set that all snapshots originate from the same starting atmosphere) to reproduce the emergent line profiles and whether an ANN can then learn to decode this information.

\section{Training Data}

To train this model we use 81 \Radyn{} simulations computed by the F-CHROMA project \footnote{\url{https://star.pst.qub.ac.uk/wiki/public/solarmodels/start.html}}.
These models all start from a variant of the VAL3C quiet sun atmosphere \citep{Vernazza1981}, slightly modified to remain stable in \Radyn{}.
All models are heated by a symmetric triangular electron beam pulse, modelled using the Fokker-Planck module (with an initial power law distribution of electron energies), of \SI{20}{\s} duration, with a peak at \SI{10}{\s}.
The total beam deposition varies between \SI{3e10}{\erg\per\square\cm} and \SI{1e12}{\erg\per\square\cm}, the low-energy cut-off is one of \{10, 15, 20, 25\}~\si{\kilo\electronvolt}, and the spectral index of the electron energy distribution is one of \{3, 4, 5, 6, 7, 8\}.
All of these simulations last for \SI{50}{\s}, with data saved every \SI{0.1}{\s}.

Not all of these simulations converged due to certain parameter combinations.
In particular some simulations with lower values for the low-energy cut-off, higher spectral indices, and high total energy deposition were not present in the grid of models.
From the 81 simulations we then have 40,500 individual timesteps, of which we separate 20\% for validation purposes.
The atmospheric parameters and line profiles are mapped onto their fixed grids and the parameters are prepared as discussed previously.
Our height stratification is chosen to primarily sample the chromosphere, and places 45 linearly spaced points below \SI{3.5}{\mega\metre}, with a constant spacing of \SI{79.2}{\kilo\metre}.
The remaining 5 points are then exponentially spread through the corona from \SIrange{3.5}{10}{\mega\metre}.

\section{Training Method}

Our training method is based on the one presented in \citet{2018Ardizzone} and the network is constructed using their framework, FrEIA\footnote{\url{https://github.com/VLL-HD/FrEIA}}.
The INN is trained in both directions to ensure the conditioning of both the forward and inverse problems.
The model is trained using minibatching with the same minibatch of the training set being used in both directions.
Both training directions are constrained by two loss functions and a linear combination of these serves as our final loss to minimise.
The forward direction (from atmospheric parameters to line profiles) uses an L2 loss ($||y-y_\textnormal{true}||_2^2$, where $y$ indicates the output of the network and $y_\textnormal{true}$ the expected output) on the output vector of line profiles and zero padding.
This latent space is constrained by a Maximum Mean Discrepancy (MMD) loss.
The MMD is a loss that compares distributions from finite samples, and is computed between batches of [$y$, $z$] and [$y_\textnormal{true}$, $\mathcal{N}(0, \mathcal{I}_z)$].
This is discussed in depth, along with implementation details in Section~\ref{Sec:Mmd}.
During the forward process the MMD loss is used to ensure that the network learns to map the true latent space to our chosen form for it (the multivariate unit Gaussian distribution).
A traditional regression loss cannot be applied here, as we would have to assign fixed samples from the latent space for each timestep in the training set, which cannot be done without understanding the true latent space.
Its aim is instead to condition the form of the distribution produced in the latent space.
To this end, whilst $y$ is included in the MMD loss terms (as this is an important component of the output), the gradients on $y$ due to the MMD loss are ignored, so as not to affect the training of the forward model i.e. whilst the elements of $y$ are considered when computing the value of the MMD loss, the MMD can only affect the weights determining $z$.
The convergence of both the L2 and MMD losses ensures that samples of $z$ are correctly independent of $y$ as they must not contain copies of the same information (i.e. they must be independent) for the reverse process to work correctly.

The inverse process is trained similarly, with an additional two losses.
An L2 loss is used for $x$ and the zero-padding to ensure the expected atmosphere parameters are produced (and that the padding remain 0), and an MMD loss ensuring the correct distribution of $x$ for random latent samples.

Both of the forward and backwards losses are linearly combined to produce a set of weighted gradients used to update the network.
We define three hyperparameter weights for this purpose $w_\textnormal{pred}$, $w_\textnormal{latent}$, and $w_\textnormal{rev}$.
These are combined to produce the losses
\begin{align}
    \textnormal{loss}_f &= w_\textnormal{pred} L2_f + w_\textnormal{latent} MMD_f,\\
    \textnormal{loss}_b &= 0.5w_\textnormal{pred} L2_b + \xi(n)w_\textnormal{rev} MMD_b,
\end{align}
where $f$ and $b$ represent the forward and backward terms respectively, and $\xi$ is a term that gradually increases towards unity over the course of a fade-in period.
It is parametrised as
\begin{equation}
    \xi(n) = \left( \min\left( \frac{n}{0.4 N_\textnormal{fade}}, 1 \right) \right)^3,
\end{equation}
where $n$ is the current epoch, and $N_\textnormal{fade}$ is the fade-in period.
This terms serves to slowly increase the effect of the MMD loss, as this was otherwise found to hinder the training of both the forward and inverse problems by dominating $\textnormal{loss}_b$ and guiding the system away from a solution that minimised both terms.
To ensure that the output in the zero-padded sections remains close to zero we also use $1-\xi$ to initialise these with a small amount of random noise, decaying over this same period.
This increases the activation of these neurons early on, forcing the network to learn that these must be adjusted towards 0 for all inputs.
Through a manual hyperparameter search we found that for a fade-in period of 800 epochs, a good choice for the loss weights was $w_\textnormal{pred}=4000$, $w_\textnormal{latent}=900$, and $w_\textnormal{rev}=1000$.
After the fade-in period the network was trained in blocks of 400 epochs, increasing the value of $w_\textnormal{pred}$ by 1000 for each of these blocks to fine-tune the line profiles and atmospheric parameters which were otherwise a little noisy.
From 4,800 epochs to 12,000 epochs the network was trained in blocks of 600 epochs, with the value of $w_\textnormal{pred}$ again being increased by 1000.
These weights were all tuned empirically, and others were also found to yield good convergence, however we found it important that the L2 weight be a factor of 2 or more larger than the MMD weights or the forward process would not reliably converge.

The update of the weights inside the neural networks is computed from the gradients of the linearly combined losses using the Adam optimisation algorithm \citep{2014Kingma} with hyperparameters $\beta_1=\beta_2=0.8$ and $\epsilon=1\times10^{-6}$.
The $\beta_i$ terms control the decay rate for momentum of the first- and second-moment estimates of the gradients and $\epsilon$ simply prevents division by zero.
These gradients are limited to a range of $\pm15$ to help further mitigate problems with exploding gradients.
This does not affect the final solution as the gradients will become small as we approach a minimum.
The learning rate was initialised to $1.5\times10^{-3}$ and decays by a factor of $0.004^{1/1333}$ every 12 epochs.
Each minibatch contained 500 different samples and 20 minibatches were used per learning epoch.
The final model was selected based on its L2 performance for the forward and backwards results on the validation set.
In this case the best performing model was the one saved after 11,400 epochs of training.


\section{Maximum Mean Discrepancy}\label{Sec:Mmd}

\emph{The content of this section draws primarily from \citet{Sriperumbudur2009}, \citet{2012Gretton}, \citet{Muandet2017}, and Gretton's lecture content, currently available online}\footnote{\url{http://www.gatsby.ucl.ac.uk/~gretton/teaching.html}}.
% e.g. http://www.gatsby.ucl.ac.uk/~gretton/coursefiles/lecture1_whatIsRKHS.pdf

The maximum mean discrepancy (MMD) is a statistic for comparing two distributions, based on samples drawn from these, and computes the difference in expectations over functions in the unit ball of a reproducing kernel Hilbert space (RKHS).
It represents an estimate of the distance between the mean features of the sampled distributions in the space defined by a chosen kernel i.e. the greater similarity between the two sampled distributions the smaller the value of the MMD.

A Hilbert space is a space in which an inner product is defined that is linear, symmetric, and where the inner product of an element with itself is positive definite.
A norm can be defined from this inner product $||f|| = \sqrt{\langle f, f \rangle}$.
These spaces must also be Cauchy complete, implying that every Cauchy sequence (convergent sequence), must converge to a point in the space.

An RKHS $\mathcal{H}$ is then a Hilbert space of functions $f : \mathcal{X} \rightarrow \mathbb{R}$ for which the evaluation functional $\delta_x : f \mapsto f(x)$ is bounded and continuous\footnote{This can be generalised to functions $f : \mathcal{X} \rightarrow \mathbb{C}$.}.
The RKHS has the property that two functions that are close in norm in $\mathcal{H}$ are then pointwise close when evaluated anywhere over $\mathcal{X}$.
The kernel associated with this RKHS is a positive definite kernel $k : \mathcal{X} \times \mathcal{X} \rightarrow \mathbb{R}$ if there exists a map $\phi : \mathcal{X} \rightarrow \mathcal{H}$ such that $\forall\, x,y \in \mathcal{X}$
\begin{equation}
    k(x,y) = \langle \phi(x), \phi(y) \rangle_\mathcal{H}.
\end{equation}
The map $\phi$ is termed the feature map, and $\mathcal{H}$ is known as the feature space.

Let us define two probability distributions $P$ and $Q$ and draw observations $X$ and $Y$ in an independent and identically distributed fashion from $P$ and $Q$ respectively.
The MMD is then defined by
\begin{equation}\label{Eq:MmdDef}
\begin{aligned}
    \textnormal{MMD}^2 &= ||\mu_P - \mu_Q ||_\mathcal{H}^2\\
    &= \langle \mu_P, \mu_P \rangle_\mathcal{H} +
       \langle \mu_Q, \mu_Q \rangle_\mathcal{H} -
       2 \langle \mu_P, \mu_Q \rangle_\mathcal{H},
\end{aligned}
\end{equation}
where $\mu_A$ represents the mean embedding of the distribution $A$ in the feature space, which is the expectation vector of the features of $\mathcal{H}$ evaluated for this distribution.
The kernel associated with $\mathcal{H}$ is \emph{characteristic} if the feature map is injective, and in this case the MMD is zero iff $P = Q$.
It was shown by \citet{Sriperumbudur2009} that all measurable and bounded strictly positive definite kernels are characteristic, and we therefore limit ourselves to this class.

$\mu_P$ can now be written in terms of the features of $\mathcal{H}$
\begin{equation}
    \mu_P = [\ldots \mathbb{E}_P[\phi_i(X)] \ldots],
\end{equation}
where $\mathbb{E}_P$ denotes the expected value of its argument with respect to $P$, and $\phi_i$ is the $i$th feature of the feature map (which may contain infinitely many features).
We can then write
% Muandet2017, p51, crossed with Gretton Madrid notes
\begin{equation}
    \langle \mu_P, \mu_P \rangle_\mathcal{H} = \langle \mathbb{E}_P [k(\cdot\, ,\, X)], \mathbb{E}_{P} [k(\cdot\, ,\, X^\prime)] \rangle_\mathcal{H} = \mathbb{E}_{P} [k(X, X^\prime)],
\end{equation}
where $X^\prime$ is an independently drawn copy of $X$ from $P$, and $k(\cdot\, ,\, X)$ refers to the function, and not its evaluation at a particular point.
Thus $k(\cdot,\, X)$ is the feature map $\phi(X)$.
We define $Y^\prime$ analogously for $Y$ and $Q$ to then write \eqref{Eq:MmdDef} as
\begin{equation}
    \textnormal{MMD}^2 = ||\mu_P - \mu_Q|| ^2
                   = \mathbb{E}_P [k(X, X^\prime)] + \mathbb{E}_Q [k(Y, Y^\prime)] - 2 \mathbb{E}_{P,Q}[k(X,Y)].
\end{equation}
Here the first two terms compare the distributions for internal similarity, whereas the last compares the intra-distribution similarity.

For length $n$ finite observations $X$ and $Y$ we can expand this to provide an unbiased sample estimate
\begin{equation}
    \widehat{\textnormal{MMD}}_u^2 = \frac{1}{n(n-1)} \sum_{i\neq j} k(x_i, x_j) + \frac{1}{n(n-1)} \sum_{i\neq j} k(y_i, y_j) - \frac{2}{n^2} \sum_{i, j} k(x_i, y_j).
\end{equation}
As this statistic is unbiased and computed from a finite sample size, it can be negative when $P$ and $Q$ are similar distributions, despite being the definition of $\textnormal{MMD}^2$.
We therefore employ a biased estimate of the MMD which remains positive in all scenarios
\begin{equation}
    \widehat{\textnormal{MMD}}_b^2 = \frac{1}{n^2}\sum_{i, j}\left( k(x_i, x_j) + k(y_i, y_j) - 2k(x_i, y_j) \right).
\end{equation}
This biased form of the MMD is also more efficient to compute using the vectorised tensor operations present in machine learning frameworks like pytorch.

The choice of kernel used in the MMD will then determine how this statistic is able to distinguish between distributions.
We choose to employ the inverse multi-quadric (IMQ) kernel as used by \citet{2017Tolstikhin} and \citet{2018Ardizzone}
\begin{equation}
    k_\alpha(x, y) = \frac{\alpha^2}{\alpha^2 + ||x-y||_2^2}.
\end{equation}
This kernel meets the strictly positive definite criterion that is necessary for a characteristic kernel of an RKHS, but contains a free parameter $\alpha$.
This equation therefore describes a family of kernels, which will have different performance depending on the data and the choice of $\alpha$.
We were unable to empirically determine a single value for $\alpha$ for which the MMD could reliably distinguish between the two distributions well enough to optimise over, however it was found that the value of the MMD for different values of $\alpha$, whilst retaining fixed $X$ and $Y$, peaked for a particular value of $\alpha$.
The kernel of the family with this value of $\alpha$ is able to better resolve the differences between our fixed samples and is therefore best suited (of the tested values) to guiding the optimisation of the weights associated with these terms.
This approach was used to refine the MMD losses by updating the $\alpha$ parameter of the kernel to the value for which the MMD was maximal (given the fixed input samples from this epoch) every five epochs of training.
Modifying the MMD loss in this way ensures that it is most sensitive to the scale of the currently differing features between our distribution samples.

Minimising the forward MMD loss then ensures the independence of data stored in the latent space and that the latent space takes a normal unit distribution form, whilst minimising the backwards MMD ensures that the distribution of atmospheres generated with different draws of the latent space is a plausible distribution when compared against the training set.

\section{Validation}

% spell-checker: disable
\begin{pycode}[Radynversion]
def logvel_to_vel(v):
    vSign = v / np.abs(v)
    vSign[np.isnan(vSign)] = 0
    vel = vSign * (10**np.abs(v) - 1.0)
    return vel

def find_range_in_schema(schema, name):
    nameIdx = 0
    for i, s in enumerate(schema):
        if s[0] == name:
            nameIdx = i
            break
    else:
        raise ValueError('Name %s not found in schema %s' % (name, repr(schema)))

    startLoc = 0
    for i in range(nameIdx):
        startLoc += schema[i][1]
    endLoc = startLoc + schema[nameIdx][1]
    return range(startLoc, endLoc)

with open(chRad.data_file('Validation/Schemas.pickle'), 'rb') as f:
    schemas = pickle.load(f)

forwards = np.load(chRad.data_file('Validation/ForwardsProcess.npz'))
reverse = np.load(chRad.data_file('Validation/ReverseProcess.npz'))
z = schemas['z']
zMm = schemas['z'] / 1e8
wls = schemas['wls']

fig, ax = plt.subplots(2, 2, #constrained_layout=True,
                       figsize=texfigure.figsize(pytex, scale=1, height_ratio=0.75))
ax = ax.ravel()
ax = [ax[0], ax[0].twinx(), *ax[1:]]
ax[0].plot(zMm, forwards['xTrue'][0, 0])
ax[1].plot(zMm, forwards['xTrue'][0, 1], c='C1')
ax[2].plot(zMm, logvel_to_vel(forwards['xTrue'][0, 2]), c='C2')
ax[0].set_ylabel(r'$\log{n_e}$ [\si{\cm\tothe{-3}}]', c='C0')
ax[0].set_xlabel(r'$z$ [\si{\mega\metre}]')
ax[1].set_ylabel(r'$\log{T}$ [\si{\K}]', c='C1')
ax[2].set_ylabel(r'$\varv$ [\si{\kilo\metre\per\second}]', c='C2')
ax[2].set_xlabel(r'$z$ [\si{\mega\metre}]')


halphaCoords = find_range_in_schema(schemas['outSchema'], 'Halpha')
caCoords = find_range_in_schema(schemas['outSchema'], 'Ca8542')
haCentre = 0.5 * (wls[0][0] + wls[0][-1])
caCentre = 0.5 * (wls[1][0] + wls[1][-1])
ax[3].plot((wls[0] - haCentre) / 10, forwards['yTrue'][0, 0], c='C2')
ax[3].plot((wls[0] - haCentre) / 10, forwards['yzPred'][0, halphaCoords], '--', c='C4')
ax[4].plot((wls[1] - caCentre) / 10, forwards['yTrue'][0, 1], c='C2', label='Ground Truth')
ax[4].plot((wls[1] - caCentre) / 10, forwards['yzPred'][0, caCoords], '--', c='C4', label='Predicted')
ax[3].xaxis.set_major_locator(plt.MaxNLocator(6))
ax[4].xaxis.set_major_locator(plt.MaxNLocator(6))
fig.legend(loc='lower left', frameon=False, bbox_to_anchor=(0.42, 0.45))

ax[3].set_ylabel('Normalised Intensity')
ax[3].set_xlabel(r'$\Delta\lambda$ [\si{\nano\metre}]')
ax[4].set_xlabel(r'$\Delta\lambda$ [\si{\nano\metre}]')
ax[3].set_title(r'H$\alpha$')
ax[4].set_title(r'Ca\,\textsc{ii} \SI{854.2}{\nano\metre}')

fig.tight_layout()
latexFig = chRad.save_figure('RadynversionValidationForwards', fig, fext='.pgf')
latexFig.caption = 'Validation of the RADYNVERSION forwards process on unseen data. The upper row shows the atmospheric input, and the lower row the expected output along with the predicition from the network.'
latexFig.short_caption = r'Validation of RADYNVERSION forwards model.'
latexFig.placement = r'ptb'
\end{pycode}

\begin{pycode}[Radynversion]
from matplotlib.colors import LinearSegmentedColormap, PowerNorm
cmapNe = [(1.0,1.0,1.0,0.0), (*sns.color_palette()[0], 1.0)]
neColors = LinearSegmentedColormap.from_list('ne', cmapNe)
cmapTemp = [(1.0,1.0,1.0,0.0), (*sns.color_palette()[1], 1.0)]
tempColors = LinearSegmentedColormap.from_list('temp', cmapTemp)
cmapVel = [(1.0,1.0,1.0,0.0), (*sns.color_palette()[2], 1.0)]
velColors = LinearSegmentedColormap.from_list('vel', cmapVel)
powerNormIdx = 0.2

fig, ax = plt.subplots(1, 2, #constrained_layout=True,
                       figsize=texfigure.figsize(pytex, scale=1, height_ratio=0.4))
ax = ax.ravel()
ax = [ax[0], ax[0].twinx(), *ax[1:]]

zEdges = [zMm[0] - 0.5 * (zMm[1] - zMm[0])]
for i in range(zMm.shape[0] - 1):
    zEdges.append(0.5 * (zMm[i] + zMm[i+1]))
zEdges.append(zMm[-1] + 0.5 * (zMm[-1] - zMm[-2]))

xPred = reverse['xPred']
xTrue = reverse['xTrue']

neEdges = np.linspace(8, 15, 101)
neIdxs = find_range_in_schema(schemas['inSchema'], 'ne')
tempEdges = np.linspace(3, 8, 101)
tempIdxs = find_range_in_schema(schemas['inSchema'], 'temperature')
velIdxs = find_range_in_schema(schemas['inSchema'], 'vel')
minVel = np.min(np.median(logvel_to_vel(xPred[:, velIdxs]), axis=0))
minVel = np.sign(minVel) * 2 * np.abs(minVel) if minVel <= 0 else 0.9 * minVel
maxVel = 2 * np.max(np.median(logvel_to_vel(xPred[:, velIdxs]), axis=0))
velEdges = np.linspace(minVel, maxVel, num=101)

ax[0].hist2d(np.concatenate([zMm] * xPred.shape[0]),
             xPred[:, neIdxs].reshape(-1),
             bins=(zEdges, neEdges), cmap=neColors, norm=PowerNorm(powerNormIdx), rasterized=True)
ax[1].hist2d(np.concatenate([zMm] * xPred.shape[0]),
             xPred[:, tempIdxs].reshape(-1),
             bins=(zEdges, tempEdges), cmap=tempColors, norm=PowerNorm(powerNormIdx), rasterized=True)
ax[0].plot(zMm, xTrue[0, 0], 'k--', linewidth=0.5)
ax[1].plot(zMm, xTrue[0, 1], 'k--', linewidth=0.5)
ax[0].set_xlim(None, 10.5)

ax[2].hist2d(np.concatenate([zMm] * xPred.shape[0]),
             logvel_to_vel(xPred[:, velIdxs].reshape(-1)),
             bins=(zEdges, velEdges), cmap=velColors, norm=PowerNorm(powerNormIdx), rasterized=True)
ax[2].plot(zMm, logvel_to_vel(xTrue[0, 2]), 'k--', linewidth=0.5)
ax[2].set_xlim(None, 10.5)


ax[0].set_ylabel(r'$\log{n_e}$ [\si{\cm\tothe{-3}}]', c=cmapNe[-1])
ax[0].set_xlabel(r'$z$ [\si{\mega\metre}]')
ax[1].set_ylabel(r'$\log{T}$ [\si{\K}]', c=cmapTemp[-1])
ax[2].set_ylabel(r'$\varv$ [\si{\kilo\metre\per\second}]', c=cmapVel[-1])
ax[2].set_xlabel(r'$z$ [\si{\mega\metre}]')

fig.tight_layout()
latexFig = chRad.save_figure('RadynversionValidationReverse', fig, fext='.pgf', dpi=500)
latexFig.caption = r'Validation of the RADYNVERSION reverse process from the ground truth line profiles shown in Fig.~\ref{Fig:RadynversionValidationForwards}. The two-dimensional histograms show the probability density of the solution in each altitude node, and the black dashed lines the expected solution.'
latexFig.short_caption = r'Validation of the RADYNVERSION reverse model.'
latexFig.placement = 'ptb'
\end{pycode}

\py[Radynversion]|chRad.get_figure('RadynversionValidationForwards')|
% spell-checker: enable

During and after training, the RADYNVERSION model is validated against the unseen validation data separated from the training set.
An example taken from the validation set showing the forward process is presented in Fig.~\ref{Fig:RadynversionValidationForwards}.
The upper row shows the atmosphere input into the model whilst the lower row shows the expected output (solid lines) and the output of the forward process (dashed lines).
The mean squared error in the scaled intensity at each wavelength point for the validation set is $5.74\times10^{-5}$ showing that the model can very accurately predict the scaled line profiles based on the atmospheric parameters for unseen atmospheres.

\py[Radynversion]|chRad.get_figure('RadynversionValidationReverse')|

Due to the inherent non-uniqueness and presence of possible degeneracies it is harder to numerically evaluate the performance of the model's reverse process.
For each pair of line profiles we draw a large number of samples from the latent space and infer the predicted atmosphere from each latent space draw combined with the pair of line profiles.
This gives a large number of possible sets of atmospheric parameters which we plot on a two dimensional histogram to show the probability density of the solution in each altitude node.
This method then allows us to gauge possible degeneracies and establish the relative probabilities of different solutions.
An example validation inversion is shown in Fig.~\ref{Fig:RadynversionValidationReverse}, using the ground truth output line profiles shown in the forward validation process as input.
These histograms were generated from 10\,000 draws latent space draws, and their values were gamma corrected (with $\gamma=$ \py[Radynversion]|powerNormIdx|) to enhance the visibility of less probable solutions.
The overplotted black dashed lines show the ground truth solution for each of the atmospheric parameters, and overlap the peak density of the histogram extremely well.
The histogram remains very narrow in the lower atmosphere, but starts to expand above \SI{3}{\mega\metre}, where the solution is poorly constrained by the chromospheric lines in use here.
This effect is most visible on the velocity plot, but despite the increase in uncertainty, the solutions remain accurate on the validation set due to the model's conditioning to the RADYN training data.

\section{Proof of Concept Results}

\emph{The proof of concept application of the RADYNVERSION model was primarily undertaken by my co-authors. I will briefly summarise the primary results in this section, but the methodology is more fully described in the associated paper.}

% spell-checker: disable
\begin{pycode}[Radynversion]
from astropy.io import fits
ca_file = chRad.data_file('crisp_l2_20140906_152724_8542_r00459.fits')
ha_file = chRad.data_file('crisp_l2_20140906_152724_6563_r00459.fits')

ha_central_idx = 7
ca_central_idx = 12
ha_hw = 1.4
ca_hw = 1.0 #1.0 because RADYN has a 1A half-width for calcium

# crisp = CRISP(ca_file=ca_file,ha_file=ha_file,rotate=True)
ca = fits.open(ca_file)
ha = fits.open(ha_file)

im_centre_ca = ca[0].data[12]
im_centre_ha = ha[0].data[7]
im_bwing_ca =  ca[0].data[4]
im_bwing_ha =  ha[0].data[0]
im_rwing_ca =  ca[0].data[20]
im_rwing_ha =  ha[0].data[14]
px_width = ca[0].header['CDELT1']
point_1_ha = np.array([30.72,37.47])
point_2_ha = np.array([50.37,3.73])
point_1_ca = np.array([30.22,36.47])
point_2_ca = np.array([49.87,2.73])
point_2_ca = np.array([35, 5])
point_2_ha = point_2_ca
# point_1_ha = np.array([53.5, 39.5])
# point_1_ha = np.array([49.9, 42.3]) #broken
# point_1_ha = np.array([50.27, 41.50]) # not too bad
# point_1_ha = np.array([49.191, 42.294]) # True one for Ha from paper.
point_1_ha = np.array([49.05, 42.19]) # Close.
point_1_ca = point_1_ha

fig, ax = plt.subplots(ncols=3,nrows=2,
figsize=texfigure.figsize(pytex, scale=1, height_ratio=0.7),
constrained_layout=True, sharex=True, sharey=True)
sol_cm = 'Greys_r'
ax[0,0].imshow(im_bwing_ca,extent=[0,px_width*im_centre_ca.shape[1],0,px_width*im_centre_ca.shape[0]],origin="lower",cmap=sol_cm)
ax[0,0].set_title(r"$\Delta\lambda=-0.08$\,nm")
ax[0,0].set_ylabel(r"y [$^{\prime\prime}$]")
ax[0,0].plot(point_1_ca[0],point_1_ca[1],"wo")
ax[0,0].plot(point_2_ca[0],point_2_ca[1],"ws")
ax[0,1].imshow(im_centre_ca,extent=[0,px_width*im_centre_ca.shape[1],0,px_width*im_centre_ca.shape[0]],origin="lower",cmap=sol_cm)
ax[0,1].set_title(r"$\lambda_0=854.2$\,nm")
ax[0,1].plot(point_1_ca[0],point_1_ca[1],"wo")
ax[0,1].plot(point_2_ca[0],point_2_ca[1],"ws")
ax[0,2].imshow(im_rwing_ca,extent=[0,px_width*im_centre_ca.shape[1],0,px_width*im_centre_ca.shape[0]],origin="lower",cmap=sol_cm)
ax[0,2].set_title(r"$\Delta\lambda=0.08$\,nm")
ax[0,2].plot(point_1_ca[0],point_1_ca[1],"wo")
ax[0,2].plot(point_2_ca[0],point_2_ca[1],"ws")
ax[1,0].imshow(im_bwing_ha,extent=[0,px_width*im_centre_ca.shape[1],0,px_width*im_centre_ca.shape[0]],origin="lower",cmap=sol_cm)
ax[1,0].set_title(r"$\Delta\lambda=-0.14$\,nm")
ax[1,0].set_ylabel(r"y [$^{\prime\prime}$]")
ax[1,0].set_xlabel(r"x [$^{\prime\prime}$]")
ax[1,0].plot(point_1_ha[0],point_1_ha[1],"wo")
ax[1,0].plot(point_2_ha[0],point_2_ha[1],"ws")
ax[1,1].imshow(im_centre_ha,extent=[0,px_width*im_centre_ca.shape[1],0,px_width*im_centre_ca.shape[0]],origin="lower",cmap=sol_cm)
ax[1,1].set_title(r"$\lambda_0=656.3$\,nm")
ax[1,1].set_xlabel(r"x [$^{\prime\prime}$]")
ax[1,1].plot(point_1_ha[0],point_1_ha[1],"wo")
ax[1,1].plot(point_2_ha[0],point_2_ha[1],"ws")
ax[1,2].imshow(im_rwing_ha,extent=[0,px_width*im_centre_ca.shape[1],0,px_width*im_centre_ca.shape[0]],origin="lower",cmap=sol_cm)
ax[1,2].set_title(r"$\Delta\lambda=0.14$\,nm")
ax[1,2].set_xlabel(r"x [$^{\prime\prime}$]")
ax[1,2].plot(point_1_ha[0],point_1_ha[1],"wo")
ax[1,2].plot(point_2_ha[0],point_2_ha[1],"ws")

lFig = chRad.save_figure('CrispPlot', fig, fext='.pgf', dpi=600)
lFig.caption = r'Observations of the the M1.1 flare from AR 12157 on 2014-09-06 just after flare onset. The upper row shows images in the \CaLine{} band, and the lower row shows equivalent images from the \Ha{} band. These two inverted pixels are marked by the square (off-ribbon) and circle (on-ribbon). Wavelengths in this figure use their values in air.'
lFig.short_caption = r'CRISP context image of 2014-09-06 M1.1 flare just after flare peak.'
lFig.placement = 'ptb'
\end{pycode}

\begin{pycode}[Radynversion]
from utils import intensity_vector, interp_to_radyn_grid, normalise
ca_1 = intensity_vector(ca, point_1_ca,coord_type="arcsec")
ha_1 = intensity_vector(ha, point_1_ha,coord_type="arcsec")
ca_2 = intensity_vector(ca, point_2_ca,coord_type="arcsec")
ha_2 = intensity_vector(ha, point_2_ha,coord_type="arcsec")

ca_centre_wvl = ca[0].header["TWAVE1"]
ca_wvls = ca[1].data
ha_centre_wvl = ha[0].header["TWAVE1"]
ha_wvls = ha[1].data

new_ca_1 = interp_to_radyn_grid(ca_1,ca_centre_wvl,ca_hw,ca_wvls)
new_ha_1 = interp_to_radyn_grid(ha_1,ha_centre_wvl,ha_hw,ha_wvls)
new_ca_2 = interp_to_radyn_grid(ca_2,ca_centre_wvl,ca_hw,ca_wvls)
new_ha_2 = interp_to_radyn_grid(ha_2,ha_centre_wvl,ha_hw,ha_wvls)

new_ca_1, new_ha_1 = normalise(new_ca_1,new_ha_1)
new_ca_2, new_ha_2 = normalise(new_ca_2,new_ha_2)

fig, ax = plt.subplots(2,2,
figsize=texfigure.figsize(pytex, scale=1, height_ratio=0.65),
constrained_layout=True)
ax[0,0].plot(new_ca_1[0]/10 - ca_centre_wvl/10,new_ca_1[1])
ax[0,0].set_title(r"Ca\,\textsc{ii} \SI{854.2}{\nano\metre} for the circular point")
ax[0,0].set_ylabel("Normalised Intensity")
ax[0,0].set_xticklabels([])
ax[0,1].plot(new_ha_1[0]/10 - ha_centre_wvl/10,new_ha_1[1])
ax[0,1].set_title(r"H$\alpha$ for the circular point")
ax[0,1].set_xticklabels([])
ax[1,0].plot(new_ca_2[0]/10 - ca_centre_wvl/10,new_ca_2[1])
ax[1,0].set_title(r"Ca\,\textsc{ii} \SI{854.2}{\nano\metre} for the square point")
ax[1,0].set_ylabel("Normalised Intensity")
ax[1,0].set_xlabel(r"$\Delta\lambda$ [nm]")
ax[1,1].plot(new_ha_2[0]/10 - ha_centre_wvl/10,new_ha_2[1])
ax[1,1].set_title(r"H$\alpha$ for the square point")
ax[1,1].set_xlabel(r"$\Delta\lambda$ [nm]")
fig.subplots_adjust(left=0.1, right=0.999, wspace=0.4)
fig.align_ylabels(ax[:, 0])
for axi in ax.flat:
    axi.xaxis.set_major_locator(plt.MaxNLocator(5))
    axi.yaxis.set_major_locator(plt.MaxNLocator(5))
lFig = chRad.save_figure('LineProfilesToInvert', fig, fext='.pgf')
lFig.caption = r'The spectral line profiles of \CaLine{} and \Ha{} for the two pixels marked in Fig.~\ref{Fig:CrispPlot}.'
lFig.short_caption = r'Line profiles to invert, on- and off-ribbon.'
lFig.placement = 'ptb'
\end{pycode}

% NOTE(cmo): To further adjust these in future go back to hephaistos and use the single_pixel_inversions notebook in ~/RadynversionRef.
\begin{pycode}[Radynversion]

import utils
with open(chRad.data_file('InversionResults.pickle'), 'rb') as f:
    res = pickle.load(f)

fig = utils.inversion_plots(res['flare'], utils.z, new_ca_1, new_ha_1, rasterizeHists=True, figsize=texfigure.figsize(pytex, scale=1, height_ratio=0.4), powerNormIdx=0.2)
lFig = chRad.save_figure('InversionResultsFlare', fig, fext='.pgf', dpi=500)
lFig.caption = r'Inversion results for the on-ribbon pixel. The histograms represent the probability density for the solution in each altitude node, and the median solution is shown with the dashed black lines.'
lFig.short_caption = r'Inversion results for the on-ribbon pixel.'
lFig.placement = 'ptb'

fig = utils.inversion_plots(res['quiet'], utils.z, new_ca_1, new_ha_1, rasterizeHists=True, figsize=texfigure.figsize(pytex, scale=1, height_ratio=0.4), powerNormIdx=0.2)
lFig = chRad.save_figure('InversionResultsQuiet', fig, fext='.pgf', dpi=500)
lFig.caption = r'Inversion results for the off-ribbon pixel. The histograms represent the probability density for the solution in each altitude node, and the median solution is shown with the dashed black lines.'
lFig.short_caption = r'Inversion results for off-ribbon pixel.'
lFig.placement = 'ptb'
\end{pycode}
% spell-checker: enable

As a proof of concept the RADYNVERSION model was applied to the two-ribbon M1.1 flare SOL 20140906T17:09 observed with the CRISP instrument in \Ha{} and \CaLine{}.
The preparation of this data is briefly discussed in Sec.~\ref{Sec:CRISP}.

\py[Radynversion]|chRad.get_figure('CrispPlot')|

Due to the formation heights of these spectral lines, our interest is primarily focused on the region below $\sim$\SI{2}{\mega\metre}.
Fig.~\ref{Fig:CrispPlot} shows CRISP images in the blue wing, line core, and red wing for both of the spectral lines respectively.
These images were taken just after flare onset.
Two pixels are marked, a circle on the flare ribbon, and a square far from the flare, in a much quieter region.
The spectral line profiles from these two pixels are shown in Fig.~\ref{Fig:LineProfilesToInvert}.
For the circular point both lines are strongly in emission whereas for the square point they are broad absorption lines.
These lines from these pixels have then been inverted using RADYNVERSION, with 20\,000 latent space draws each.
The results of these inversions are shown in Figs~\ref{Fig:InversionResultsFlare}~and~
\ref{Fig:InversionResultsQuiet} for the circular and square points respectively.
These figures present equivalent information to the lower panels of Fig.~\ref{Fig:RadynversionValidationReverse}, although the dashed black lines now show the median of the histogram at each atmospheric point as there is no ground truth solution available.
Performing these inversions with 20\,000 draws each takes $\sim$\SI{893}{\milli\second} on an NVIDIA GTX 1050 Ti GPU installed in \emph{hephaistos}.

\py[Radynversion]|chRad.get_figure('LineProfilesToInvert')|
\py[Radynversion]|chRad.get_figure('InversionResultsFlare')|
\py[Radynversion]|chRad.get_figure('InversionResultsQuiet')|

The following is a brief summary of the analysis undertaken by my co-authors.
The inverted pixels were found to be consistent with previous analyses.
For example, forward modelling by \citet{Kuridze2015} suggests that the \Ha{} line profile forms below \SI{1.2}{\mega\metre}, with the core forming towards the top of this region, and the line wings forming below \SI{0.95}{\mega\metre}.
In this observation the \Ha{} line profile is found to be asymmetric in favour of the red wing, and from the inversions we see that there is a slight upflow in the region where the wings are formed.
This is likely due to chromospheric evaporation in this region causing an increase in the opacity of the blue wing, leading in turn to more intensity in the red wing.

For the off-ribbon pixel we note that both line profiles are very broad.
The inverted velocity field contains a significant number of small magnitude oscillations which we believe are due to RADYN's conservative assumption of a \SI{2}{\kilo\metre\per\second} microturbulent velocity throughout the atmosphere, as this is insufficient to produce line profiles as broad as those observed here.
If the network has learned that bulk plasma flows can shift the position of the line core (i.e. the majority of the opacity in a line), then it is reasonable to suggest that these represent our model's attempt to broaden the line profiles.
Recent studies have shown that significantly higher microturbulent velocities are needed to explain the non-thermal broadenings observed in chromospheric plages \citep[6--\SI{7}{\kilo\metre\per\second},][]{2015Carlsson}.
The other atmospheric parameters vary more smoothly and do not reach values as large as those found for the on-ribbon pixel, which is consistent with the much quieter atmosphere expected at this location.

\section{Discussion}

The RADYNVERSION invertible neural network presented in this chapter represents a novel method for investigating the atmospheric properties of observed events and lifts many of the restrictions that previously made inversions of flaring line profiles infeasible.
This is achieved by the union of machine learning and a large body of RHD simulations.
The implementation is currently a proof of concept but shows much promise, agreeing with previous investigations, and can easily be extended to other spectral lines and atmospheric parameters.
With the addition of more advanced forward models this technique could be applied to inference of the chromospheric magnetic field from full Stokes observations.
Inversions using this method are fast and robust; the effort of ``exploring'' the latent space that is common in regression based codes has effectively been replaced with an up-front cost in the training process.
Once the model is trained, taking multiple draws from the latent space replicates the exploration, but extremely rapidly, due to the previous training effort which is then shared between every application of the model (contrary to the traditional 1.5D inversion technique, where every column is treated independently, and a lot of this work is replicated).
These latent draws additionally serve to provide an estimate of the uncertainty on the inferred parameters.
Potential future extensions to this model include incorporating the concept of time-dependence in a robust fashion so as to condition the solution from previous observations, and increasing the number of atmospheric parameters inferred.

The RADYNVERSION approach has the potential to provide new insight into the structure of the flaring chromosphere and allow investigation of complete observation fields of view in a timely fashion, allowing researchers to leverage the full capabilities of next-generation solar telescopes such as DKIST.
